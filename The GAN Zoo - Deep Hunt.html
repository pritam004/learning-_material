<!DOCTYPE html>
<!-- saved from url=(0044)https://deephunt.in/the-gan-zoo-79597dc8c347 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style class="vjs-styles-defaults">
      .video-js {
        width: 300px;
        height: 150px;
      }

      .vjs-fluid {
        padding-top: 56.25%
      }
    </style><script async="" src="./The GAN Zoo - Deep Hunt_files/branch-latest.min.js"></script><script async="" src="./The GAN Zoo - Deep Hunt_files/analytics.js"></script><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><script defer="" src="./The GAN Zoo - Deep Hunt_files/16180790160.js"></script><title>The GAN Zoo - Deep Hunt</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-09-30T20:07:19.456Z"><meta data-rh="true" name="title" content="The GAN Zoo - Deep Hunt"><meta data-rh="true" property="og:title" content="The GAN Zoo"><meta data-rh="true" property="twitter:title" content="The GAN Zoo"><meta data-rh="true" name="twitter:site" content="@deephunt_in"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/79597dc8c347"><meta data-rh="true" property="al:android:url" content="medium://p/79597dc8c347"><meta data-rh="true" property="al:ios:url" content="medium://p/79597dc8c347"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="Every week, new papers on Generative Adversarial Networks (GAN) are coming out and it’s hard to keep track of them all, not to mention the incredibly creative ways in which researchers are naming…"><meta data-rh="true" property="og:description" content="A list of all named GANs!"><meta data-rh="true" property="twitter:description" content="A list of all named GANs!"><meta data-rh="true" property="og:url" content="https://deephunt.in/the-gan-zoo-79597dc8c347"><meta data-rh="true" property="al:web:url" content="https://deephunt.in/the-gan-zoo-79597dc8c347"><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/0*ncqqFthh4e9baHxI.jpg"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/0*ncqqFthh4e9baHxI.jpg"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="https://deephunt.in/@hindupuravinash"><meta data-rh="true" name="twitter:creator" content="@hindupuravinash"><meta data-rh="true" name="author" content="Avinash Hindupur"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="22 min read"><meta data-rh="true" name="parsely-post-id" content="79597dc8c347"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://deephunt.in/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./The GAN Zoo - Deep Hunt_files/m2.css"><link data-rh="true" rel="author" href="https://deephunt.in/@hindupuravinash"><link data-rh="true" rel="canonical" href="https://deephunt.in/the-gan-zoo-79597dc8c347"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/79597dc8c347"><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="./The GAN Zoo - Deep Hunt_files/16180790160.js" as="script"><style type="text/css" data-fela-rehydration="467" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-webkit-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@-moz-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{fill:rgba(0, 0, 0, 0.84)}.r{display:block}.s{position:absolute}.t{top:0}.u{left:0}.v{right:0}.w{z-index:500}.x{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.ag{max-width:1192px}.ah{min-width:0}.ai{width:100%}.aj{height:65px}.am{flex:1 0 auto}.an{fill:rgba(0, 0, 0, 0.9)}.ao{visibility:hidden}.ap{margin-left:16px}.aq{display:none}.as{color:rgba(184, 73, 23, 1)}.at{fill:rgba(217, 81, 18, 1)}.au{font-size:inherit}.av{border:inherit}.aw{font-family:inherit}.ax{letter-spacing:inherit}.ay{font-weight:inherit}.az{padding:0}.ba{margin:0}.bb:hover{cursor:pointer}.bc:hover{color:rgba(167, 68, 24, 1)}.bd:hover{fill:rgba(184, 73, 23, 1)}.be:focus{outline:none}.bf:disabled{cursor:default}.bg:disabled{color:rgba(3, 168, 124, 0.5)}.bh:disabled{fill:rgba(3, 168, 124, 0.5)}.bi{flex:0 0 auto}.bj{font-family:medium-content-sans-serif-font, "Lucida Grande", "Lucida Sans Unicode", "Lucida Sans", Geneva, Arial, sans-serif}.bk{font-style:normal}.bl{line-height:20px}.bm{font-size:15.8px}.bn{letter-spacing:0px}.bo{color:rgba(0, 0, 0, 0.54)}.bp{fill:rgba(0, 0, 0, 0.54)}.bq{justify-content:flex-end}.br{margin-top:16px}.bs{margin-bottom:16px}.bt{display:inherit}.bu{max-width:210px}.bv{text-overflow:ellipsis}.bw{overflow:hidden}.bx{white-space:nowrap}.by{display:inline-block}.bz{border:none}.ca{outline:none}.cb{font:inherit}.cc{font-size:16px}.cd{opacity:0}.ce{position:relative}.cf{width:0px}.cg{transition:width 140ms ease-in}.ch{color:inherit}.ci{fill:inherit}.cj:hover{color:rgba(0, 0, 0, 0.9)}.ck:hover{fill:rgba(0, 0, 0, 0.9)}.cl:disabled{color:rgba(0, 0, 0, 0.54)}.cm:disabled{fill:rgba(0, 0, 0, 0.54)}.cn{margin-right:10px}.cr{margin-right:16px}.cs{margin:15px 0}.ct{padding:4px 12px}.cu{color:rgba(0, 0, 0, 0.84)}.cv{background:0}.cw{border-color:rgba(0, 0, 0, 0.54)}.cx:hover{color:rgba(0, 0, 0, 0.97)}.cy:hover{fill:rgba(0, 0, 0, 0.97)}.cz:hover{border-color:rgba(0, 0, 0, 0.84)}.da:disabled{fill:rgba(0, 0, 0, 0.76)}.db:disabled{border-color:rgba(0, 0, 0, 0.2)}.dc:disabled{cursor:inherit}.dd:disabled:hover{color:rgba(0, 0, 0, 0.54)}.de:disabled:hover{fill:rgba(0, 0, 0, 0.76)}.df:disabled:hover{border-color:rgba(0, 0, 0, 0.2)}.dg{border-radius:4px}.dh{border-width:1px}.di{border-style:solid}.dj{box-sizing:border-box}.dk{text-decoration:none}.dl{padding-bottom:10px}.dm{padding-top:10px}.dn{border-radius:50%}.do{height:32px}.dp{width:32px}.dq{border-top:none}.dr{background-color:rgba(225, 87, 24, 1)}.ds{height:54px}.dt{margin-right:40px}.du{font-weight:600}.dv{font-size:22px}.dw{line-height:28px}.dx{max-height:28px}.dy{display:-webkit-box}.dz{-webkit-line-clamp:1}.ea{-webkit-box-orient:vertical}.eb{color:rgba(255, 242, 223, 1)}.ec{overflow:auto}.ed{flex:0 1 auto}.ee{list-style-type:none}.ef{line-height:40px}.eg{overflow-x:auto}.eh{align-items:flex-start}.ei{margin-top:20px}.ej{padding-top:20px}.ek{height:80px}.el{height:20px}.em{margin-right:15px}.en{margin-left:15px}.eo:first-child{margin-left:0}.ep{font-weight:300}.eq{font-size:15px}.er{color:rgba(255, 198, 163, 1)}.es{text-transform:uppercase}.et{letter-spacing:1px}.eu:hover{color:rgba(255, 242, 223, 1)}.ev:hover{fill:rgba(255, 228, 203, 1)}.ew:disabled{color:rgba(255, 160, 114, 1)}.ex:disabled{fill:rgba(255, 160, 114, 1)}.ey{margin-bottom:0px}.ez{height:119px}.fc{padding-left:24px}.fd{padding-right:24px}.fe{margin-left:auto}.ff{margin-right:auto}.fg{max-width:728px}.fh{top:calc(100vh + 100px)}.fi{bottom:calc(100vh + 100px)}.fj{width:10px}.fk{pointer-events:none}.fl{word-break:break-word}.fm{word-wrap:break-word}.fn:after{display:block}.fo:after{content:""}.fp:after{clear:both}.fq{max-width:680px}.fr{line-height:1.23}.fs{letter-spacing:0}.ft{font-family:medium-content-title-font, Georgia, Cambria, "Times New Roman", Times, serif}.ge{margin-bottom:-0.27em}.gk{line-height:1.394}.gv{margin-bottom:-0.42em}.hb{margin-top:32px}.hc{justify-content:space-between}.hg{height:48px}.hh{width:48px}.hi{margin-left:12px}.hj{margin-bottom:2px}.hl{max-height:20px}.hm:hover{text-decoration:underline}.hn{margin-left:8px}.ho{padding:0px 8px}.hp{border-color:rgba(217, 81, 18, 1)}.hq:hover{border-color:rgba(184, 73, 23, 1)}.hr{line-height:18px}.hs{align-items:flex-end}.ia{padding-right:6px}.ib{margin-right:8px}.ic{fill:rgba(0, 0, 0, 0.76)}.id{margin-right:-6px}.ie{max-width:1200px}.ik{clear:both}.il{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.im{cursor:zoom-in}.in{z-index:auto}.io{transition:opacity 100ms 400ms}.ip{height:100%}.iq{will-change:transform}.ir{transform:translateZ(0)}.is{margin:auto}.it{background-color:rgba(0, 0, 0, 0.05)}.iu{padding-bottom:80.66666666666666%}.iv{height:0}.iw{filter:blur(20px)}.ix{transform:scale(1.1)}.iy{visibility:visible}.iz{background:rgba(255, 255, 255, 1)}.ja{margin-top:10px}.jb{text-align:center}.je{line-height:1.58}.jf{letter-spacing:-0.004em}.jg{font-family:medium-content-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.jp{margin-bottom:-0.46em}.jq{letter-spacing:-0.003em}.jt{background-repeat:repeat-x}.ju{background-image:linear-gradient(to right,rgba(0, 0, 0, 0.84) 100%,rgba(0, 0, 0, 0.84) 0);background-image:url('data:image/svg+xml;utf8,<svg preserveAspectRatio="none" viewBox="0 0 1 1" xmlns="http://www.w3.org/2000/svg"><line x1="0" y1="0" x2="1" y2="1" stroke="rgba(0, 0, 0, 0.84)" /></svg>')}.jv{background-size:1px 1px}.jw{background-position:0 1.05em;background-position:0 calc(1em + 1px)}.jx{max-width:800px}.jy{padding-bottom:68.75%}.jz{font-weight:700}.ka{font-family:medium-content-slab-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.kb{font-size:28px}.kc{color:rgba(0, 0, 0, 0.97)}.kd{margin-top:30px}.ke:before{content:"..."}.kf:before{letter-spacing:0.6em}.kg:before{text-indent:0.6em}.kh:before{font-style:italic}.ki:before{line-height:1.4}.kj{list-style-type:disc}.kk{margin-left:30px}.kl{padding-left:0px}.kr{will-change:opacity}.ks{position:fixed}.kt{width:188px}.ku{left:50%}.kv{transform:translateX(406px)}.kw{top:calc(65px + 54px + 14px)}.kz{top:calc(65px + 54px + 40px)}.lb{width:131px}.lc{flex-direction:column}.ld{padding-bottom:28px}.le{border-bottom:1px solid rgba(0, 0, 0, 0.1)}.lf{font-size:18px}.lg{padding-bottom:20px}.lh{padding-top:2px}.li{max-height:120px}.lj{-webkit-line-clamp:6}.lk{padding-top:28px}.ll{margin-bottom:19px}.lm{margin-left:-3px}.ls{outline:0}.lt{border:0}.lu{user-select:none}.lv{cursor:pointer}.lw> svg{pointer-events:none}.lx:active{border-style:none}.ly{-webkit-user-select:none}.lz:focus{fill:rgba(0, 0, 0, 0.54)}.ma:hover{fill:rgba(0, 0, 0, 0.54)}.mi button{text-align:left}.mj{margin-top:40px}.mk{flex-wrap:wrap}.ml{margin-top:25px}.mm{margin-bottom:8px}.mn{border-radius:3px}.mo{padding:5px 10px}.mp{background:rgba(0, 0, 0, 0.05)}.mq{line-height:22px}.mr{margin-top:15px}.ms{flex-direction:row}.mt{max-width:155px}.mz{border:1px solid rgba(0, 0, 0, 0.1)}.na{height:60px}.nb{width:60px}.no:hover{border-color:rgba(0, 0, 0, 0.54)}.np:active{border-style:solid}.nq{z-index:2}.ns{top:1px}.ny{padding-right:8px}.nz{padding-top:32px}.oa{border-top:1px solid rgba(0, 0, 0, 0.1)}.ob{margin-bottom:25px}.od{margin-bottom:32px}.oe{min-height:80px}.oj{width:80px}.ok{padding-left:102px}.om{letter-spacing:0.05em}.on{margin-bottom:6px}.oo{line-height:36px}.op{max-width:555px}.oq{max-width:450px}.or{line-height:24px}.ot{max-width:550px}.ou{padding-top:24px}.ov{margin-top:5px}.ow{height:40px}.ox{width:40px}.oy{font-size:12px}.oz{line-height:15px}.pa{padding-top:8px}.pb{padding-top:25px}.pd{color:rgba(0, 0, 0, 0.76)}.pe{opacity:1}.pf{padding:20px}.pg{border:1px solid rgba(217, 81, 18, 1)}.ph{margin-top:64px}.pi{background-color:rgba(0, 0, 0, 0.02)}.pj{padding:60px 0}.pk{background-color:rgba(0, 0, 0, 0.9)}.qb{padding-bottom:48px}.qc{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.qd{margin:0 -12px}.qe{margin:0 12px}.qf{flex:1 1 0}.qg{padding-bottom:12px}.qh:hover{color:rgba(255, 255, 255, 0.99)}.qi:hover{fill:rgba(255, 255, 255, 0.99)}.qj:disabled{color:rgba(255, 255, 255, 0.7)}.qk:disabled{fill:rgba(255, 255, 255, 0.7)}.ql{color:rgba(255, 255, 255, 0.98)}.qm{fill:rgba(255, 255, 255, 0.98)}.qn{text-align:inherit}.qo{font-size:21.6px}.qp{letter-spacing:-0.32px}.qq{color:rgba(255, 255, 255, 0.7)}.qr{fill:rgba(255, 255, 255, 0.7)}.qs{text-decoration:underline}.qt{padding-bottom:8px}.qu{width:200px}.ra{-webkit-user-select:none}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.af{margin:0 64px}.gc{font-size:40px}.gd{margin-top:0.78em}.gj{line-height:48px}.gt{font-size:24px}.gu{margin-top:0.79em}.ha{line-height:32px}.hz{margin-left:30px}.ij{margin-top:56px}.jn{font-size:21px}.jo{margin-top:2em}.kq{margin-top:1.05em}.lr{margin-right:5px}.mh{margin-top:5px}.my{margin-right:16px}.nx{width:25px}.py{padding-left:64px}.pz{padding-right:64px}.qa{max-width:1320px}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.hy{margin-left:30px}.jc{margin-left:auto}.jd{text-align:center}.lq{margin-right:5px}.mg{margin-top:5px}.mx{margin-right:16px}.nw{width:25px}.pv{padding-left:64px}.pw{padding-right:64px}.px{max-width:1080px}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.cq{display:flex}.hx{margin-left:30px}.lp{margin-right:5px}.mf{margin-top:5px}.mw{margin-right:16px}.nv{width:15px}.ps{padding-left:48px}.pt{padding-right:48px}.pu{max-width:904px}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.ak{height:56px}.al{display:flex}.ar{display:block}.co{margin-left:10px}.cp{margin-right:10px}.fa{margin-bottom:0px}.fb{height:110px}.he{margin-top:32px}.hf{flex-direction:column-reverse}.hv{margin-bottom:30px}.hw{margin-left:0px}.lo{margin-left:8px}.md{margin-top:2px}.me{margin-right:8px}.mv{margin-left:16px}.nu{width:15px}.oc{padding-top:0}.of{margin-bottom:24px}.og{align-items:center}.oh{width:102px}.oi{position:relative}.ol{padding-left:0}.os{margin-top:24px}.pc{border-top:none}.pl{padding:32px 0}.pp{padding-left:24px}.pq{padding-right:24px}.pr{max-width:728px}.qv{width:140px}.qw{margin-bottom:16px}.qx{margin-top:30px}.qy{width:100%}.qz{flex-direction:row}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.z{margin:0 24px}.fu{font-size:30px}.fv{margin-top:0.72em}.gf{line-height:40px}.gl{font-size:18px}.gm{margin-top:0.79em}.gw{line-height:24px}.hd{margin-top:32px}.hk{margin-bottom:0px}.ht{margin-bottom:30px}.hu{margin-left:0px}.if{margin-top:40px}.jh{margin-top:1.56em}.jr{line-height:28px}.km{margin-top:1.34em}.ln{margin-left:8px}.mb{margin-top:2px}.mc{margin-right:8px}.mu{margin-left:16px}.nt{width:15px}.pm{padding-left:24px}.pn{padding-right:24px}.po{max-width:552px}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.ae{margin:0 64px}.ga{font-size:40px}.gb{margin-top:0.78em}.gi{line-height:48px}.gr{font-size:24px}.gs{margin-top:0.79em}.gz{line-height:32px}.ii{margin-top:56px}.jl{font-size:21px}.jm{margin-top:2em}.kp{margin-top:1.05em}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.ac{margin:0 48px}.fy{font-size:40px}.fz{margin-top:0.78em}.gh{line-height:48px}.gp{font-size:24px}.gq{margin-top:0.79em}.gy{line-height:32px}.ih{margin-top:56px}.jj{font-size:21px}.jk{margin-top:2em}.ko{margin-top:1.05em}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ab{margin:0 24px}.fw{font-size:30px}.fx{margin-top:0.72em}.gg{line-height:40px}.gn{font-size:18px}.go{margin-top:0.79em}.gx{line-height:24px}.ig{margin-top:40px}.ji{margin-top:1.56em}.js{line-height:28px}.kn{margin-top:1.34em}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="print">.y{display:none}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.kx{transition:opacity 200ms}.nc{transition:border-color 150ms ease}.nd::before{background:
      radial-gradient(circle, rgba(0, 0, 0, 0.84) 60%, transparent 70%)
    }.ne::before{border-radius:50%}.nf::before{content:""}.ng::before{display:block}.nh::before{z-index:0}.ni::before{left:0}.nj::before{height:100%}.nk::before{position:absolute}.nl::before{top:0}.nm::before{width:100%}.nn:hover::before{animation:k2 2000ms infinite cubic-bezier(.1,.12,.25,1)}.nr{transition:fill 200ms ease}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (max-width: 1230px)">.ky{display:none}</style><style type="text/css" data-fela-rehydration="467" data-fela-type="RULE" media="all and (max-width: 1198px)">.la{display:none}</style><link rel="icon" href="https://miro.medium.com/fit/c/128/128/1*6yx91P_l0phituLnYOK7Jw.png" data-rh="true"><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F0*ncqqFthh4e9baHxI.jpg"],"url":"https:\u002F\u002Fdeephunt.in\u002Fthe-gan-zoo-79597dc8c347","dateCreated":"2017-04-19T16:13:52.100Z","datePublished":"2017-04-19T16:13:52.100Z","dateModified":"2018-09-30T20:07:19.456Z","headline":"The GAN Zoo - Deep Hunt","name":"The GAN Zoo - Deep Hunt","description":"Every week, new papers on Generative Adversarial Networks (GAN) are coming out and it’s hard to keep track of them all, not to mention the incredibly creative ways in which researchers are naming…","identifier":"79597dc8c347","keywords":["Lite:true","Tag:Machine Learning","Tag:Artificial Intelligence","Tag:Deep Learning","Tag:Technology","Tag:Neural Networks","Publication:deep-hunt","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:0"],"author":{"@type":"Person","name":"Avinash Hindupur","url":"https:\u002F\u002Fdeephunt.in\u002F@hindupuravinash"},"creator":["Avinash Hindupur"],"publisher":{"@type":"Organization","name":"Deep Hunt","url":"deephunt.in","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F308\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fdeephunt.in\u002Fthe-gan-zoo-79597dc8c347"}</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><nav class="r s t u v c w x y"><div><div class="r c"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="aj n o ak al"><div class="n o am w"><a href="https://medium.com/?source=post_page-----79597dc8c347----------------------" aria-label="Homepage" rel="noopener"><svg width="35" height="35" viewBox="5 5 35 35" class="an"><path d="M5 40V5h35v35H5zm8.56-12.63c0 .56-.03.69-.32 1.03L10.8 31.4v.4h6.97v-.4L15.3 28.4c-.29-.34-.34-.5-.34-1.03v-8.95l6.13 13.36h.71l5.26-13.36v10.64c0 .3 0 .35-.19.53l-1.85 1.8v.4h9.2v-.4l-1.83-1.8c-.18-.18-.2-.24-.2-.53V15.94c0-.3.02-.35.2-.53l1.82-1.8v-.4h-6.47l-4.62 11.55-5.2-11.54h-6.8v.4l2.15 2.63c.24.3.29.37.29.77v10.35z"></path></svg></a><div class="iy" id="li-general-navbar-open-in-app-button"><div class="ap aq ar"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F79597dc8c347&amp;~feature=LiOpenInAppButton&amp;~channel=ShowPostUnderCollection&amp;~stage=mobileNavBar&amp;source=post_page-----79597dc8c347----------------------" class="as at au av aw ax ay az ba bb bc bd be bf bg bh" rel="noopener">Open in app</a></div></div></div><div class="r bi w"><span class="bj b bk bl bm bn r bo bp"><div class="n o bq"><div class="n f"><div class="by" aria-hidden="true"><div class="n"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="0 0 25 25" class="ap cn r co cp"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></button><input class="bz ca cb cc bl cd ce cf cg" placeholder="Search Deep Hunt" value=""></div></div></div><div class="aq cq"><a href="https://deephunt.in/search?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="ap cr r co cp"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></a></div><a href="https://medium.com/me/list/queue?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="cr r g"><path d="M16 6a2 2 0 0 1 2 2v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-5.67-4.13-5.66 4.13a.5.5 0 0 1-.7-.03.48.48 0 0 1-.13-.29H5V8c0-1.1.9-2 2-2h9zM6 8v12.64l5.16-3.67a.49.49 0 0 1 .68 0L17 20.64V8a1 1 0 0 0-1-1H7a1 1 0 0 0-1 1z"></path><path d="M21 5v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-.17-.12V5a1 1 0 0 0-1-1h-9a1 1 0 0 0-1 1H8c0-1.1.9-2 2-2h9a2 2 0 0 1 2 2z"></path></svg></a><div class="cr n cp"><div class="by" aria-hidden="true"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm r"><svg width="25" height="25" viewBox="-293 409 25 25" class="cs r"><path d="M-273.33 423.67l-1.67-1.52v-3.65a5.5 5.5 0 0 0-6.04-5.47 5.66 5.66 0 0 0-4.96 5.71v3.41l-1.68 1.55a1 1 0 0 0-.32.74V427a1 1 0 0 0 1 1h3.49a3.08 3.08 0 0 0 3.01 2.45 3.08 3.08 0 0 0 3.01-2.45h3.49a1 1 0 0 0 1-1v-2.59a1 1 0 0 0-.33-.74zm-7.17 5.63c-.84 0-1.55-.55-1.81-1.3h3.62a1.92 1.92 0 0 1-1.81 1.3zm6.35-2.45h-12.7v-2.35l1.63-1.5c.24-.22.37-.53.37-.85v-3.41a4.51 4.51 0 0 1 3.92-4.57 4.35 4.35 0 0 1 4.78 4.33v3.65c0 .32.14.63.38.85l1.62 1.48v2.37z"></path></svg></button></div></div><div class="iy" id="li-post-page-navbar-upsell-button"><div class="cr r g"><div><a href="https://medium.com/membership?source=upgrade_membership---nav_full------------------------" class="ct cu q cv cw cx cy cz bb cl da db dc dd de df dg bj b bk bl bm bn dh di dj by dk be" rel="noopener">Upgrade</a></div></div></div><div class="n" aria-hidden="true"><div class="dl dm n o"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><img alt="Nath Pritam" class="r dn do dp" src="./The GAN Zoo - Deep Hunt_files/0_ltmrQGulORdZR-m6" width="32" height="32"></button></div></div></div></span></div></div></div></div></div><div class="dq r dr ar"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="ds bw n o"><div class="dt r bi"><a href="https://deephunt.in/?source=post_page-----79597dc8c347----------------------" rel="noopener"><span class="bj du dv dw bw dx bv dy dz ea eb">Deep Hunt</span></a></div><div class="ec r ed"><ul class="ee ba ef bx eg n eh g ei ej ek"><li class="n o el em en eo"><span class="bj ep eq bl er es et"><a class="ch ci au av aw ax ay az ba bb eu ev be bf ew ex" rel="noopener" href="https://deephunt.in/tagged/newsletter?source=post_page-----79597dc8c347----------------------">Newsletter</a></span></li></ul></div></div></div></div></div></div></nav><div class="ey ez r fa fb"></div><article><section class="fc fd fe ff ai fg dj r"></section><span class="r"></span><div><div class="s u fh fi fj fk"></div><section class="fl fm fn fo fp"><div class="n p"><div class="z ab ac ae af fq ah ai"><div><div id="8038" class="fr fs cu bk ft b fu fv fw fx fy fz ga gb gc gd ge"><h1 class="ft b fu gf fw gg fy gh ga gi gc gj cu">The GAN Zoo</h1></div></div><h2 id="9c45" class="gk fs bo bk bj ep gl gm gw gn go gx gp gq gy gr gs gz gt gu ha gv">A list of all named GANs!</h2><div class="hb"><div class="n hc hd he hf"><div class="o n"><div><a href="https://deephunt.in/@hindupuravinash?source=post_page-----79597dc8c347----------------------" rel="noopener"><img alt="Avinash Hindupur" class="r dn hg hh" src="./The GAN Zoo - Deep Hunt_files/0_5q7vZAHEK04LVoU4.jpeg" width="48" height="48"></a></div><div class="hi ai r"><div class="n"><div style="flex:1"><span class="bj b bk bl bm bn r cu q"><div class="hj n o hk"><span class="bj ep cc bl bw hl bv dy dz ea cu"><a href="https://deephunt.in/@hindupuravinash?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Avinash Hindupur</a></span><div class="hn r bi h"><button class="ho cv as at hp bc bd hq bb dg bj b bk hr eq bn dh di dj by dk be">Follow</button></div></div></span></div></div><span class="bj b bk bl bm bn r bo bp"><span class="bj ep cc bl bw hl bv dy dz ea bo"><div><a class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener" href="https://deephunt.in/the-gan-zoo-79597dc8c347?source=post_page-----79597dc8c347----------------------">Apr 19, 2017</a> <!-- -->·<!-- --> <!-- -->22<!-- --> min read</div></span></span></div></div><div class="n hs ht hu hv hw hx hy hz y"><div class="n o"><div class="ia r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></button></div><div class="ia r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="ia r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></button></div><div class="ib r"><div><div class="ic"><div><div class="by" role="tooltip" aria-hidden="true" aria-describedby="1" aria-labelledby="1"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="id r am"><div class="by" aria-hidden="true"><div class="by" aria-hidden="true"><div class="r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="q"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div></div></div></div><figure class="if ig ih ii ij ik fe ff paragraph-image"><div class="il im ce in ai"><div class="fe ff ie"><div class="is r ce it"><div class="iu iv r"><div class="cd io s t u ip ai bw iq ir"><img class="s t u ip ai iw ix ao rc" src="./The GAN Zoo - Deep Hunt_files/0_ncqqFthh4e9baHxI.jpg" width="1200" height="968" role="presentation"></div><img class="pe rb s t u ip ai iz" width="1200" height="968" srcset="https://miro.medium.com/max/552/0*ncqqFthh4e9baHxI.jpg 276w, https://miro.medium.com/max/1104/0*ncqqFthh4e9baHxI.jpg 552w, https://miro.medium.com/max/1280/0*ncqqFthh4e9baHxI.jpg 640w, https://miro.medium.com/max/1400/0*ncqqFthh4e9baHxI.jpg 700w" sizes="700px" role="presentation" src="./The GAN Zoo - Deep Hunt_files/0_ncqqFthh4e9baHxI(1).jpg"><noscript><img class="s t u ip ai" src="https://miro.medium.com/max/2400/0*ncqqFthh4e9baHxI.jpg" width="1200" height="968" srcSet="https://miro.medium.com/max/552/0*ncqqFthh4e9baHxI.jpg 276w, https://miro.medium.com/max/1104/0*ncqqFthh4e9baHxI.jpg 552w, https://miro.medium.com/max/1280/0*ncqqFthh4e9baHxI.jpg 640w, https://miro.medium.com/max/1400/0*ncqqFthh4e9baHxI.jpg 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="ja jb fg fe ff jc jd bj ep eq bl bo" data-selectable-paragraph="">Pretty painting is always better than a Terminator</figcaption></figure><p id="16a9" class="je jq cu bk jg b gl jh jr gn ji js jj jk gy jl jm gz jn jo ha jp fl" data-selectable-paragraph="">Every week, new papers on Generative Adversarial Networks (GAN) are coming out and it’s hard to keep track of them all, not to mention the incredibly creative ways in which researchers are naming these GANs! You can read more about GANs in this <a href="https://blog.openai.com/generative-models/" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Models post</a> by OpenAI or this <a href="http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html" class="ch dk jt ju jv jw" target="_blank" rel="noopener">overview tutorial</a> in KDNuggets.</p><figure class="if ig ih ii ij ik fe ff paragraph-image"><div class="il im ce in ai"><div class="fe ff jx"><div class="is r ce it"><div class="jy iv r"><div class="cd io s t u ip ai bw iq ir"><img class="s t u ip ai iw ix ao rc" src="./The GAN Zoo - Deep Hunt_files/0_NI4oWIcZgSKjIE88.jpg" width="800" height="550" role="presentation"></div><img class="pe rb s t u ip ai iz" width="800" height="550" srcset="https://miro.medium.com/max/552/0*NI4oWIcZgSKjIE88.jpg 276w, https://miro.medium.com/max/1104/0*NI4oWIcZgSKjIE88.jpg 552w, https://miro.medium.com/max/1280/0*NI4oWIcZgSKjIE88.jpg 640w, https://miro.medium.com/max/1400/0*NI4oWIcZgSKjIE88.jpg 700w" sizes="700px" role="presentation" src="./The GAN Zoo - Deep Hunt_files/0_NI4oWIcZgSKjIE88(1).jpg"><noscript><img class="s t u ip ai" src="https://miro.medium.com/max/1600/0*NI4oWIcZgSKjIE88.jpg" width="800" height="550" srcSet="https://miro.medium.com/max/552/0*NI4oWIcZgSKjIE88.jpg 276w, https://miro.medium.com/max/1104/0*NI4oWIcZgSKjIE88.jpg 552w, https://miro.medium.com/max/1280/0*NI4oWIcZgSKjIE88.jpg 640w, https://miro.medium.com/max/1400/0*NI4oWIcZgSKjIE88.jpg 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="ja jb fg fe ff jc jd bj ep eq bl bo" data-selectable-paragraph="">Explosive growth — All the named GAN variants cumulatively since 2014. Credit: <a href="https://github.com/bgavran" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Bruno Gavranović</a></figcaption></figure><p id="dd00" class="je jq cu bk jg b gl jh jr gn ji js jj jk gy jl jm gz jn jo ha jp fl" data-selectable-paragraph="">So, here’s the current and frequently updated list, from what started as a fun activity compiling all named GANs in this format: <strong class="jg jz">Name</strong> and <strong class="jg jz">Source Paper</strong> linked to <a href="https://arxiv.org/" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Arxiv</a>. Last updated on Feb 23, 2018.</p></div></div></section><hr class="ka ep kb kc bz kd jb ke kf kg kh ki"><section class="fl fm fn fo fp"><div class="n p"><div class="z ab ac ae af fq ah ai"><ul class=""><li id="0b56" class="je jq cu bk jg b gl jh jr gn ji js jj jk gy jl jm gz jn jo ha jp kj kk kl" data-selectable-paragraph="">3D-ED-GAN — <a href="https://arxiv.org/abs/1711.06375" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Shape Inpainting using 3D Generative Adversarial Network and Recurrent Convolutional Networks</a></li><li id="6a92" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">3D-GAN — <a href="https://arxiv.org/abs/1610.07584" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling</a> (<a href="https://github.com/zck119/3dgan-release" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="040c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">3D-IWGAN — <a href="https://arxiv.org/abs/1707.09557" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improved Adversarial Systems for 3D Object Generation and Reconstruction</a> (<a href="https://github.com/EdwardSmith1884/3D-IWGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="ae16" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">3D-PhysNet — <a href="https://arxiv.org/abs/1805.00328" class="ch dk jt ju jv jw" target="_blank" rel="noopener">3D-PhysNet: Learning the Intuitive Physics of Non-Rigid Object Deformations</a></li><li id="cd7a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">3D-RecGAN — <a href="https://arxiv.org/abs/1708.07969" class="ch dk jt ju jv jw" target="_blank" rel="noopener">3D Object Reconstruction from a Single Depth View with Adversarial Learning</a> (<a href="https://github.com/Yang7879/3D-RecGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="78df" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ABC-GAN — <a href="https://drive.google.com/file/d/0B3wEP_lEl0laVTdGcHE2VnRiMlE/view" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ABC-GAN: Adaptive Blur and Control for improved training stability of Generative Adversarial Networks</a>(<a href="https://github.com/IgorSusmelj/ABC-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="a2c9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ABC-GAN — <a href="https://arxiv.org/abs/1711.11139" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GANs for LIFE: Generative Adversarial Networks for Likelihood Free Inference</a></li><li id="b72f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AC-GAN — <a href="https://arxiv.org/abs/1610.09585" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Conditional Image Synthesis With Auxiliary Classifier GANs</a></li><li id="b96a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">acGAN — <a href="https://arxiv.org/abs/1702.01983" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Face Aging With Conditional Generative Adversarial Networks</a></li><li id="d30a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ACGAN — <a href="https://arxiv.org/abs/1712.06951" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Coverless Information Hiding Based on Generative adversarial networks</a></li><li id="0d8f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">acGAN — <a href="https://arxiv.org/abs/1808.00020" class="ch dk jt ju jv jw" target="_blank" rel="noopener">On-line Adaptative Curriculum Learning for GANs</a></li><li id="6ffa" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ACtuAL — <a href="https://arxiv.org/abs/1711.04755" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ACtuAL: Actor-Critic Under Adversarial Learning</a></li><li id="c8f5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AdaGAN — <a href="https://arxiv.org/abs/1701.02386v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AdaGAN: Boosting Generative Models</a></li><li id="a500" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Adaptive GAN — <a href="https://arxiv.org/abs/1806.10496" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Customizing an Adversarial Example Generator with Class-Conditional GANs</a></li><li id="5e8e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AdvEntuRe — <a href="https://arxiv.org/abs/1805.04680" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AdvEntuRe: Adversarial Training for Textual Entailment with Knowledge-Guided Examples</a></li><li id="90bc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AdvGAN — <a href="https://arxiv.org/abs/1801.02610" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating adversarial examples with adversarial networks</a></li><li id="5893" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AE-GAN — <a href="https://arxiv.org/abs/1707.05474" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AE-GAN: adversarial eliminating with GAN</a></li><li id="c828" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AE-OT — <a href="https://arxiv.org/abs/1809.05964" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Latent Space Optimal Transport for Generative Models</a></li><li id="7dc0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AEGAN — <a href="https://arxiv.org/abs/1703.10094" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Inverse Mapping by Autoencoder based Generative Adversarial Nets</a></li><li id="9df0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AF-DCGAN — <a href="https://arxiv.org/abs/1804.05347" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AF-DCGAN: Amplitude Feature Deep Convolutional GAN for Fingerprint Construction in Indoor Localization System</a></li><li id="88db" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AffGAN — <a href="https://arxiv.org/abs/1610.04490" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Amortised MAP Inference for Image Super-resolution</a></li><li id="00d2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AIM — <a href="https://arxiv.org/abs/1809.05972" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization</a></li><li id="58bc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AL-CGAN — <a href="https://arxiv.org/abs/1612.00215" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning to Generate Images of Outdoor Scenes from Attributes and Semantic Layouts</a></li><li id="3497" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ALI — <a href="https://arxiv.org/abs/1606.00704" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarially Learned Inference</a> (<a href="https://github.com/IshmaelBelghazi/ALI" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="c472" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AlignGAN — <a href="https://arxiv.org/abs/1707.01400" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AlignGAN: Learning to Align Cross-Domain Images with Conditional Generative Adversarial Networks</a></li><li id="8de2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AlphaGAN — <a href="https://arxiv.org/abs/1807.10088" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AlphaGAN: Generative adversarial networks for natural image matting</a></li><li id="b74e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AM-GAN — <a href="https://arxiv.org/abs/1703.02000" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Activation Maximization Generative Adversarial Nets</a></li><li id="df03" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AmbientGAN — <a href="https://openreview.net/forum?id=Hy7fDog0b" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AmbientGAN: Generative models from lossy measurements</a> (<a href="https://github.com/AshishBora/ambient-gan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="fb14" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AMC-GAN — <a href="https://arxiv.org/abs/1807.02635" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Video Prediction with Appearance and Motion Conditions</a></li><li id="3911" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AnoGAN — <a href="https://arxiv.org/abs/1703.05921v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</a></li><li id="5aba" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">APD — <a href="https://arxiv.org/abs/1806.10317" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Distillation of Bayesian Neural Network Posteriors</a></li><li id="af82" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">APE-GAN — <a href="https://arxiv.org/abs/1707.05474" class="ch dk jt ju jv jw" target="_blank" rel="noopener">APE-GAN: Adversarial Perturbation Elimination with GAN</a></li><li id="a1d9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ARAE — <a href="https://arxiv.org/abs/1706.04223" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarially Regularized Autoencoders for Generating Discrete Structures</a> (<a href="https://github.com/jakezhaojb/ARAE" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="d2b6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ARDA — <a href="https://arxiv.org/abs/1707.01217" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Representation Learning for Domain Adaptation</a></li><li id="c07d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ARIGAN — <a href="https://arxiv.org/abs/1709.00938" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ARIGAN: Synthetic Arabidopsis Plants using Generative Adversarial Network</a></li><li id="eb03" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ArtGAN — <a href="https://arxiv.org/abs/1702.03410" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ArtGAN: Artwork Synthesis with Conditional Categorial GANs</a></li><li id="8e4d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ASDL-GAN — <a href="https://ieeexplore.ieee.org/document/8017430/" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Automatic Steganographic Distortion Learning Using a Generative Adversarial Network</a></li><li id="3ca5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ATA-GAN — <a href="https://arxiv.org/abs/1802.09070" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Attention-Aware Generative Adversarial Networks (ATA-GANs)</a></li><li id="248b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Attention-GAN — <a href="https://arxiv.org/abs/1803.06798" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Attention-GAN for Object Transfiguration in Wild Images</a></li><li id="bc0a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AttGAN — <a href="https://arxiv.org/abs/1711.10678" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Arbitrary Facial Attribute Editing: Only Change What You Want</a> (<a href="https://github.com/LynnHo/AttGAN-Tensorflow" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="b04a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AttnGAN — <a href="https://arxiv.org/abs/1711.10485" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks</a> (<a href="https://github.com/taoxugit/AttnGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="cba6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">AVID — <a href="https://arxiv.org/abs/1805.09521" class="ch dk jt ju jv jw" target="_blank" rel="noopener">AVID: Adversarial Visual Irregularity Detection</a></li><li id="c6dd" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">B-DCGAN — <a href="https://arxiv.org/abs/1803.10930" class="ch dk jt ju jv jw" target="_blank" rel="noopener">B-DCGAN:Evaluation of Binarized DCGAN for FPGA</a></li><li id="8b82" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">b-GAN — <a href="https://arxiv.org/abs/1610.02920" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Nets from a Density Ratio Estimation Perspective</a></li><li id="ea0c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BAGAN — <a href="https://arxiv.org/abs/1803.09655" class="ch dk jt ju jv jw" target="_blank" rel="noopener">BAGAN: Data Augmentation with Balancing GAN</a></li><li id="bbba" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Bayesian GAN — <a href="https://arxiv.org/abs/1702.08896" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep and Hierarchical Implicit Models</a></li><li id="b271" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Bayesian GAN — <a href="https://arxiv.org/abs/1705.09558" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Bayesian GAN</a> (<a href="https://github.com/andrewgordonwilson/bayesgan/" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="316c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BCGAN — <a href="https://arxiv.org/abs/1706.05477" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Bayesian Conditional Generative Adverserial Networks</a></li><li id="82d6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BCGAN — <a href="https://arxiv.org/abs/1711.07461" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Bidirectional Conditional Generative Adversarial networks</a></li><li id="f084" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BEAM — <a href="https://arxiv.org/abs/1804.08682" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Boltzmann Encoded Adversarial Machines</a></li><li id="88fa" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BEGAN — <a href="https://arxiv.org/abs/1703.10717" class="ch dk jt ju jv jw" target="_blank" rel="noopener">BEGAN: Boundary Equilibrium Generative Adversarial Networks</a></li><li id="2663" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BEGAN-CS — <a href="https://arxiv.org/abs/1808.07258" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Escaping from Collapsing Modes in a Constrained Space</a></li><li id="21a6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Bellman GAN — <a href="https://arxiv.org/abs/1808.01960" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Distributional Multivariate Policy Evaluation and Exploration with the Bellman GAN</a></li><li id="490e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BGAN — <a href="https://arxiv.org/abs/1708.04150" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Binary Generative Adversarial Networks for Image Retrieval</a> (<a href="https://github.com/htconquer/BGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="39b1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Bi-GAN — <a href="https://arxiv.org/abs/1809.10244" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Autonomously and Simultaneously Refining Deep Neural Network Parameters by a Bi-Generative Adversarial Network Aided Genetic Algorithm</a></li><li id="ba84" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BicycleGAN — <a href="https://arxiv.org/abs/1711.11586" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Toward Multimodal Image-to-Image Translation</a> (<a href="https://github.com/junyanz/BicycleGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="a345" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BiGAN — <a href="https://arxiv.org/abs/1605.09782v7" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Feature Learning</a></li><li id="ca91" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BinGAN — <a href="https://arxiv.org/abs/1806.06778" class="ch dk jt ju jv jw" target="_blank" rel="noopener">BinGAN: Learning Compact Binary Descriptors with a Regularized GAN</a></li><li id="a54b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BourGAN — <a href="https://arxiv.org/abs/1805.07674" class="ch dk jt ju jv jw" target="_blank" rel="noopener">BourGAN: Generative Networks with Metric Embeddings</a></li><li id="d4b2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BranchGAN — <a href="https://arxiv.org/abs/1803.08467" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Branched Generative Adversarial Networks for Multi-Scale Image Manifold Learning</a></li><li id="37f5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BRE — <a href="https://arxiv.org/abs/1805.03644" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improving GAN Training via Binarized Representation Entropy (BRE) Regularization</a> (<a href="https://github.com/BorealisAI/bre-gan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="1724" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BridgeGAN — <a href="https://arxiv.org/abs/1808.00327" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Frontal View to Bird View Synthesis</a></li><li id="8cba" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BS-GAN — <a href="https://arxiv.org/abs/1702.08431v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Boundary-Seeking Generative Adversarial Networks</a></li><li id="e91c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BubGAN — <a href="https://arxiv.org/abs/1809.02266" class="ch dk jt ju jv jw" target="_blank" rel="noopener">BubGAN: Bubble Generative Adversarial Networks for Synthesizing Realistic Bubbly Flow Images</a></li><li id="5485" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">BWGAN — <a href="https://arxiv.org/abs/1806.06621" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Banach Wasserstein GAN</a></li><li id="3e87" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">C-GAN — <a href="https://arxiv.org/abs/1802.00237" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Face Aging with Contextual Generative Adversarial Nets</a></li><li id="9b88" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">C-RNN-GAN — <a href="https://arxiv.org/abs/1611.09904" class="ch dk jt ju jv jw" target="_blank" rel="noopener">C-RNN-GAN: Continuous recurrent neural networks with adversarial training</a> (<a href="https://github.com/olofmogren/c-rnn-gan/" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="6d2a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CA-GAN — <a href="https://arxiv.org/abs/1712.00899" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Composition-aided Sketch-realistic Portrait Generation</a></li><li id="e790" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CaloGAN — <a href="https://arxiv.org/abs/1705.02355" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks</a> (<a href="https://github.com/hep-lbdl/CaloGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="3c7b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CAN — <a href="https://arxiv.org/abs/1706.07068" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CAN: Creative Adversarial Networks, Generating Art by Learning About Styles and Deviating from Style Norms</a></li><li id="ae7d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CapsGAN — <a href="https://arxiv.org/abs/1806.03968" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CapsGAN: Using Dynamic Routing for Generative Adversarial Networks</a></li><li id="c7b3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CapsuleGAN — <a href="http://arxiv.org/abs/1802.06167" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CapsuleGAN: Generative Adversarial Capsule Network</a></li><li id="a57e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CatGAN — <a href="https://arxiv.org/abs/1511.06390v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks</a></li><li id="5fb5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CatGAN — <a href="https://arxiv.org/abs/1711.08904" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CatGAN: Coupled Adversarial Transfer for Domain Generation</a></li><li id="96f7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CausalGAN — <a href="https://arxiv.org/abs/1709.02023" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training</a></li><li id="1e41" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CC-GAN — <a href="https://arxiv.org/abs/1611.06430" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks</a> (<a href="https://github.com/edenton/cc-gan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="4487" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">cd-GAN — <a href="https://arxiv.org/abs/1805.00251" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Conditional Image-to-Image Translation</a></li><li id="7ddb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CDcGAN — <a href="https://arxiv.org/abs/1708.09105" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Simultaneously Color-Depth Super-Resolution with Conditional Generative Adversarial Network</a></li><li id="3334" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CE-GAN — <a href="https://arxiv.org/abs/1807.04585" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Learning for Imbalance Data Classification using Class Expert Generative Adversarial Network</a></li><li id="906f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CFG-GAN — <a href="https://arxiv.org/abs/1801.06309" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Composite Functional Gradient Learning of Generative Adversarial Models</a></li><li id="d21c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CGAN — <a href="https://arxiv.org/abs/1411.1784" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Conditional Generative Adversarial Nets</a></li><li id="4086" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CGAN — <a href="https://arxiv.org/abs/1708.00598" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Controllable Generative Adversarial Network</a></li><li id="73b4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Chekhov GAN — <a href="https://arxiv.org/abs/1706.03269" class="ch dk jt ju jv jw" target="_blank" rel="noopener">An Online Learning Approach to Generative Adversarial Networks</a></li><li id="9268" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ciGAN — <a href="https://arxiv.org/abs/1807.08093" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Conditional Infilling GANs for Data Augmentation in Mammogram Classification</a></li><li id="2e77" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CinCGAN — <a href="https://arxiv.org/abs/1809.00437" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Image Super-Resolution using Cycle-in-Cycle Generative Adversarial Networks</a></li><li id="e3ce" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CipherGAN — <a href="https://arxiv.org/abs/1801.04883" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Cipher Cracking Using Discrete GANs</a></li><li id="d91e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ClusterGAN — <a href="https://arxiv.org/abs/1809.03627" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ClusterGAN : Latent Space Clustering in Generative Adversarial Networks</a></li><li id="729c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CM-GAN — <a href="https://arxiv.org/abs/1710.05106" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning</a></li><li id="49dc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CoAtt-GAN — <a href="https://arxiv.org/abs/1711.07613" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning</a></li><li id="f07d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CoGAN — <a href="https://arxiv.org/abs/1606.07536v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Coupled Generative Adversarial Networks</a></li><li id="e9d4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ComboGAN — <a href="https://arxiv.org/abs/1712.06909" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ComboGAN: Unrestrained Scalability for Image Domain Translation</a> (<a href="https://github.com/AAnoosheh/ComboGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="b578" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ConceptGAN — <a href="https://arxiv.org/abs/1711.06148" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Compositional Visual Concepts with Mutual Consistency</a></li><li id="9027" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Conditional cycleGAN — <a href="https://arxiv.org/abs/1705.09966" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Conditional CycleGAN for Attribute Guided Face Image Generation</a></li><li id="0c99" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">constrast-GAN — <a href="https://arxiv.org/abs/1708.00315" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Semantic Manipulation with Contrasting GAN</a></li><li id="1845" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Context-RNN-GAN — <a href="https://arxiv.org/abs/1609.09444" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Contextual RNN-GANs for Abstract Reasoning Diagram Generation</a></li><li id="e51d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CorrGAN — <a href="https://arxiv.org/abs/1804.00925" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Correlated discrete data generation using adversarial training</a></li><li id="aa14" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Coulomb GAN — <a href="https://arxiv.org/abs/1708.08819" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields</a></li><li id="63e9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Cover-GAN — <a href="https://arxiv.org/abs/1711.04916" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Steganography with Kerckhoffs’ Principle based on Generative Adversarial Networks</a></li><li id="a526" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">cowboy — <a href="https://arxiv.org/abs/1805.10652" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Defending Against Adversarial Attacks by Leveraging an Entire GAN</a></li><li id="eccc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CR-GAN — <a href="https://arxiv.org/abs/1806.11191" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CR-GAN: Learning Complete Representations for Multi-view Generation</a></li><li id="ffa3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Cramèr GAN — <a href="https://arxiv.org/abs/1705.10743" class="ch dk jt ju jv jw" target="_blank" rel="noopener">The Cramer Distance as a Solution to Biased Wasserstein Gradients</a></li><li id="69e5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Cross-GAN — <a href="https://arxiv.org/abs/1801.01760" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Crossing Generative Adversarial Networks for Cross-View Person Re-identification</a></li><li id="a967" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">crVAE-GAN — <a href="https://arxiv.org/abs/1706.03729" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Channel-Recurrent Variational Autoencoders</a></li><li id="53dc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CS-GAN — <a href="https://arxiv.org/abs/1703.04887" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets</a></li><li id="c0d7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CSG — <a href="https://arxiv.org/abs/1806.00154" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Speech-Driven Expressive Talking Lips with Conditional Sequential Generative Adversarial Networks</a></li><li id="d798" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CT-GAN — <a href="https://arxiv.org/abs/1807.04812" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CT-GAN: Conditional Transformation Generative Adversarial Network for Image Attribute Modification</a></li><li id="3852" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CVAE-GAN — <a href="https://arxiv.org/abs/1703.10155" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training</a></li><li id="78e7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">CycleGAN — <a href="https://arxiv.org/abs/1703.10593" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a> (<a href="https://github.com/junyanz/CycleGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="e65b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">D-GAN — <a href="https://arxiv.org/abs/1711.10267" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Differential Generative Adversarial Networks: Synthesizing Non-linear Facial Variations with Limited Number of Training Data</a></li><li id="1d89" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">D-WCGAN — <a href="https://arxiv.org/abs/1804.00290" class="ch dk jt ju jv jw" target="_blank" rel="noopener">I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification</a></li><li id="d8ed" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">D2GAN — <a href="http://arxiv.org/abs/1709.03831" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Dual Discriminator Generative Adversarial Nets</a></li><li id="fd3d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">D2IA-GAN — <a href="https://arxiv.org/abs/1804.00113" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Tagging like Humans: Diverse and Distinct Image Annotation</a></li><li id="087d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DA-GAN — <a href="http://arxiv.org/abs/1802.06454" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DA-GAN: Instance-level Image Translation by Deep Attention Generative Adversarial Networks (with Supplementary Materials)</a></li><li id="cfde" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DADA — <a href="https://arxiv.org/abs/1809.00981" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DADA: Deep Adversarial Data Augmentation for Extremely Low Data Regime Classification</a></li><li id="466d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DAGAN — <a href="https://arxiv.org/abs/1711.04340" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Data Augmentation Generative Adversarial Networks</a></li><li id="02b4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DAN — <a href="https://arxiv.org/abs/1706.09549" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Distributional Adversarial Networks</a></li><li id="c9d0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DBLRGAN — <a href="https://arxiv.org/abs/1804.00533" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Spatio-Temporal Learning for Video Deblurring</a></li><li id="4139" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DCGAN — <a href="https://arxiv.org/abs/1511.06434" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a> (<a href="https://github.com/Newmu/dcgan_code" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="9f22" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DE-GAN — <a href="https://arxiv.org/abs/1807.03923" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Networks with Decoder-Encoder Output Noise</a></li><li id="ac6d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DeblurGAN — <a href="https://arxiv.org/abs/1711.07064" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks</a> (<a href="https://github.com/KupynOrest/DeblurGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="ce13" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DeepFD — <a href="https://arxiv.org/abs/1809.08754" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning to Detect Fake Face Images in the Wild</a></li><li id="e1b9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Defense-GAN — <a href="https://arxiv.org/abs/1805.06605" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models </a>(<a href="https://github.com/kabkabm/defensegan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="0021" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Defo-Net — <a href="https://arxiv.org/abs/1804.05928" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Defo-Net: Learning Body Deformation using Generative Adversarial Networks</a></li><li id="ebd0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DeliGAN — <a href="https://arxiv.org/abs/1706.02071" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DeLiGAN : Generative Adversarial Networks for Diverse and Limited Data</a> (<a href="https://github.com/val-iisc/deligan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="e00f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DF-GAN — <a href="https://arxiv.org/abs/1712.04646" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Disentangling and Fusing Networks for Face Completion Under Structured Occlusions</a></li><li id="22e0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DialogWAE — <a href="https://arxiv.org/abs/1805.12352" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder</a></li><li id="d712" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DiscoGAN — <a href="https://arxiv.org/abs/1703.05192v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning to Discover Cross-Domain Relations with Generative Adversarial Networks</a></li><li id="764e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DistanceGAN — <a href="https://arxiv.org/abs/1706.00826" class="ch dk jt ju jv jw" target="_blank" rel="noopener">One-Sided Unsupervised Domain Mapping</a></li><li id="3d99" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DM-GAN — <a href="https://arxiv.org/abs/1708.00284" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Dual Motion GAN for Future-Flow Embedded Video Prediction</a></li><li id="e89a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DMGAN — <a href="https://arxiv.org/abs/1806.00880" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Disconnected Manifold Learning for Generative Adversarial Networks</a></li><li id="ca57" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DNA-GAN — <a href="https://arxiv.org/abs/1711.05415" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images</a></li><li id="e194" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DOPING — <a href="https://arxiv.org/abs/1808.07632" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection with GAN</a></li><li id="3fb0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">dp-GAN — <a href="https://arxiv.org/abs/1801.01594" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Differentially Private Releasing via Deep Generative Model</a></li><li id="6c8f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DP-GAN — <a href="https://arxiv.org/abs/1802.01345" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DP-GAN: Diversity-Promoting Generative Adversarial Network for Generating Informative and Diversified Text</a></li><li id="587a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DPGAN — <a href="http://arxiv.org/abs/1802.06739" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Differentially Private Generative Adversarial Network</a></li><li id="14c4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DR-GAN — <a href="https://arxiv.org/abs/1705.11136" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Representation Learning by Rotating Your Faces</a></li><li id="56cf" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DRAGAN — <a href="https://arxiv.org/abs/1705.07215" class="ch dk jt ju jv jw" target="_blank" rel="noopener">How to Train Your DRAGAN</a> (<a href="https://github.com/kodalinaveen3/DRAGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="5781" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Dropout-GAN — <a href="https://arxiv.org/abs/1807.11346" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Dropout-GAN: Learning from a Dynamic Ensemble of Discriminators</a></li><li id="10cc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DRPAN — <a href="https://arxiv.org/abs/1711.09554" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Discriminative Region Proposal Adversarial Networks for High-Quality Image-to-Image Translation</a></li><li id="cd8d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DSH-GAN — <a href="https://arxiv.org/abs/1804.08275" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Semantic Hashing with Generative Adversarial Networks</a></li><li id="1c55" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DSP-GAN — <a href="https://arxiv.org/abs/1706.00212" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Depth Structure Preserving Scene Image Generation</a></li><li id="4784" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DTLC-GAN — <a href="https://arxiv.org/abs/1805.10603" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Image Synthesis with Decision Tree Latent Controller</a></li><li id="dd3f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DTN — <a href="https://arxiv.org/abs/1611.02200" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Cross-Domain Image Generation</a></li><li id="0a01" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DTR-GAN — <a href="https://arxiv.org/abs/1804.11228" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DTR-GAN: Dilated Temporal Relational Adversarial Network for Video Summarization</a></li><li id="f9f0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DualGAN — <a href="https://arxiv.org/abs/1704.02510v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">DualGAN: Unsupervised Dual Learning for Image-to-Image Translation</a></li><li id="4ddc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Dualing GAN — <a href="https://arxiv.org/abs/1706.06216" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Dualing GANs</a></li><li id="88fc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">DVGAN — <a href="https://arxiv.org/abs/1804.10652" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Human Motion Modeling using DVGANs</a></li><li id="d979" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Dynamics Transfer GAN — <a href="https://arxiv.org/abs/1712.03534" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Dynamics Transfer GAN: Generating Video by Transferring Arbitrary Temporal Dynamics from a Source Video to a Single Target Image</a></li><li id="87e4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">E-GAN — <a href="https://arxiv.org/abs/1803.00657" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Evolutionary Generative Adversarial Networks</a></li><li id="71ac" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">EAR — <a href="https://arxiv.org/abs/1804.09858" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Model for Heterogeneous Inference</a></li><li id="371c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">EBGAN — <a href="https://arxiv.org/abs/1609.03126v4" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Energy-based Generative Adversarial Network</a></li><li id="f947" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ecGAN — <a href="https://arxiv.org/abs/1801.03244" class="ch dk jt ju jv jw" target="_blank" rel="noopener">eCommerceGAN : A Generative Adversarial Network for E-commerce</a></li><li id="253b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ED//GAN — <a href="https://arxiv.org/abs/1705.09367" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Stabilizing Training of Generative Adversarial Networks through Regularization</a></li><li id="4f8a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Editable GAN — <a href="https://arxiv.org/abs/1807.07700" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Editable Generative Adversarial Networks: Generating and Editing Faces Simultaneously</a></li><li id="8af5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">EGAN — <a href="https://arxiv.org/abs/1705.08245" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Enhanced Experience Replay Generation for Efficient Reinforcement Learning</a></li><li id="3c14" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">EL-GAN — <a href="https://arxiv.org/abs/1806.05525" class="ch dk jt ju jv jw" target="_blank" rel="noopener">EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection</a></li><li id="83af" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ELEGANT — <a href="https://arxiv.org/abs/1803.10562" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes</a></li><li id="8bb7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">EnergyWGAN — <a href="https://arxiv.org/abs/1712.01026" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Energy-relaxed Wassertein GANs (EnergyWGAN): Towards More Stable and High Resolution Image Generation</a></li><li id="5232" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ESRGAN — <a href="https://arxiv.org/abs/1809.00219" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks</a></li><li id="7f3d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ExGAN — <a href="https://arxiv.org/abs/1712.03999" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Eye In-Painting with Exemplar Generative Adversarial Networks</a></li><li id="b837" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ExposureGAN — <a href="https://arxiv.org/abs/1709.09602" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Exposure: A White-Box Photo Post-Processing Framework</a> (<a href="https://github.com/yuanming-hu/exposure" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="5716" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ExprGAN — <a href="https://arxiv.org/abs/1709.03842" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ExprGAN: Facial Expression Editing with Controllable Expression Intensity</a></li><li id="484c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">f-CLSWGAN — <a href="https://arxiv.org/abs/1712.00981" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Feature Generating Networks for Zero-Shot Learning</a></li><li id="bcbc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">f-GAN — <a href="https://arxiv.org/abs/1606.00709" class="ch dk jt ju jv jw" target="_blank" rel="noopener">f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization</a></li><li id="d8af" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FairGAN — <a href="https://arxiv.org/abs/1805.11202" class="ch dk jt ju jv jw" target="_blank" rel="noopener">FairGAN: Fairness-aware Generative Adversarial Networks</a></li><li id="d471" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Fairness GAN — <a href="https://arxiv.org/abs/1805.09910" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Fairness GAN</a></li><li id="6c6b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FakeGAN — <a href="https://arxiv.org/abs/1805.10364" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Detecting Deceptive Reviews using Generative Adversarial Networks</a></li><li id="93ff" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FBGAN — <a href="https://arxiv.org/abs/1804.01694" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions</a></li><li id="9e7e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FBGAN — <a href="https://arxiv.org/abs/1805.07862" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference</a></li><li id="3212" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FC-GAN — <a href="https://arxiv.org/abs/1805.01972" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Fast-converging Conditional Generative Adversarial Networks for Image Synthesis</a></li><li id="499f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FF-GAN — <a href="https://arxiv.org/abs/1704.06244" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Towards Large-Pose Face Frontalization in the Wild</a></li><li id="26ff" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FGGAN — <a href="https://arxiv.org/abs/1807.02247" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Learning for Fine-grained Image Search</a></li><li id="8c98" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Fictitious GAN — <a href="https://arxiv.org/abs/1803.08647" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Fictitious GAN: Training GANs with Historical Models</a></li><li id="674c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FIGAN — <a href="https://arxiv.org/abs/1711.06045" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Frame Interpolation with Multi-Scale Deep Loss Functions and Generative Adversarial Networks</a></li><li id="d3f4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Fila-GAN — <a href="https://arxiv.org/abs/1706.02185" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Synthesizing Filamentary Structured Images with GANs</a></li><li id="8802" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">First Order GAN — <a href="https://arxiv.org/abs/1802.04591" class="ch dk jt ju jv jw" target="_blank" rel="noopener">First Order Generative Adversarial Networks </a>(<a href="https://github.com/zalandoresearch/first_order_gan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="3ae7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Fisher GAN — <a href="https://arxiv.org/abs/1705.09675" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Fisher GAN</a></li><li id="aee8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Flow-GAN — <a href="https://arxiv.org/abs/1705.08868" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Flow-GAN: Bridging implicit and prescribed learning in generative models</a></li><li id="6fff" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FrankenGAN — <a href="https://arxiv.org/abs/1806.07179" class="ch dk jt ju jv jw" target="_blank" rel="noopener">rankenGAN: Guided Detail Synthesis for Building Mass-Models Using Style-Synchonized GANs</a></li><li id="1318" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FSEGAN — <a href="https://arxiv.org/abs/1711.05747" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Exploring Speech Enhancement with Generative Adversarial Networks for Robust Speech Recognition</a></li><li id="cd6f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FTGAN — <a href="https://arxiv.org/abs/1711.09618" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture</a></li><li id="f658" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FusedGAN — <a href="https://arxiv.org/abs/1801.05551" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semi-supervised FusedGAN for Conditional Image Generation</a></li><li id="0626" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FusionGAN — <a href="https://arxiv.org/abs/1712.01456" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning to Fuse Music Genres with Generative Adversarial Dual Learning</a></li><li id="ad65" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">FusionGAN — <a href="https://arxiv.org/abs/1804.07455" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating a Fusion Image: One’s Identity and Another’s Shape</a></li><li id="151b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">G2-GAN — <a href="https://arxiv.org/abs/1712.03474" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Geometry Guided Adversarial Facial Expression Synthesis</a></li><li id="e3b9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAAN — <a href="https://arxiv.org/abs/1803.08887" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Autoencoder Networks</a></li><li id="02b9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAF — <a href="https://arxiv.org/abs/1805.05185" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Forests for Better Conditioned Adversarial Learning</a></li><li id="71f7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAGAN — <a href="https://arxiv.org/abs/1712.00684" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GAGAN: Geometry-Aware Generative Adverserial Networks</a></li><li id="4aca" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAIA — <a href="https://arxiv.org/abs/1807.06650" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions</a></li><li id="dd2c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAIN — <a href="https://arxiv.org/abs/1806.02920" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GAIN: Missing Data Imputation using Generative Adversarial Nets</a></li><li id="2971" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAMN — <a href="https://arxiv.org/abs/1709.09820" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Mapping Networks</a></li><li id="5424" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN — <a href="https://arxiv.org/abs/1406.2661" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Networks</a> (<a href="https://github.com/goodfeli/adversarial" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="d3c3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN Lab — <a href="https://arxiv.org/abs/1809.01587" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation</a></li><li id="13e1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN Q-learning — <a href="https://arxiv.org/abs/1805.04874" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GAN Q-learning</a></li><li id="3eaf" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-AD — <a href="https://arxiv.org/abs/1809.04758" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series</a></li><li id="a303" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-ATV — <a href="https://arxiv.org/abs/1710.10553" class="ch dk jt ju jv jw" target="_blank" rel="noopener">A Novel Approach to Artistic Textual Visualization via GAN</a></li><li id="b93f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-CLS — <a href="https://arxiv.org/abs/1605.05396" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Text to Image Synthesis</a> (<a href="https://github.com/reedscot/icml2016" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="3542" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-RS — <a href="https://arxiv.org/abs/1712.00736" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Towards Qualitative Advancement of Underwater Machine Vision with Generative Adversarial Networks</a></li><li id="39b2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-SD — <a href="https://arxiv.org/abs/1805.10000" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Virtual-Taobao: Virtualizing Real-world Online Retail Environment for Reinforcement Learning</a></li><li id="bad0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-sep — <a href="https://arxiv.org/abs/1708.04692" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GANs for Biological Image Synthesis</a> (<a href="https://github.com/aosokin/biogans" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="7de5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-VFS — <a href="https://arxiv.org/abs/1708.02681" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Network-based Synthesis of Visible Faces from Polarimetric Thermal Faces</a></li><li id="3abb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAN-Word2Vec — <a href="https://arxiv.org/abs/1805.08720" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Training of Word2Vec for Basket Completion</a></li><li id="2dfb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GANAX — <a href="https://arxiv.org/abs/1806.01107" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GANAX: A Unified MIMD-SIMD Acceleration for Generative Adversarial Networks</a></li><li id="0bd7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GANCS — <a href="https://arxiv.org/abs/1706.00051" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Generative Adversarial Networks for Compressed Sensing Automates MRI</a></li><li id="d8bc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GANDI — <a href="https://arxiv.org/abs/1711.01391" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Guiding the search in continuous state-action spaces by learning an action sampling distribution from off-target samples</a></li><li id="1fbf" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GANG — <a href="https://arxiv.org/abs/1712.00679" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GANGs: Generative Adversarial Network Games</a></li><li id="bc74" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GANG — <a href="https://arxiv.org/abs/1806.07268" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Beyond Local Nash Equilibria for Adversarial Networks</a></li><li id="6a03" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GANosaic — <a href="https://arxiv.org/abs/1712.00269" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GANosaic: Mosaic Creation with Generative Texture Manifolds</a></li><li id="51ba" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GANVO — <a href="https://arxiv.org/abs/1809.05786" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks</a></li><li id="8e9a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAP — <a href="https://arxiv.org/abs/1710.09549" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Context-Aware Generative Adversarial Privacy</a></li><li id="d8b1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAP — <a href="https://arxiv.org/abs/1807.05306" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Privacy</a></li><li id="fedc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GATS — <a href="https://arxiv.org/abs/1806.05780" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Sample-Efficient Deep RL with Generative Adversarial Tree Search</a></li><li id="ed9a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GAWWN — <a href="https://arxiv.org/abs/1610.02454" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning What and Where to Draw</a> (<a href="https://github.com/reedscot/nips2016" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="2830" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GC-GAN — <a href="https://arxiv.org/abs/1802.01822" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Geometry-Contrastive Generative Adversarial Network for Facial Expression Synthesis</a></li><li id="15f1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GcGAN — <a href="https://arxiv.org/abs/1809.05852" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Geometry-Consistent Adversarial Networks for One-Sided Unsupervised Domain Mapping</a></li><li id="2a37" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GeneGAN — <a href="https://arxiv.org/abs/1705.04932" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GeneGAN: Learning Object Transfiguration and Attribute Subspace from Unpaired Data</a> (<a href="https://github.com/Prinsphield/GeneGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="e4fd" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GeoGAN — <a href="https://arxiv.org/abs/1801.08839" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating Instance Segmentation Annotation by Geometry-guided GAN</a></li><li id="6893" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Geometric GAN — <a href="https://arxiv.org/abs/1705.02894" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Geometric GAN</a></li><li id="1acb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GIN — <a href="https://arxiv.org/abs/1808.04495" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Invertible Networks (GIN): Pathophysiology-Interpretable Feature Mapping and Virtual Patient Generation</a></li><li id="d1c0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GLCA-GAN — <a href="https://arxiv.org/abs/1801.08390" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Global and Local Consistent Age Generative Adversarial Networks</a></li><li id="7957" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GM-GAN — <a href="https://arxiv.org/abs/1808.10356" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Gaussian Mixture Generative Adversarial Networks for Diverse Datasets, and the Unsupervised Clustering of Images</a></li><li id="1130" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GMAN — <a href="http://arxiv.org/abs/1611.01673" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Multi-Adversarial Networks</a></li><li id="6ccf" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GMM-GAN — <a href="https://arxiv.org/abs/1706.09884" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Towards Understanding the Dynamics of Generative Adversarial Networks</a></li><li id="c4fc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GoGAN — <a href="https://arxiv.org/abs/1704.04865" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Gang of GANs: Generative Adversarial Networks with Maximum Margin Ranking</a></li><li id="7652" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GONet — <a href="https://arxiv.org/abs/1803.03254" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation</a></li><li id="a710" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GP-GAN — <a href="https://arxiv.org/abs/1703.07195" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GP-GAN: Towards Realistic High-Resolution Image Blending</a> (<a href="https://github.com/wuhuikai/GP-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="9c48" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GP-GAN — <a href="https://arxiv.org/abs/1710.00962" class="ch dk jt ju jv jw" target="_blank" rel="noopener">GP-GAN: Gender Preserving GAN for Synthesizing Faces from Landmarks</a></li><li id="3ca9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GPU — <a href="https://arxiv.org/abs/1711.08054" class="ch dk jt ju jv jw" target="_blank" rel="noopener">A generative adversarial framework for positive-unlabeled classification</a></li><li id="5ba3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GRAN — <a href="https://arxiv.org/abs/1602.05110" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating images with recurrent adversarial networks</a> (<a href="https://github.com/jiwoongim/GRAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="ded6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Graphical-GAN — <a href="https://arxiv.org/abs/1804.03429" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Graphical Generative Adversarial Networks</a></li><li id="9349" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GraphSGAN — <a href="https://arxiv.org/abs/1809.00130" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semi-supervised Learning on Graphs with Generative Adversarial Nets</a></li><li id="c3e8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GraspGAN — <a href="https://arxiv.org/abs/1709.07857" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping</a></li><li id="8a74" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">GT-GAN — <a href="https://arxiv.org/abs/1805.09980" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Graph Translation</a></li><li id="1dfa" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">HAN — <a href="https://arxiv.org/abs/1711.06448" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Chinese Typeface Transformation with Hierarchical Adversarial Network</a></li><li id="f8b4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">HAN — <a href="https://arxiv.org/abs/1805.08006" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Bidirectional Learning for Robust Neural Networks</a></li><li id="1591" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">HiGAN — <a href="https://arxiv.org/abs/1805.04384" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Exploiting Images for Video Recognition with Hierarchical Generative Adversarial Networks</a></li><li id="b42b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">HP-GAN — <a href="https://arxiv.org/abs/1711.09561" class="ch dk jt ju jv jw" target="_blank" rel="noopener">HP-GAN: Probabilistic 3D human motion prediction via GAN</a></li><li id="4a04" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">HR-DCGAN — <a href="https://arxiv.org/abs/1711.06491" class="ch dk jt ju jv jw" target="_blank" rel="noopener">High-Resolution Deep Convolutional Generative Adversarial Networks</a></li><li id="265b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">hredGAN — <a href="https://arxiv.org/abs/1805.11752" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Multi-turn Dialogue Response Generation in an Adversarial Learning framework</a></li><li id="5415" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IAN — <a href="https://arxiv.org/abs/1609.07093" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Neural Photo Editing with Introspective Adversarial Networks</a> (<a href="https://github.com/ajbrock/Neural-Photo-Editor" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="3493" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IcGAN — <a href="https://arxiv.org/abs/1611.06355" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Invertible Conditional GANs for image editing</a> (<a href="https://github.com/Guim3/IcGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="f379" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ID-CGAN — <a href="https://arxiv.org/abs/1701.05957v3" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Image De-raining Using a Conditional Generative Adversarial Network</a></li><li id="dea8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IdCycleGAN — <a href="https://arxiv.org/abs/1712.00971" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Face Translation between Images and Videos using Identity-aware CycleGAN</a></li><li id="d6b1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IFcVAEGAN — <a href="https://arxiv.org/abs/1711.05175" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Conditional Autoencoders with Adversarial Information Factorization</a></li><li id="9165" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">iGAN — <a href="https://arxiv.org/abs/1609.03552v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Visual Manipulation on the Natural Image Manifold</a> (<a href="https://github.com/junyanz/iGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="1fc9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IGMM-GAN — <a href="https://arxiv.org/abs/1809.02728" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Coupled IGMM-GANs for deep multimodal anomaly detection in human mobility data</a></li><li id="f924" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Improved GAN — <a href="https://arxiv.org/abs/1606.03498" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improved Techniques for Training GANs</a> (<a href="https://github.com/openai/improved-gan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="9140" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">In2I — <a href="https://arxiv.org/abs/1711.09334" class="ch dk jt ju jv jw" target="_blank" rel="noopener">In2I : Unsupervised Multi-Image-to-Image Translation Using Generative Adversarial Networks</a></li><li id="2b5f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">InfoGAN — <a href="https://arxiv.org/abs/1606.03657v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a>(<a href="https://github.com/openai/InfoGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="c1b7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IntroVAE — <a href="https://arxiv.org/abs/1807.06358" class="ch dk jt ju jv jw" target="_blank" rel="noopener">IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis</a></li><li id="421d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IR2VI — <a href="https://arxiv.org/abs/1806.09565" class="ch dk jt ju jv jw" target="_blank" rel="noopener">IR2VI: Enhanced Night Environmental Perception by Unsupervised Thermal Image Translation</a></li><li id="ec4a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IRGAN — <a href="https://arxiv.org/abs/1705.10513v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval models</a></li><li id="0603" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IRGAN — <a href="https://arxiv.org/abs/1806.03577" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Nets for Information Retrieval: Fundamentals and Advances</a></li><li id="cb91" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ISGAN — <a href="https://arxiv.org/abs/1807.08571" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Invisible Steganography via Generative Adversarial Network</a></li><li id="1e81" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ISP-GPM — <a href="https://arxiv.org/abs/1808.02104" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Inner Space Preserving Generative Pose Machine</a></li><li id="fc7c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Iterative-GAN — <a href="https://arxiv.org/abs/1711.06078" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Two Birds with One Stone: Iteratively Learn Facial Attributes with GANs</a> (<a href="https://github.com/punkcure/Iterative-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="6fb1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IterGAN — <a href="https://arxiv.org/abs/1804.05651" class="ch dk jt ju jv jw" target="_blank" rel="noopener">IterGANs: Iterative GANs to Learn and Control 3D Object Transformation</a></li><li id="71f6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IVE-GAN — <a href="https://arxiv.org/abs/1711.08646" class="ch dk jt ju jv jw" target="_blank" rel="noopener">IVE-GAN: Invariant Encoding Generative Adversarial Networks</a></li><li id="5162" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">iVGAN — <a href="https://arxiv.org/abs/1711.11453" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Towards an Understanding of Our World by GANing Videos in the Wild</a> (<a href="https://github.com/bernhard2202/improved-video-gan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="952e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">IWGAN — <a href="https://arxiv.org/abs/1706.00550" class="ch dk jt ju jv jw" target="_blank" rel="noopener">On Unifying Deep Generative Models</a></li><li id="1def" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">JointGAN — <a href="https://arxiv.org/abs/1806.02978" class="ch dk jt ju jv jw" target="_blank" rel="noopener">JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets</a></li><li id="2af8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">JR-GAN — <a href="https://arxiv.org/abs/1806.09235" class="ch dk jt ju jv jw" target="_blank" rel="noopener">JR-GAN: Jacobian Regularization for Generative Adversarial Networks</a></li><li id="e25f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">KBGAN — <a href="https://arxiv.org/abs/1711.04071" class="ch dk jt ju jv jw" target="_blank" rel="noopener">KBGAN: Adversarial Learning for Knowledge Graph Embeddings</a></li><li id="7222" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">KGAN — <a href="https://arxiv.org/abs/1711.01744" class="ch dk jt ju jv jw" target="_blank" rel="noopener">KGAN: How to Break The Minimax Game in GAN</a></li><li id="b5eb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">l-GAN — <a href="https://arxiv.org/abs/1707.02392" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Representation Learning and Adversarial Generation of 3D Point Clouds</a></li><li id="0d45" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LAC-GAN — <a href="https://arxiv.org/abs/1801.05096" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Grounded Language Understanding for Manipulation Instructions Using GAN-Based Classification</a></li><li id="a17c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LAGAN — <a href="https://arxiv.org/abs/1701.05927" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis</a></li><li id="f8b7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LAPGAN — <a href="https://arxiv.org/abs/1506.05751" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks</a> (<a href="https://github.com/facebook/eyescream" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="df5a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LB-GAN — <a href="http://arxiv.org/abs/1802.07447" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Load Balanced GANs for Multi-view Face Image Synthesis</a></li><li id="34f8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LBT — <a href="https://arxiv.org/abs/1807.03870" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Implicit Generative Models by Teaching Explicit Ones</a></li><li id="383f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LCC-GAN — <a href="https://arxiv.org/abs/1806.04895" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Learning with Local Coordinate Coding</a></li><li id="e40a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LD-GAN — <a href="https://arxiv.org/abs/1707.07831" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Linear Discriminant Generative Adversarial Networks</a></li><li id="4e60" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LDAN — <a href="https://arxiv.org/abs/1709.01993" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Face Images</a></li><li id="78c7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LeakGAN — <a href="https://arxiv.org/abs/1709.08624" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Long Text Generation via Adversarial Training with Leaked Information</a></li><li id="1168" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LeGAN — <a href="https://arxiv.org/abs/1707.07530" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Likelihood Estimation for Generative Adversarial Networks</a></li><li id="102d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LGAN — <a href="https://arxiv.org/abs/1711.06020" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Global versus Localized Generative Adversarial Nets</a></li><li id="8ac9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Lipizzaner — <a href="https://arxiv.org/abs/1807.08194" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Towards Distributed Coevolutionary GANs</a></li><li id="1ce1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LR-GAN — <a href="https://arxiv.org/abs/1703.01560v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation</a></li><li id="4847" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LS-GAN — <a href="https://arxiv.org/abs/1701.06264" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities</a></li><li id="458e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">LSGAN — <a href="https://arxiv.org/abs/1611.04076v3" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Least Squares Generative Adversarial Networks</a></li><li id="16d3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">M-AAE — <a href="https://arxiv.org/abs/1804.08882" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Mask-aware Photorealistic Face Attribute Manipulation</a></li><li id="a131" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MAD-GAN — <a href="https://arxiv.org/abs/1704.02906" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Multi-Agent Diverse Generative Adversarial Networks</a></li><li id="b234" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MAGAN — <a href="https://arxiv.org/abs/1704.03817v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MAGAN: Margin Adaptation for Generative Adversarial Networks</a></li><li id="083c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MAGAN — <a href="https://arxiv.org/abs/1803.00385" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MAGAN: Aligning Biological Manifolds</a></li><li id="eed1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MalGAN — <a href="https://arxiv.org/abs/1702.05983v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN</a></li><li id="d6e8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MaliGAN — <a href="https://arxiv.org/abs/1702.07983" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Maximum-Likelihood Augmented Discrete Generative Adversarial Networks</a></li><li id="87d5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">manifold-WGAN — <a href="https://arxiv.org/abs/1712.01551" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Manifold-valued Image Generation with Wasserstein Adversarial Networks</a></li><li id="333e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MARTA-GAN — <a href="https://arxiv.org/abs/1612.08879" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Unsupervised Representation Learning for Remote Sensing Images</a></li><li id="a13e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MaskGAN — <a href="https://arxiv.org/abs/1801.07736" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MaskGAN: Better Text Generation via Filling in the ______</a></li><li id="9061" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MC-GAN — <a href="https://arxiv.org/abs/1712.00516" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Multi-Content GAN for Few-Shot Font Style Transfer</a> (<a href="https://github.com/azadis/MC-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="aee9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MC-GAN — <a href="https://arxiv.org/abs/1805.01123" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MC-GAN: Multi-conditional Generative Adversarial Network for Image Synthesis</a></li><li id="82fc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">McGAN — <a href="https://arxiv.org/abs/1702.08398v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">McGan: Mean and Covariance Feature Matching GAN</a></li><li id="a686" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MD-GAN — <a href="https://arxiv.org/abs/1709.07592" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks</a></li><li id="b746" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MDGAN — <a href="https://arxiv.org/abs/1612.02136" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Mode Regularized Generative Adversarial Networks</a></li><li id="720c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MedGAN — <a href="https://arxiv.org/abs/1703.06490v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating Multi-label Discrete Electronic Health Records using Generative Adversarial Networks</a></li><li id="908b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MedGAN — <a href="https://arxiv.org/abs/1806.06397" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MedGAN: Medical Image Translation using GANs</a></li><li id="e1f4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MEGAN — <a href="https://arxiv.org/abs/1805.02481" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MEGAN: Mixture of Experts of Generative Adversarial Networks for Multimodal Image Generation</a></li><li id="af3e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MelanoGAN — <a href="https://arxiv.org/abs/1804.04338" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MelanoGANs: High Resolution Skin Lesion Synthesis with GANs</a></li><li id="ea75" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">memoryGAN — <a href="https://arxiv.org/abs/1803.01500" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks</a></li><li id="7d90" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MeRGAN — <a href="https://arxiv.org/abs/1809.02058" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Memory Replay GANs: learning to generate images from new categories without forgetting</a></li><li id="8509" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MGAN — <a href="https://arxiv.org/abs/1604.04382" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks</a> (<a href="https://github.com/chuanli11/MGANs" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="092d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MGGAN — <a href="https://arxiv.org/abs/1708.02556" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Multi-Generator Generative Adversarial Nets</a></li><li id="76b3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MGGAN — <a href="https://arxiv.org/abs/1804.04391" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MGGAN: Solving Mode Collapse using Manifold Guided Training</a></li><li id="5d83" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MIL-GAN — <a href="https://arxiv.org/abs/1712.01455" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Multimodal Storytelling via Generative Adversarial Imitation Learning</a></li><li id="0ca7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MinLGAN — <a href="https://arxiv.org/abs/1808.00200" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Anomaly Detection via Minimum Likelihood Generative Adversarial Networks</a></li><li id="4561" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MIX+GAN — <a href="https://arxiv.org/abs/1703.00573v3" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generalization and Equilibrium in Generative Adversarial Nets (GANs)</a></li><li id="e488" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MIXGAN — <a href="https://arxiv.org/abs/1807.01659" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MIXGAN: Learning Concepts from Different Domains for Mixture Generation</a></li><li id="0cba" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MLGAN — <a href="https://arxiv.org/abs/1711.02792" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Metric Learning-based Generative Adversarial Network</a></li><li id="40f0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MMC-GAN — <a href="https://arxiv.org/abs/1806.03847" class="ch dk jt ju jv jw" target="_blank" rel="noopener">A Multimodal Classifier Generative Adversarial Network for Carry and Place Tasks from Ambiguous Language Instructions</a></li><li id="2c8c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MMD-GAN — <a href="https://arxiv.org/abs/1705.08584" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MMD GAN: Towards Deeper Understanding of Moment Matching Network</a> (<a href="https://github.com/dougalsutherland/opt-mmd" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="ec47" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MMGAN — <a href="https://arxiv.org/abs/1707.08273" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MMGAN: Manifold Matching Generative Adversarial Network for Generating Images</a></li><li id="ebe0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MoCoGAN — <a href="https://arxiv.org/abs/1707.04993" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MoCoGAN: Decomposing Motion and Content for Video Generation</a> (<a href="https://github.com/sergeytulyakov/mocogan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="0b95" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Modified GAN-CLS — <a href="https://arxiv.org/abs/1806.11302" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generate the corresponding Image from Text Description using Modified GAN-CLS Algorithm</a></li><li id="5742" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ModularGAN — <a href="https://arxiv.org/abs/1804.03343" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Modular Generative Adversarial Networks</a></li><li id="5b4a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MolGAN — <a href="https://arxiv.org/abs/1805.11973" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MolGAN: An implicit generative model for small molecular graphs</a></li><li id="5331" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MPM-GAN — <a href="https://arxiv.org/abs/1612.01294" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Message Passing Multi-Agent GANs</a></li><li id="3e57" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MS-GAN — <a href="http://papers.nips.cc/paper/7014-temporal-coherency-based-criteria-for-predicting-video-frames-using-deep-multi-stage-generative-adversarial-networks" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Temporal Coherency based Criteria for Predicting Video Frames using Deep Multi-stage Generative Adversarial Networks</a></li><li id="9e06" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MTGAN — <a href="https://arxiv.org/abs/1803.09059" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks</a></li><li id="4aa2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MuseGAN — <a href="https://arxiv.org/abs/1709.06298" class="ch dk jt ju jv jw" target="_blank" rel="noopener">MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks</a></li><li id="0bfb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">MV-BiGAN — <a href="https://arxiv.org/abs/1611.02019v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Multi-view Generative Adversarial Networks</a></li><li id="d74a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">N2RPP — <a href="https://arxiv.org/abs/1805.02825" class="ch dk jt ju jv jw" target="_blank" rel="noopener">N2RPP: An Adversarial Network to Rebuild Plantar Pressure for ACLD Patients</a></li><li id="8973" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">NAN — <a href="https://arxiv.org/abs/1804.03287" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing</a></li><li id="5ddb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">NCE-GAN — <a href="https://arxiv.org/abs/1803.10996" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Dihedral angle prediction using generative adversarial networks</a></li><li id="e3c8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ND-GAN — <a href="https://arxiv.org/abs/1802.10560" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Novelty Detection with GAN</a></li><li id="ac1c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">NetGAN — <a href="https://arxiv.org/abs/1803.00816" class="ch dk jt ju jv jw" target="_blank" rel="noopener">NetGAN: Generating Graphs via Random Walks</a></li><li id="20b3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">OCAN — <a href="https://arxiv.org/abs/1803.01798" class="ch dk jt ju jv jw" target="_blank" rel="noopener">One-Class Adversarial Nets for Fraud Detection</a></li><li id="25c0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">OptionGAN — <a href="https://arxiv.org/abs/1709.06683" class="ch dk jt ju jv jw" target="_blank" rel="noopener">OptionGAN: Learning Joint Reward-Policy Options using Generative Adversarial Inverse Reinforcement Learning</a></li><li id="e4a4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ORGAN — <a href="https://arxiv.org/abs/1705.10843" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models</a></li><li id="e48a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ORGAN — <a href="https://arxiv.org/abs/1711.06363" class="ch dk jt ju jv jw" target="_blank" rel="noopener">3D Reconstruction of Incomplete Archaeological Objects Using a Generative Adversary Network</a></li><li id="cd1d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">OT-GAN — <a href="https://arxiv.org/abs/1803.05573" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improving GANs Using Optimal Transport</a></li><li id="5ca1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PacGAN — <a href="https://arxiv.org/abs/1712.04086" class="ch dk jt ju jv jw" target="_blank" rel="noopener">PacGAN: The power of two samples in generative adversarial networks</a></li><li id="a204" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PAN — <a href="https://arxiv.org/abs/1706.09138" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Perceptual Adversarial Networks for Image-to-Image Transformation</a></li><li id="af86" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PassGAN — <a href="https://arxiv.org/abs/1709.00440" class="ch dk jt ju jv jw" target="_blank" rel="noopener">PassGAN: A Deep Learning Approach for Password Guessing</a></li><li id="8226" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PD-WGAN — <a href="https://arxiv.org/abs/1805.09575" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Primal-Dual Wasserstein GAN</a></li><li id="1f94" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Perceptual GAN — <a href="https://arxiv.org/abs/1706.05274" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Perceptual Generative Adversarial Networks for Small Object Detection</a></li><li id="15ee" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PGAN — <a href="https://arxiv.org/abs/1708.01886" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Probabilistic Generative Adversarial Networks</a></li><li id="df67" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PGD-GAN — <a href="https://arxiv.org/abs/1802.08406" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Solving Linear Inverse Problems Using GAN Priors: An Algorithm with Provable Guarantees</a></li><li id="9305" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PGGAN — <a href="https://arxiv.org/abs/1803.07422" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Patch-Based Image Inpainting with Generative Adversarial Networks</a></li><li id="a827" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PIONEER — <a href="https://arxiv.org/abs/1807.03026" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Pioneer Networks: Progressively Growing Generative Autoencoder</a></li><li id="085a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Pip-GAN — <a href="https://arxiv.org/abs/1711.10742" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Pipeline Generative Adversarial Networks for Facial Images Generation with Multiple Attributes</a></li><li id="211d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">pix2pix — <a href="https://arxiv.org/abs/1611.07004" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Image-to-Image Translation with Conditional Adversarial Networks</a> (<a href="https://github.com/phillipi/pix2pix" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="771e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">pix2pixHD — <a href="https://arxiv.org/abs/1711.11585" class="ch dk jt ju jv jw" target="_blank" rel="noopener">High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs</a> (<a href="https://github.com/NVIDIA/pix2pixHD" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="2ddd" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PixelGAN — <a href="https://arxiv.org/abs/1706.00531" class="ch dk jt ju jv jw" target="_blank" rel="noopener">PixelGAN Autoencoders</a></li><li id="b767" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PM-GAN — <a href="https://arxiv.org/abs/1804.06248" class="ch dk jt ju jv jw" target="_blank" rel="noopener">PM-GANs: Discriminative Representation Learning for Action Recognition Using Partial-modalities</a></li><li id="8a02" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PN-GAN — <a href="https://arxiv.org/abs/1712.02225" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Pose-Normalized Image Generation for Person Re-identification</a></li><li id="500d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">POGAN — <a href="https://arxiv.org/abs/1805.01084" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Perceptually Optimized Generative Adversarial Network for Single Image Dehazing</a></li><li id="1f47" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Pose-GAN — <a href="https://arxiv.org/abs/1705.00053" class="ch dk jt ju jv jw" target="_blank" rel="noopener">The Pose Knows: Video Forecasting by Generating Pose Futures</a></li><li id="18a0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PP-GAN — <a href="https://arxiv.org/abs/1806.08906" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Privacy-Protective-GAN for Face De-identification</a></li><li id="8502" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PPAN — <a href="https://arxiv.org/abs/1712.07008" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Privacy-Preserving Adversarial Networks</a></li><li id="6c60" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PPGN — <a href="https://arxiv.org/abs/1612.00005" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space</a></li><li id="d758" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PrGAN — <a href="https://arxiv.org/abs/1612.05872" class="ch dk jt ju jv jw" target="_blank" rel="noopener">3D Shape Induction from 2D Views of Multiple Objects</a></li><li id="254c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ProGanSR — <a href="https://arxiv.org/abs/1804.02900" class="ch dk jt ju jv jw" target="_blank" rel="noopener">A Fully Progressive Approach to Single-Image Super-Resolution</a></li><li id="abf5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Progressive GAN — <a href="https://arxiv.org/abs/1710.10196" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Progressive Growing of GANs for Improved Quality, Stability, and Variation</a> (<a href="https://github.com/tkarras/progressive_growing_of_gans" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="9def" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PS-GAN — <a href="https://arxiv.org/abs/1804.02047" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond</a></li><li id="d177" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PSGAN — <a href="http://arxiv.org/abs/1705.06566" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Texture Manifolds with the Periodic Spatial GAN</a></li><li id="25ad" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PSGAN — <a href="https://arxiv.org/abs/1805.03371" class="ch dk jt ju jv jw" target="_blank" rel="noopener">PSGAN: A Generative Adversarial Network for Remote Sensing Image Pan-Sharpening</a></li><li id="8ce8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">PS²-GAN — <a href="https://arxiv.org/abs/1710.10182" class="ch dk jt ju jv jw" target="_blank" rel="noopener">High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks</a></li><li id="e127" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RadialGAN — <a href="http://arxiv.org/abs/1802.06403" class="ch dk jt ju jv jw" target="_blank" rel="noopener">RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks</a></li><li id="26de" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RaGAN — <a href="https://arxiv.org/abs/1807.00734" class="ch dk jt ju jv jw" target="_blank" rel="noopener">The relativistic discriminator: a key element missing from standard GAN</a></li><li id="1540" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RAN — <a href="https://arxiv.org/abs/1712.05444" class="ch dk jt ju jv jw" target="_blank" rel="noopener">RAN4IQA: Restorative Adversarial Nets for No-Reference Image Quality Assessment</a> (<a href="https://github.com/hindupuravinash/the-gan-zoo/blob/master" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="ca2b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RankGAN — <a href="https://arxiv.org/abs/1705.11001" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Ranking for Language Generation</a></li><li id="57ca" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RCGAN — <a href="https://arxiv.org/abs/1706.02633" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs</a></li><li id="016b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ReConNN — <a href="https://arxiv.org/abs/1805.00528" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Reconstruction of Simulation-Based Physical Field with Limited Samples by Reconstruction Neural Network</a></li><li id="8dd9" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Recycle-GAN — <a href="https://arxiv.org/abs/1808.05174" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Recycle-GAN: Unsupervised Video Retargeting</a></li><li id="3c25" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RefineGAN — <a href="https://arxiv.org/abs/1709.00753" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Compressed Sensing MRI Reconstruction with Cyclic Loss in Generative Adversarial Networks</a></li><li id="799e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ReGAN — <a href="https://arxiv.org/abs/1805.02788" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ReGAN: RE[LAX|BAR|INFORCE] based Sequence Generation using GANs</a> (<a href="https://github.com/TalkToTheGAN/REGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="ff15" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RegCGAN — <a href="https://arxiv.org/abs/1805.02456" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unpaired Multi-Domain Image Generation via Regularized Conditional GANs</a></li><li id="12b8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RenderGAN — <a href="https://arxiv.org/abs/1611.01331" class="ch dk jt ju jv jw" target="_blank" rel="noopener">RenderGAN: Generating Realistic Labeled Data</a></li><li id="5ff1" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Resembled GAN — <a href="https://arxiv.org/abs/1807.00947" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Resembled Generative Adversarial Networks: Two Domains with Similar Attributes</a></li><li id="ec72" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ResGAN — <a href="https://arxiv.org/abs/1707.04881" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Network based on Resnet for Conditional Image Restoration</a></li><li id="dcdf" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RNN-WGAN — <a href="https://arxiv.org/abs/1706.01399" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Language Generation with Recurrent Generative Adversarial Networks without Pre-training</a> (<a href="https://github.com/amirbar/rnn.wgan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="1626" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RoCGAN — <a href="https://arxiv.org/abs/1805.08657" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Robust Conditional Generative Adversarial Networks</a></li><li id="8a3c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RPGAN — <a href="https://arxiv.org/abs/1705.07831" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Stabilizing GAN Training with Multiple Random Projections</a> (<a href="https://github.com/ayanc/rpgan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="e3ac" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RTT-GAN — <a href="https://arxiv.org/abs/1703.07022v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Recurrent Topic-Transition GAN for Visual Paragraph Generation</a></li><li id="8b73" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">RWGAN — <a href="https://arxiv.org/abs/1705.07164" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Relaxed Wasserstein with Applications to GANs</a></li><li id="bb8e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SAD-GAN — <a href="https://arxiv.org/abs/1611.08788v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks</a></li><li id="811f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SAGA — <a href="https://arxiv.org/abs/1804.00709" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Learning for Spectrum Sensing</a></li><li id="ae38" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SAGAN — <a href="https://arxiv.org/abs/1805.08318" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Self-Attention Generative Adversarial Networks</a></li><li id="3e51" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SalGAN — <a href="https://arxiv.org/abs/1701.01081" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SalGAN: Visual Saliency Prediction with Generative Adversarial Networks</a> (<a href="https://github.com/imatge-upc/saliency-salgan-2017" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="6089" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SAM — <a href="https://arxiv.org/abs/1809.02064" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Sample-Efficient Imitation Learning via Generative Adversarial Nets</a></li><li id="a1fa" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">sAOG — <a href="https://arxiv.org/abs/1807.03877" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Structured Generative Models</a></li><li id="3510" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SAR-GAN — <a href="https://arxiv.org/abs/1802.10036" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating High Quality Visible Images from SAR Images Using CNNs</a></li><li id="23f4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SBADA-GAN — <a href="https://arxiv.org/abs/1705.08824" class="ch dk jt ju jv jw" target="_blank" rel="noopener">From source to target and back: symmetric bi-directional adaptive GAN</a></li><li id="8a17" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ScarGAN — <a href="https://arxiv.org/abs/1808.04500" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ScarGAN: Chained Generative Adversarial Networks to Simulate Pathological Tissue on Cardiovascular MR Scans</a></li><li id="d343" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SCH-GAN — <a href="https://arxiv.org/abs/1802.02488" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SCH-GAN: Semi-supervised Cross-modal Hashing by Generative Adversarial Network</a></li><li id="ab9d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SD-GAN — <a href="https://arxiv.org/abs/1705.07904" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semantically Decomposing the Latent Spaces of Generative Adversarial Networks</a></li><li id="5cc8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Sdf-GAN — <a href="https://arxiv.org/abs/1803.06657" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Sdf-GAN: Semi-supervised Depth Fusion with Multi-scale Adversarial Networks</a></li><li id="c85a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SEGAN — <a href="https://arxiv.org/abs/1703.09452v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SEGAN: Speech Enhancement Generative Adversarial Network</a></li><li id="4cf7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SeGAN — <a href="https://arxiv.org/abs/1703.10239" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SeGAN: Segmenting and Generating the Invisible</a></li><li id="af55" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SegAN — <a href="https://arxiv.org/abs/1706.01805" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SegAN: Adversarial Network with Multi-scale L1 Loss for Medical Image Segmentation</a></li><li id="b383" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Sem-GAN — <a href="https://arxiv.org/abs/1807.04409" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Sem-GAN: Semantically-Consistent Image-to-Image Translation</a></li><li id="ebdb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SeqGAN — <a href="https://arxiv.org/abs/1609.05473v5" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient</a> (<a href="https://github.com/LantaoYu/SeqGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="7bad" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SeUDA — <a href="https://arxiv.org/abs/1806.00600" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semantic-Aware Generative Adversarial Nets for Unsupervised Domain Adaptation in Chest X-ray Segmentation</a></li><li id="d8aa" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SG-GAN — <a href="https://arxiv.org/abs/1801.01726" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semantic-aware Grad-GAN for Virtual-to-Real Urban Scene Adaption</a> (<a href="https://github.com/Peilun-Li/SG-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="7927" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SG-GAN — <a href="https://arxiv.org/abs/1805.07509" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Sparsely Grouped Multi-task Generative Adversarial Networks for Facial Attribute Manipulation</a></li><li id="0ecb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SGAN — <a href="https://arxiv.org/abs/1611.08207" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Texture Synthesis with Spatial Generative Adversarial Networks</a></li><li id="55bb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SGAN — <a href="https://arxiv.org/abs/1612.04357v4" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Stacked Generative Adversarial Networks</a> (<a href="https://github.com/xunhuang1995/SGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="9228" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SGAN — <a href="https://arxiv.org/abs/1703.05502" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Steganographic Generative Adversarial Networks</a></li><li id="53c0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SGAN — <a href="https://arxiv.org/abs/1712.02330" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SGAN: An Alternative Training of Generative Adversarial Networks</a></li><li id="223c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SGAN — <a href="https://arxiv.org/abs/1807.07144" class="ch dk jt ju jv jw" target="_blank" rel="noopener">CT Image Enhancement Using Stacked Generative Adversarial Networks and Transfer Learning for Lesion Segmentation Improvement</a></li><li id="b075" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">sGAN — <a href="https://arxiv.org/abs/1804.04366" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Training for MRA Image Synthesis Using Multi-Contrast MRI</a></li><li id="adc5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SiftingGAN — <a href="https://arxiv.org/abs/1809.04985" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SiftingGAN: Generating and Sifting Labeled Samples to Improve the Remote Sensing Image Scene Classification Baseline in vitro</a></li><li id="87d6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SiGAN — <a href="https://arxiv.org/abs/1807.08370" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SiGAN: Siamese Generative Adversarial Network for Identity-Preserving Face Hallucination</a></li><li id="1945" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SimGAN — <a href="https://arxiv.org/abs/1612.07828" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning from Simulated and Unsupervised Images through Adversarial Training</a></li><li id="0406" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SisGAN — <a href="https://arxiv.org/abs/1707.06873" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semantic Image Synthesis via Adversarial Learning</a></li><li id="2094" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Sketcher-Refiner GAN — <a href="https://arxiv.org/abs/1804.08039" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Myelin Content in Multiple Sclerosis from Multimodal MRI through Adversarial Training</a></li><li id="75eb" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SketchGAN — <a href="https://arxiv.org/abs/1607.02748" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Adversarial Training For Sketch Retrieval</a></li><li id="bb1e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SketchyGAN — <a href="https://arxiv.org/abs/1801.02753" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis</a></li><li id="322f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Skip-Thought GAN — <a href="https://arxiv.org/abs/1808.08703" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating Text through Adversarial Training using Skip-Thought Vectors</a></li><li id="faa3" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SL-GAN — <a href="https://arxiv.org/abs/1704.02166" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semi-Latent GAN: Learning to generate and modify facial images from attributes</a></li><li id="8bff" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SLSR — <a href="https://arxiv.org/abs/1809.04976" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Sparse Label Smoothing for Semi-supervised Person Re-Identification</a></li><li id="8436" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SN-DCGAN — <a href="https://arxiv.org/abs/1806.00236" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Networks for Unsupervised Object Co-localization</a></li><li id="ce3e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SN-GAN — <a href="https://drive.google.com/file/d/0B8HZ50DPgR3eSVV6YlF3XzQxSjQ/view" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Spectral Normalization for Generative Adversarial Networks</a> (<a href="https://github.com/pfnet-research/chainer-gan-lib" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="7083" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SN-PatchGAN — <a href="https://arxiv.org/abs/1806.03589" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Free-Form Image Inpainting with Gated Convolution</a></li><li id="0e1e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Sobolev GAN — <a href="https://arxiv.org/abs/1711.04894" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Sobolev GAN</a></li><li id="5df5" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Social GAN — <a href="https://arxiv.org/abs/1803.10892" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks</a></li><li id="3e2a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Softmax GAN — <a href="https://arxiv.org/abs/1704.06191" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Softmax GAN</a></li><li id="3018" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SoPhie — <a href="https://arxiv.org/abs/1806.01482" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SoPhie: An Attentive GAN for Predicting Paths Compliant to Social and Physical Constraints</a></li><li id="b321" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">speech-driven animation GAN — <a href="https://arxiv.org/abs/1805.09313" class="ch dk jt ju jv jw" target="_blank" rel="noopener">End-to-End Speech-Driven Facial Animation with Temporal GANs</a></li><li id="d366" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Spike-GAN — <a href="https://arxiv.org/abs/1803.00338" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Synthesizing realistic neural population activity patterns using Generative Adversarial Networks</a></li><li id="863d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Splitting GAN — <a href="https://arxiv.org/abs/1709.07359" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Class-Splitting Generative Adversarial Networks</a></li><li id="e412" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SR-CNN-VAE-GAN — <a href="https://arxiv.org/abs/1806.00509" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semi-Recurrent CNN-based VAE-GAN for Sequential Data Generation</a> (<a href="https://github.com/makbari7/SR-CNN-VAE-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="b013" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SRGAN — <a href="https://arxiv.org/abs/1609.04802" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</a></li><li id="616a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SRPGAN — <a href="https://arxiv.org/abs/1712.05927" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SRPGAN: Perceptual Generative Adversarial Network for Single Image Super Resolution</a></li><li id="b6d2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SS-GAN — <a href="https://arxiv.org/abs/1708.05789" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semi-supervised Conditional GANs</a></li><li id="ee90" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ss-InfoGAN — <a href="https://arxiv.org/abs/1707.04487" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Guiding InfoGAN with Semi-Supervision</a></li><li id="3336" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SSGAN — <a href="https://arxiv.org/abs/1707.01613" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SSGAN: Secure Steganography Based on Generative Adversarial Networks</a></li><li id="9531" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SSL-GAN — <a href="https://arxiv.org/abs/1611.06430v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks</a></li><li id="1d4b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ST-CGAN — <a href="https://arxiv.org/abs/1712.02478" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal</a></li><li id="9edd" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ST-GAN — <a href="https://arxiv.org/abs/1702.06762" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Style Transfer Generative Adversarial Networks: Learning to Play Chess Differently</a></li><li id="d06b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ST-GAN — <a href="https://arxiv.org/abs/1803.01837" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing</a></li><li id="bdde" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">StackGAN — <a href="https://arxiv.org/abs/1612.03242v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks</a> (<a href="https://github.com/hanzhanggit/StackGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="d9bc" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">StainGAN — <a href="https://arxiv.org/abs/1804.01601" class="ch dk jt ju jv jw" target="_blank" rel="noopener">StainGAN: Stain Style Transfer for Digital Histological Images</a></li><li id="30ad" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">StarGAN — <a href="https://arxiv.org/abs/1711.09020" class="ch dk jt ju jv jw" target="_blank" rel="noopener">StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation</a> (<a href="https://github.com/yunjey/StarGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="589c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">StarGAN-VC — <a href="https://arxiv.org/abs/1806.02169" class="ch dk jt ju jv jw" target="_blank" rel="noopener">StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks</a></li><li id="cdb7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SteinGAN — <a href="https://arxiv.org/abs/1707.00797" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Learning Deep Energy Models: Contrastive Divergence vs. Amortized MLE</a></li><li id="564d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">StepGAN — <a href="https://arxiv.org/abs/1808.05599" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation</a></li><li id="8dba" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Super-FAN — <a href="https://arxiv.org/abs/1712.02765" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Super-FAN: Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANs</a></li><li id="b66e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SVSGAN — <a href="https://arxiv.org/abs/1710.11428" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SVSGAN: Singing Voice Separation via Generative Adversarial Network</a></li><li id="4c60" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SWGAN — <a href="https://arxiv.org/abs/1802.08249" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Solving Approximate Wasserstein GANs to Stationarity</a></li><li id="a35b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">SyncGAN — <a href="https://arxiv.org/abs/1804.00410" class="ch dk jt ju jv jw" target="_blank" rel="noopener">SyncGAN: Synchronize the Latent Space of Cross-modal Generative Adversarial Networks</a></li><li id="9072" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">S²GAN — <a href="https://arxiv.org/abs/1603.05631v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Image Modeling using Style and Structure Adversarial Networks</a></li><li id="86a8" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">T2Net — <a href="https://arxiv.org/abs/1808.01454" class="ch dk jt ju jv jw" target="_blank" rel="noopener">T2Net: Synthetic-to-Realistic Translation for Solving Single-Image Depth Estimation Tasks</a></li><li id="2c5a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">table-GAN — <a href="https://arxiv.org/abs/1806.03384" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Data Synthesis based on Generative Adversarial Networks</a></li><li id="6b8e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TAC-GAN — <a href="https://arxiv.org/abs/1703.06412v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">TAC-GAN — Text Conditioned Auxiliary Classifier Generative Adversarial Network</a> (<a href="https://github.com/dashayushman/TAC-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="bdc2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TAN — <a href="https://arxiv.org/abs/1704.08834" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Outline Colorization through Tandem Adversarial Networks</a></li><li id="d3d2" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">tcGAN — <a href="https://arxiv.org/abs/1806.05147" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Cross-modal Hallucination for Few-shot Fine-grained Recognition</a></li><li id="b49a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TD-GAN — <a href="https://arxiv.org/abs/1806.07201" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Task Driven Generative Modeling for Unsupervised Domain Adaptation: Application to X-ray Image Segmentation</a></li><li id="d6be" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">tempCycleGAN — <a href="https://arxiv.org/abs/1806.03627" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improving Surgical Training Phantoms by Hyperrealism: Deep Unpaired Image-to-Image Translation from Real Surgeries</a></li><li id="b230" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">tempoGAN — <a href="https://arxiv.org/abs/1801.09710" class="ch dk jt ju jv jw" target="_blank" rel="noopener">tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow</a></li><li id="0679" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TequilaGAN — <a href="https://arxiv.org/abs/1807.04919" class="ch dk jt ju jv jw" target="_blank" rel="noopener">TequilaGAN: How to easily identify GAN samples</a></li><li id="2c58" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Text2Shape — <a href="https://arxiv.org/abs/1803.08495" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings</a></li><li id="d65e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">textGAN — <a href="https://zhegan27.github.io/Papers/textGAN_nips2016_workshop.pdf" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating Text via Adversarial Training</a></li><li id="76cf" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TextureGAN — <a href="https://arxiv.org/abs/1706.02823" class="ch dk jt ju jv jw" target="_blank" rel="noopener">TextureGAN: Controlling Deep Image Synthesis with Texture Patches</a></li><li id="ec1f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TGAN — <a href="https://arxiv.org/abs/1611.06624v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Temporal Generative Adversarial Nets</a></li><li id="c716" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TGAN — <a href="https://arxiv.org/abs/1710.10772" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Tensorizing Generative Adversarial Nets</a></li><li id="3cda" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TGAN — <a href="https://arxiv.org/abs/1711.02666" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Tensor-Generative Adversarial Network with Two-dimensional Sparse Coding: Application to Real-time Indoor Localization</a></li><li id="d074" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TGANs-C — <a href="https://arxiv.org/abs/1804.08264" class="ch dk jt ju jv jw" target="_blank" rel="noopener">To Create What You Tell: Generating Videos from Captions</a></li><li id="795c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">tiny-GAN — <a href="https://arxiv.org/abs/1803.05045" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Analysis of Nonautonomous Adversarial Systems</a></li><li id="d908" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TP-GAN — <a href="https://arxiv.org/abs/1704.04086" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis</a></li><li id="8fee" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TreeGAN — <a href="https://arxiv.org/abs/1808.07582" class="ch dk jt ju jv jw" target="_blank" rel="noopener">TreeGAN: Syntax-Aware Sequence Generation with Generative Adversarial Networks</a></li><li id="3199" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Triple-GAN — <a href="https://arxiv.org/abs/1703.02291v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Triple Generative Adversarial Nets</a></li><li id="7d50" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">tripletGAN — <a href="https://arxiv.org/abs/1711.05084" class="ch dk jt ju jv jw" target="_blank" rel="noopener">TripletGAN: Training Generative Model with Triplet Loss</a></li><li id="56de" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">TV-GAN — <a href="https://arxiv.org/abs/1712.02514" class="ch dk jt ju jv jw" target="_blank" rel="noopener">TV-GAN: Generative Adversarial Network Based Thermal to Visible Face Recognition</a></li><li id="ac6e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Twin-GAN — <a href="https://arxiv.org/abs/1809.00946" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Twin-GAN — Unpaired Cross-Domain Image Translation with Weight-Sharing GANs</a></li><li id="30b7" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">UGACH — <a href="https://arxiv.org/abs/1712.00358" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Generative Adversarial Cross-modal Hashing</a></li><li id="ec50" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">UGAN — <a href="https://arxiv.org/abs/1801.04011" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Enhancing Underwater Imagery using Generative Adversarial Networks</a></li><li id="af56" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Unim2im — <a href="https://arxiv.org/abs/1701.02676" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Image-to-Image Translation with Generative Adversarial Networks </a>(<a href="http://github.com/zsdonghao/Unsup-Im2Im" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="dde0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">UNIT — <a href="https://arxiv.org/abs/1703.00848" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unsupervised Image-to-image Translation Networks</a> (<a href="https://github.com/mingyuliutw/UNIT" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="2c88" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Unrolled GAN — <a href="https://arxiv.org/abs/1611.02163" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Unrolled Generative Adversarial Networks</a> (<a href="https://github.com/poolio/unrolled_gan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="be6b" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">UT-SCA-GAN — <a href="https://arxiv.org/abs/1804.07939" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Spatial Image Steganography Based on Generative Adversarial Network</a></li><li id="4935" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">UV-GAN — <a href="https://arxiv.org/abs/1712.04695" class="ch dk jt ju jv jw" target="_blank" rel="noopener">UV-GAN: Adversarial Facial UV Map Completion for Pose-invariant Face Recognition</a></li><li id="e803" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VA-GAN — <a href="https://arxiv.org/abs/1711.08998" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Visual Feature Attribution using Wasserstein GANs</a></li><li id="823e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VAC+GAN — <a href="https://arxiv.org/abs/1806.07751" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Versatile Auxiliary Classifier with Generative Adversarial Network (VAC+GAN), Multi Class Scenarios</a></li><li id="aa48" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VAE-GAN — <a href="https://arxiv.org/abs/1512.09300" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Autoencoding beyond pixels using a learned similarity metric</a></li><li id="c5ca" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VariGAN — <a href="https://arxiv.org/abs/1704.04886" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Multi-View Image Generation from a Single-View</a></li><li id="a4f0" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VAW-GAN — <a href="https://arxiv.org/abs/1704.00849" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Voice Conversion from Unaligned Corpora using Variational Autoencoding Wasserstein Generative Adversarial Networks</a></li><li id="9b35" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VEEGAN — <a href="https://arxiv.org/abs/1705.07761" class="ch dk jt ju jv jw" target="_blank" rel="noopener">VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning</a> (<a href="https://github.com/akashgit/VEEGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="7ab4" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VGAN — <a href="https://arxiv.org/abs/1609.02612" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generating Videos with Scene Dynamics</a> (<a href="https://github.com/cvondrick/videogan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="d626" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VGAN — <a href="https://arxiv.org/abs/1611.01799" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Networks as Variational Training of Energy Based Models</a> (<a href="https://github.com/Shuangfei/vgan" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="812a" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VGAN — <a href="https://arxiv.org/abs/1712.00170" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Text Generation Based on Generative Adversarial Nets with Latent Variable</a></li><li id="9f4d" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ViGAN — <a href="https://arxiv.org/abs/1701.04568v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Image Generation and Editing with Variational Info Generative Adversarial Networks</a></li><li id="367f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VIGAN — <a href="https://arxiv.org/abs/1708.06724" class="ch dk jt ju jv jw" target="_blank" rel="noopener">VIGAN: Missing View Imputation with Generative Adversarial Networks</a></li><li id="8243" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VoiceGAN — <a href="http://arxiv.org/abs/1802.06840" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Voice Impersonation using Generative Adversarial Networks</a></li><li id="c874" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VOS-GAN — <a href="https://arxiv.org/abs/1803.09092" class="ch dk jt ju jv jw" target="_blank" rel="noopener">VOS-GAN: Adversarial Learning of Visual-Temporal Dynamics for Unsupervised Dense Prediction in Videos</a></li><li id="607f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">VRAL — <a href="https://arxiv.org/abs/1707.00309" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Variance Regularizing Adversarial Learning</a></li><li id="d9ad" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WaterGAN — <a href="https://arxiv.org/abs/1702.07392v1" class="ch dk jt ju jv jw" target="_blank" rel="noopener">WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images</a></li><li id="ffff" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WaveGAN — <a href="https://arxiv.org/abs/1802.04208" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Synthesizing Audio with Generative Adversarial Networks</a></li><li id="7914" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WaveletGLCA-GAN — <a href="https://arxiv.org/abs/1809.07764" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Global and Local Consistent Wavelet-domain Age Synthesis</a></li><li id="e4a6" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">weGAN — <a href="https://arxiv.org/abs/1712.09127" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Generative Adversarial Nets for Multiple Text Corpora</a></li><li id="24bd" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WGAN — <a href="https://arxiv.org/abs/1701.07875v2" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Wasserstein GAN</a> (<a href="https://github.com/martinarjovsky/WassersteinGAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="1789" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WGAN-CLS — <a href="https://arxiv.org/abs/1805.00676" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Text to Image Synthesis Using Generative Adversarial Networks</a></li><li id="306c" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WGAN-GP — <a href="https://arxiv.org/abs/1704.00028" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Improved Training of Wasserstein GANs</a> (<a href="https://github.com/igul222/improved_wgan_training" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="82cf" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WGAN-L1 — <a href="https://arxiv.org/abs/1807.04418" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Subsampled Turbulence Removal Network</a></li><li id="064f" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">WS-GAN — <a href="https://arxiv.org/abs/1705.10904" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Weakly Supervised Generative Adversarial Networks for 3D Reconstruction</a></li><li id="c249" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">X-GANs — <a href="https://arxiv.org/abs/1808.04432" class="ch dk jt ju jv jw" target="_blank" rel="noopener">X-GANs: Image Reconstruction Made Easy for Extreme Cases</a></li><li id="3083" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">XGAN — <a href="https://arxiv.org/abs/1711.05139" class="ch dk jt ju jv jw" target="_blank" rel="noopener">XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings</a></li><li id="324e" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">ZipNet-GAN — <a href="https://arxiv.org/abs/1711.02413" class="ch dk jt ju jv jw" target="_blank" rel="noopener">ZipNet-GAN: Inferring Fine-grained Mobile Traffic Patterns via a Generative Adversarial Neural Network</a></li><li id="1619" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">α-GAN — <a href="https://arxiv.org/abs/1706.04987" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Variational Approaches for Auto-Encoding Generative Adversarial Networks</a> (<a href="https://github.com/victor-shepardson/alpha-GAN" class="ch dk jt ju jv jw" target="_blank" rel="noopener">github</a>)</li><li id="08db" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">β-GAN — <a href="https://arxiv.org/abs/1705.07505" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Annealed Generative Adversarial Networks</a></li><li id="8aae" class="je jq cu bk jg b gl km jr gn kn js jj ko gy jl kp gz jn kq ha jp kj kk kl" data-selectable-paragraph="">Δ-GAN — <a href="https://arxiv.org/abs/1709.06548" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Triangle Generative Adversarial Networks</a></li></ul><p id="17ee" class="je jq cu bk jg b gl jh jr gn ji js jj jk gy jl jm gz jn jo ha jp fl" data-selectable-paragraph="">Visit the <a href="https://github.com/hindupuravinash/the-gan-zoo" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Github repository</a> to add more links via pull requests or create an issue to lemme know something I missed or to start a discussion. Thanks to all the contributors, especially <a href="https://github.com/Banus" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Emanuele Plebani</a>, <a href="https://github.com/lgalke" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Lukas Galke</a>, <a href="https://github.com/pwaller" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Peter Waller</a> and <a href="https://github.com/bgavran" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Bruno Gavranović</a>.</p></div></div></section><hr class="ka ep kb kc bz kd jb ke kf kg kh ki"><section class="fl fm fn fo fp"><div class="n p"><div class="z ab ac ae af fq ah ai"><p id="35d5" class="je jq cu bk jg b gl jh jr gn ji js jj jk gy jl jm gz jn jo ha jp fl" data-selectable-paragraph="">If you like what you are reading, follow <a href="https://deephunt.in/" class="ch dk jt ju jv jw" target="_blank" rel="noopener">Deep Hunt</a> — a weekly AI newsletter with special focus on Machine Learning to stay updated in this fast moving field.</p></div></div></section></div></article><div class="pe fk kr ks ai kz kx la" data-test-id="post-sidebar"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="lb n lc"><div class="uf"><div class="ld le r"><a href="https://deephunt.in/?source=post_sidebar--------------------------post_sidebar-" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener"><h2 class="bj du lf bl cu">Deep Hunt</h2></a><div class="lg lh r"><h4 class="bj ep cc bl bw li bv dy lj ea bo">Your weekly newsletter on the hottest things in Artificial…</h4></div><div class="by" aria-hidden="true"><button class="ct cv as at hp bc bd hq bb dg bj b bk bl bm bn dh di dj by dk be">Follow</button></div></div><div class="lk ll lm n"><div class="n o"><div class="r ce ln lo lp lq lr"><div class=""><button class="az ls lt lu lv lw lx ly q lz ma"><svg width="29" height="29"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r mb mc md me mf mg mh"><div class="mi"><h4 class="bj ep cc bl bo"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm">1.6K </button></h4></div></div></div></div><div class="ll r"></div><div><div class="ic"><div><div class="by" role="tooltip" aria-hidden="true" aria-describedby="2" aria-labelledby="2"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div><div class="pe uf kr ks kt ku kv kw kx ky"></div><div><div class="mj ik n lc p"><div class="n p"><div class="z ab ac ae af fq ah ai"><div class="n mk"></div><div class="n o mk"></div><div class="ml r"><ul class="az ba"><li class="by ee ib mm"><a href="https://deephunt.in/tagged/machine-learning" class="mn mo dk bo r mp mq a b eq">Machine Learning</a></li><li class="by ee ib mm"><a href="https://deephunt.in/tagged/artificial-intelligence" class="mn mo dk bo r mp mq a b eq">Artificial Intelligence</a></li><li class="by ee ib mm"><a href="https://deephunt.in/tagged/deep-learning" class="mn mo dk bo r mp mq a b eq">Deep Learning</a></li><li class="by ee ib mm"><a href="https://deephunt.in/tagged/technology" class="mn mo dk bo r mp mq a b eq">Technology</a></li><li class="by ee ib mm"><a href="https://deephunt.in/tagged/neural-networks" class="mn mo dk bo r mp mq a b eq">Neural Networks</a></li></ul></div><div class="mr n hc y"><div class="n ms"><div class="mt r"><div class="n o"><div class="r ce mu mv mw mx my"><div class=""><div class="c mz dn n o na ce nb nc nd ne nf ng nh ni nj nk nl nm nn no"><button class="az ls lt lu lv lw np ly o iz dn n p nq u ip s t ai q lz ma nr"><svg width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="r mb mc md me mf mg mh"><div class="ce ns mi"><h4 class="bj ep cc bl cu"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm">1.6K claps</button></h4></div></div></div></div><div class="r nt nu nv nw nx"></div></div><div class="n o"><div class="ia r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></button></div><div class="ia r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="ia r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></button></div><div class="ny r bi"><div><div class="ic"><div><div class="by" role="tooltip" aria-hidden="true" aria-describedby="3" aria-labelledby="3"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="by" aria-hidden="true"><div class="by" aria-hidden="true"><div class="r bi"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="q"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div><div class="nz oa ob ml r oc y"><div class="r g"><div class="od oe r ce"><span class="r of al og"><div class="r s oh oi"><a href="https://deephunt.in/@hindupuravinash?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="Avinash Hindupur" class="r dn ek oj" src="./The GAN Zoo - Deep Hunt_files/0_5q7vZAHEK04LVoU4(1).jpeg" width="80" height="80"></a></div><span class="r"><div class="ok r ol"><p class="bj ep eq bl bo es om">Written by</p></div><div class="ok on n ol"><div class="ai n o hc"><h2 class="bj du kb oo cu"><a href="https://deephunt.in/@hindupuravinash?source=follow_footer--------------------------follow_footer-" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener">Avinash Hindupur</a></h2><div class="r g"><button class="ct cv as at hp bc bd hq bb dg bj b bk bl bm bn dh di dj by dk be">Follow</button></div></div></div></span></span><div class="ok op r ol ar"><div class="oq r"><h4 class="bj ep lf or bo">Dreamer, @iitguwahati alum. Creator of @deephunt_in, Organiser @ DeepLearningDelhi | Interested in all things data and machine learning.</h4></div><div class="aq os ar"><button class="ct cv as at hp bc bd hq bb dg bj b bk bl bm bn dh di dj by dk be">Follow</button></div></div></div><div class="nz r"></div><div class="od oe r ce"><span class="r of al og"><div class="r s oh oi"><a href="https://deephunt.in/?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="Deep Hunt" class="dg oj ek" src="./The GAN Zoo - Deep Hunt_files/1_6yx91P_l0phituLnYOK7Jw.png" width="80" height="80"></a></div><span class="r"><div class="ok on n ol"><div class="ai n o hc"><h2 class="bj du kb oo cu"><a href="https://deephunt.in/?source=follow_footer--------------------------follow_footer-" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener">Deep Hunt</a></h2><div class="r g"><div class="by" aria-hidden="true"><button class="ct cv as at hp bc bd hq bb dg bj b bk bl bm bn dh di dj by dk be">Follow</button></div></div></div></div></span></span><div class="ok ot r ol ar"><div class="oq r"><h4 class="bj ep lf or bo">Your weekly newsletter on the hottest things in Artificial Intelligence carefully curated by Avinash Hindupur!</h4></div><div class="aq os ar"><div class="by" aria-hidden="true"><button class="ct cv as at hp bc bd hq bb dg bj b bk bl bm bn dh di dj by dk be">Follow</button></div></div></div></div></div><div class="aq ar"><div class="ou r"><div class="n ms"><div class="ov r"><a href="https://deephunt.in/@hindupuravinash?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="Avinash Hindupur" class="r dn ow ox" src="./The GAN Zoo - Deep Hunt_files/0_5q7vZAHEK04LVoU4(2).jpeg" width="40" height="40"></a></div><div class="hi r"><p class="bj ep oy oz bo es om">Written by</p><div class="n ms"><h2 class="bj du lf bl cu"><a href="https://deephunt.in/@hindupuravinash?source=follow_footer--------------------------follow_footer-" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener">Avinash Hindupur</a></h2><div class="hi r"><button class="ho cv as at hp bc bd hq bb dg bj b bk hr eq bn dh di dj by dk be">Follow</button></div></div><div class="pa r"><h4 class="bj ep cc bl bo">Dreamer, @iitguwahati alum. Creator of @deephunt_in, Organiser @ DeepLearningDelhi | Interested in all things data and machine learning.</h4></div></div></div><div class="ou r"><div class="n ms"><a href="https://deephunt.in/?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="Deep Hunt" class="dg ox ow" src="./The GAN Zoo - Deep Hunt_files/1_6yx91P_l0phituLnYOK7Jw(1).png" width="40" height="40"></a><div class="hi r"><div class="n ms"><h2 class="bj du lf bl cu"><a href="https://deephunt.in/?source=follow_footer--------------------------follow_footer-" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener">Deep Hunt</a></h2><div class="hi r"><div class="by" aria-hidden="true"><button class="ho cv as at hp bc bd hq bb dg bj b bk hr eq bn dh di dj by dk be">Follow</button></div></div></div><div class="pa r"><h4 class="bj ep cc bl bo">Your weekly newsletter on the hottest things in Artificial Intelligence carefully curated by Avinash Hindupur!</h4></div></div></div></div></div></div></div><div class="pb oa r oc pc y"><a href="https://medium.com/p/79597dc8c347/responses/show?source=follow_footer--------------------------follow_footer-" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm" rel="noopener"><span class="pd pe lv"><div class="pf pg dg r jb ar"><span class="as">See responses (11)</span></div></span></a></div></div></div><div class="ph r pi y"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="rd r re"><div class="qt le od r"><h2 class="bj du dv dw cu">More From Medium</h2></div><div class="eh n ms mk rf rg rh ri rj rk rl rm rn ro rp rq rr rs rt"><div class="ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so"><div class="ai ip"><div class="r sp"><div class="sq sr rf rg rh ss st ri rj rk su sv rl rm rn sw sx ro rp rq sy sz rr rs rt n mk"><div class="ru rv rw rx ry rz ta tb sc sd tc td sg sh te tf sk sl tg th so"><div class="ti r tj f"><h4 class="bj ep cc bl bo">Also tagged Deep Learning</h4></div><div class="bs r tk re"><a href="https://towardsdatascience.com/from-lenet-to-efficientnet-the-evolution-of-cnns-3a57eb34672f?source=post_recirc---------0------------------" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm r" rel="noopener"><div class="ts ce"><div class="ip s ai"><div class="ty r tu tv ip ai tw tx"></div></div></div></a></div></div><div class="ru rv rw rx ry rz ta tb sc sd tc td sg sh te tf sk sl tg th so"><div class="bs r"><div class="tl aq h tm"><h4 class="bj ep cc bl bo">Also tagged Deep Learning</h4></div><a href="https://towardsdatascience.com/from-lenet-to-efficientnet-the-evolution-of-cnns-3a57eb34672f?source=post_recirc---------0------------------" rel="noopener"><h3 class="cu q ft b bk tn to tp">From LeNet to EfficientNet: The evolution of CNNs</h3></a></div><div class="n o hc"><div class="cn r ed"><div class="o n"><div><a href="https://deephunt.in/@prakhargannu?source=post_recirc---------0------------------" rel="noopener"><img alt="Prakhar Ganesh" class="r dn ow ox" src="./The GAN Zoo - Deep Hunt_files/1_bg0efO7dij0nkGgSdHkWew.jpeg" width="40" height="40"></a></div><div class="hi ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bj b bk bl bm bn r cu q"><div class="ey n o hk"><span class="bj ep cc bl bw hl bv dy dz ea cu"><a href="https://deephunt.in/@prakhargannu?source=post_recirc---------0------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Prakhar Ganesh</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------0------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bj b bk bl bm bn r bo bp"><span class="bj ep cc bl bw hl bv dy dz ea bo"><div><a href="https://towardsdatascience.com/from-lenet-to-efficientnet-the-evolution-of-cnns-3a57eb34672f?source=post_recirc---------0------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Jun 8</a> · 7 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r ce ln lo lp lq lr"><div class=""><button class="az ls lt lu lv lw lx ra q lz ma"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r mb mc md me mf mg mh"><div class="mi"><h4 class="bj ep cc bl bo">6</h4></div></div></div><div class="tq hi cn el tr r"></div><div class="ic"><div><div class="by" role="tooltip" aria-hidden="true" aria-describedby="14" aria-labelledby="14"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><div class="ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so"><div class="ai ip"><div class="r sp"><div class="sq sr rf rg rh ss st ri rj rk su sv rl rm rn sw sx ro rp rq sy sz rr rs rt n mk"><div class="ru rv rw rx ry rz ta tb sc sd tc td sg sh te tf sk sl tg th so"><div class="ti r tj f"><h4 class="bj ep cc bl bo">Related reads</h4></div><div class="bs r tk re"><a href="https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737?source=post_recirc---------1------------------" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm r" rel="noopener"><div class="ts ce"><div class="ip s ai"><div class="tt r tu tv ip ai tw tx"></div></div></div></a></div></div><div class="ru rv rw rx ry rz ta tb sc sd tc td sg sh te tf sk sl tg th so"><div class="bs r"><div class="tl aq h tm"><h4 class="bj ep cc bl bo">Related reads</h4></div><a href="https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737?source=post_recirc---------1------------------" rel="noopener"><h3 class="cu q ft b bk tn to tp">A New Way to look at GANs</h3></a></div><div class="n o hc"><div class="cn r ed"><div class="o n"><div><a href="https://deephunt.in/@marco.pasini?source=post_recirc---------1------------------" rel="noopener"><img alt="Marco Pasini" class="r dn ow ox" src="./The GAN Zoo - Deep Hunt_files/0_Y9BzSH3IboTAW3nq.jpg" width="40" height="40"></a></div><div class="hi ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bj b bk bl bm bn r cu q"><div class="ey n o hk"><span class="bj ep cc bl bw hl bv dy dz ea cu"><a href="https://deephunt.in/@marco.pasini?source=post_recirc---------1------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Marco Pasini</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------1------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bj b bk bl bm bn r bo bp"><span class="bj ep cc bl bw hl bv dy dz ea bo"><div><a href="https://towardsdatascience.com/a-new-way-to-look-at-gans-7c6b6e6e9737?source=post_recirc---------1------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">May 20, 2019</a> · 9 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r ce ln lo lp lq lr"><div class=""><button class="az ls lt lu lv lw lx ra q lz ma"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r mb mc md me mf mg mh"><div class="mi"><h4 class="bj ep cc bl bo">272</h4></div></div></div><div class="tq hi cn el tr r"></div><div class="ic"><div><div class="by" role="tooltip" aria-hidden="true" aria-describedby="15" aria-labelledby="15"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><div class="ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so"><div class="ai ip"><div class="r sp"><div class="sq sr rf rg rh ss st ri rj rk su sv rl rm rn sw sx ro rp rq sy sz rr rs rt n mk"><div class="ru rv rw rx ry rz ta tb sc sd tc td sg sh te tf sk sl tg th so"><div class="ti r tj f"><h4 class="bj ep cc bl bo">Related reads</h4></div><div class="bs r tk re"><a href="https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d?source=post_recirc---------2------------------" class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm r" rel="noopener"><div class="ts ce"><div class="ip s ai"><div class="tz r tu tv ip ai tw tx"></div></div></div></a></div></div><div class="ru rv rw rx ry rz ta tb sc sd tc td sg sh te tf sk sl tg th so"><div class="bs r"><div class="tl aq h tm"><h4 class="bj ep cc bl bo">Related reads</h4></div><a href="https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d?source=post_recirc---------2------------------" rel="noopener"><h3 class="cu q ft b bk tn to tp">CycleGAN: Learning to Translate Images (Without Paired Training Data)</h3></a></div><div class="n o hc"><div class="cn r ed"><div class="o n"><div><a href="https://deephunt.in/@sarah.wolf32?source=post_recirc---------2------------------" rel="noopener"><div class="ce ox ow"><div class="ua n ms o p s ub uc ud ku ue fk"><svg width="49" height="49" viewBox="0 0 49 49"><path fill-rule="evenodd" clip-rule="evenodd" d="M24.5 1.1c-9.39 0-17.53 5.55-21.51 13.66L2 14.28C6.15 5.82 14.66 0 24.5 0S42.85 5.82 47 14.28l-.99.48C42.03 6.65 33.9 1.1 24.5 1.1zM2.99 34.24C6.97 42.35 15.1 47.9 24.5 47.9c9.39 0 17.53-5.55 21.51-13.66l.99.48C42.85 43.18 34.34 49 24.5 49S6.15 43.18 2 34.72l.99-.48z"></path></svg></div><img alt="Sarah Wolf" class="r dn ow ox" src="./The GAN Zoo - Deep Hunt_files/1_NJ8sdXHHw2PNPF0TXqQoAw.jpeg" width="40" height="40"></div></a></div><div class="hi ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bj b bk bl bm bn r cu q"><div class="ey n o hk"><span class="bj ep cc bl bw hl bv dy dz ea cu"><a href="https://deephunt.in/@sarah.wolf32?source=post_recirc---------2------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Sarah Wolf</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------2------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bj b bk bl bm bn r bo bp"><span class="bj ep cc bl bw hl bv dy dz ea bo"><div><a href="https://towardsdatascience.com/cyclegan-learning-to-translate-images-without-paired-training-data-5b4e93862c8d?source=post_recirc---------2------------------" class="ch ci au av aw ax ay az ba bb hm be bf cl cm" rel="noopener">Nov 20, 2018</a> · 7 min read</div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r ce ln lo lp lq lr"><div class=""><button class="az ls lt lu lv lw lx ra q lz ma"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r mb mc md me mf mg mh"><div class="mi"><h4 class="bj ep cc bl bo">1K</h4></div></div></div><div class="tq hi cn el tr r"></div><div class="ic"><div><div class="by" role="tooltip" aria-hidden="true" aria-describedby="16" aria-labelledby="16"><button class="ch ci au av aw ax ay az ba bb cj ck be bf cl cm"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="pj r pk pl"><section class="fe ff ai dj r pm pn po pp pq pr ps pt pu pv pw px py pz qa"><div class="qb qc od n hc g"><div class="qd n hc"><div class="qe r qf"><div class="qg r"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb qh qi be bf qj qk" rel="noopener"><h4 class="ql qm qn bj du bk or qo qp r">Discover <!-- -->Medium</h4></a></div><span class="bj b bk bl bm bn r qq qr">Welcome to a place where words matter. On <!-- -->Medium<!-- -->, smart voices and original ideas take center stage - with no ads in sight.<!-- --> <a href="https://medium.com/about?autoplay=1&amp;source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb be bf qj qk qs" rel="noopener">Watch</a></span></div><div class="qe r qf"><div class="qt r"><a href="https://medium.com/topics?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb qh qi be bf qj qk" rel="noopener"><h4 class="ql qm qn bj du bk or qo qp r">Make <!-- -->Medium<!-- --> yours</h4></a></div><span class="bj b bk bl bm bn r qq qr">Follow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox.<!-- --> <a href="https://medium.com/topics?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb be bf qj qk qs" rel="noopener">Explore</a></span></div><div class="qe r qf"><div class="qg r"><a href="https://medium.com/membership?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb qh qi be bf qj qk" rel="noopener"><h4 class="ql qm qn bj du bk or qo qp r">Become a member</h4></a></div><span class="bj b bk bl bm bn r qq qr">Get unlimited access to the best stories on <!-- -->Medium<!-- --> — and support writers while you’re at it. Just $5/month.<!-- --> <a href="https://medium.com/membership?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb be bf qj qk qs" rel="noopener">Upgrade</a></span></div></div></div><div class="n lc"><div class="n o hc"><a href="https://medium.com/?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb qh qi be bf qj qk" rel="noopener"><svg height="22" width="112" viewBox="0 0 111.5 22" class="qm"><path d="M56.3 19.5c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5V19c-.7 1.8-2.4 3-4.3 3-3.3 0-5.8-2.6-5.8-7.5 0-4.5 2.6-7.6 6.3-7.6 1.6-.1 3.1.8 3.8 2.4V3.2c0-.3-.1-.6-.3-.7l-1.4-1.4V1l6.5-.8v19.3zm-4.8-.8V9.5c-.5-.6-1.2-.9-1.9-.9-1.6 0-3.1 1.4-3.1 5.7 0 4 1.3 5.4 3 5.4.8.1 1.6-.3 2-1zm9.1 3.1V9.4c0-.3-.1-.6-.3-.7l-1.4-1.5v-.1h6.5v12.5c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5zm-.2-19.2C60.4 1.2 61.5 0 63 0c1.4 0 2.6 1.2 2.6 2.6S64.4 5.3 63 5.3a2.6 2.6 0 0 1-2.6-2.7zm22.5 16.9c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5v-3.2c-.6 2-2.4 3.4-4.5 3.4-2.9 0-4.4-2.1-4.4-6.2 0-1.9 0-4.1.1-6.5 0-.3-.1-.5-.3-.7L67.7 7v.1H74v8c0 2.6.4 4.4 2 4.4.9-.1 1.7-.6 2.1-1.3V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v12.4zm22 2.3c0-.5.1-6.5.1-7.9 0-2.6-.4-4.5-2.2-4.5-.9 0-1.8.5-2.3 1.3.2.8.3 1.7.3 2.5 0 1.8-.1 4.2-.1 6.5 0 .3.1.5.3.7l1.5 1.4v.1H96c0-.4.1-6.5.1-7.9 0-2.7-.4-4.5-2.2-4.5-.9 0-1.7.5-2.2 1.3v9c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v3.1a4.6 4.6 0 0 1 4.6-3.4c2.2 0 3.6 1.2 4.2 3.5.7-2.1 2.7-3.6 4.9-3.5 2.9 0 4.5 2.2 4.5 6.2 0 1.9-.1 4.2-.1 6.5-.1.3.1.6.3.7l1.4 1.4v.1h-6.6zm-81.4-2l1.9 1.9v.1h-9.8v-.1l2-1.9c.2-.2.3-.4.3-.7V7.3c0-.5 0-1.2.1-1.8L11.4 22h-.1L4.5 6.8c-.1-.4-.2-.4-.3-.6v10c-.1.7 0 1.3.3 1.9l2.7 3.6v.1H0v-.1L2.7 18c.3-.6.4-1.3.3-1.9v-11c0-.5-.1-1.1-.5-1.5L.7 1.1V1h7l5.8 12.9L18.6 1h6.8v.1l-1.9 2.2c-.2.2-.3.5-.3.7v15.2c0 .2.1.5.3.6zm7.6-5.9c0 3.8 1.9 5.3 4.2 5.3 1.9.1 3.6-1 4.4-2.7h.1c-.8 3.7-3.1 5.5-6.5 5.5-3.7 0-7.2-2.2-7.2-7.4 0-5.5 3.5-7.6 7.3-7.6 3.1 0 6.4 1.5 6.4 6.2v.8h-8.7zm0-.8h4.3v-.8c0-3.9-.8-4.9-2-4.9-1.4.1-2.3 1.6-2.3 5.7z"></path></svg></a><span class="bj b bk bl bm bn r qq qr"><div class="pa qu n hc qv al"><h4 class="bj ep lf or ql"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb hm be bf qj qk" rel="noopener">About</a></h4><h4 class="bj ep lf or ql"><a href="https://help.medium.com/?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb hm be bf qj qk" rel="noopener">Help</a></h4><h4 class="bj ep lf or ql"><a href="https://medium.com/policy/9db0094a1e0f?source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb hm be bf qj qk" rel="noopener">Legal</a></h4></div></span></div><div class="aq qw qx al"><h4 class="bj ep lf or qq">Get the Medium app</h4></div><div class="aq qw qy al qz"><div class="cr r"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb qh qi be bf qj qk" rel="noopener"><img alt="A button that says &#39;Download on the App Store&#39;, and if clicked it will lead you to the iOS App store" class="" src="./The GAN Zoo - Deep Hunt_files/1_M2FVPPidy2x386MRAE-EeA.png" width="135" height="41"></a></div><div class="r"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----79597dc8c347----------------------" class="ch ci au av aw ax ay az ba bb qh qi be bf qj qk" rel="noopener"><img alt="A button that says &#39;Get it on, Google Play&#39;, and if clicked it will lead you to the Google Play store" class="" src="./The GAN Zoo - Deep Hunt_files/1_HyH8oIcJvXp7xzu5oF6dTg.png" width="135" height="41"></a></div></div></div></section></div></div></div><script>window.__BUILD_ID__ = "master-20200608-161640-e72b368906"</script><script>window.__GRAPHQL_URI__ = "https://deephunt.in/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"config":{"nodeEnv":"production","version":"master-20200608-161640-e72b368906","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"master-20200608-161640-e72b368906"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"master-20200608-161640-e72b368906","commit":"e72b36890674054ae1d405e91901b62f6552a6f0"}},"datacenter":"us"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"webpMiroImageIds":["1*y7gegIZOYlsnhWFJwIyDJw","1*ByGRQD1zlYXGS4YBYAoLVA","1*orNowUCqCER-BwaAXOZx0A","1*itOsotYFripvvRKY1itrVQ","1*b_LB1ifqWQ2x3JG_m3MJsg","1*AD7jcqVRun0Hhwmg0-Vqfg","1*0kJoJveqoxkYXEmdM2FZ3A","1*pTq8R2lALVUytg_k4y5CpQ","1*1_tSnwIHb_oPsU9vucJijQ","1*EBN0PWXjvaF2gRdk9fCvzA","1*Uxc2_wlnoVQNMQUhQaLVZg","1*ABOw4ARUQ90kwKfXqeVdXA","1*Ok2A1h7LmAtYjWVG9c8IMA","1*Kw1AUMFyy3AGJ1BbTdeyWg","1*2RZldaiJQXadc5zjscYncg","1*hPIJUpxe2QMvOMNcTlnOlQ","1*MZyvxFpPUvfBUfoNvFhRzg","1*2ROzqt2hXcYs6BuKjG2_nQ","1*NO9eMccT-vPrY8nylJ4PVw","2*6cf2Ep3P-r1vCrc-6Bc-vA","1*hVxgUA6kP-PgL5TJjuyePg","1*VGtACZSU6AxT3ugiNr-WGg","0*8dBf1Vy9mkDdcuwQ","1*5ciI2lDFX8sJanIJa6ppnA","1*Hqtfw2Juvf6Zb9uGimLLMg","1*suPSqLiNrJPCUbtdUwLnGw","1*dIANAeHtMxPlVO9awEN0Jw","1*N2KcM3GCLymsKxnSBXyG_g","1*fgNVzsUlPl9tA8ladAT-KA","1*h-La0GVOrPo6SrFpNWQLtw","1*3IPJZVYg-95RkV8H4DRjvA","1*DgnF3PmTVG14Oz_-8BWX_g","1*x_SKDZtUCcWMH9FB092srw","1*oQ4U4pCo7OUPMXXphwqzTg","1*fjC3jxxcmOwXLwqxraNHfw","1*DXy0NEVftDaLKDVG8dS3YQ","1*KbxEajPgdT9GhcWWGG8JmQ","1*e6oTrX0jQU0lPM_0Tt-oYw","1*oQ4U4pCo7OUPMXXphwqzTg","1*5I_5X9Of8dwLfLEwJWd9jA","1*wYUZRoGUFOj1kdT7R8S0TQ","1*dzn6a448FO7kqbXk2K1qiA","1*YQDEXca6FZq-9L5WXBH-3A","1*YlpXJYsNOORiPqY0Rx6zIQ","1*NM3ybm1NGbyvF_IGL5DPYQ","1*DJ36tR2MtLrCRA1BO62L8Q","1*wV6yqGmy-aGNGWt1paWy5g","0*iWmcqANWK8Ayo6NP","0*nB8YhFfPe8q0sJcJ","0*GN_xV2uMHSeGuotv","0*oT1BmxuFNEyN0XC4","0*Aow5I0AXoM8HG4RA","0*geqIA7abXJGEobLr"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*3sela1OADrJr7dJk_CXaEQ.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"performanceTags":[],"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":["pandemic","epidemic","coronavirus","covid19","co-vid-19","containment","self-care","flatten-the-curve","public-health","virus","public-health-crisis","quarantine","self-quarantine","zika","corona","disease-prevention","wuhan","chinavirus","outbreak","influenza","socialdistancing","social-distance","flu","vaccines","healthcare","medicine","conspiracy-theories","conspiracy","virality","epidemia","pandemia","salud","corona-e-virus","coronavirus-covid19","covid-19","covid-19-symptoms","covid-19-crisis","covid-19-testing","covid-19-treatment","coronavirus-update","coronavirus-diaries"],"COVID_APPLICABLE_TOPIC_NAMES":["coronavirus"],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":["coronavirus","health"],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4"},"debug":{"requestId":"a964b5a6-e86d-4ade-b728-7fa88a2c13fc","edge":"","originalSpanCarrier":{"ot-tracer-spanid":"648b3eec669150ce","ot-tracer-traceid":"0dc4cdc714678cfa","ot-tracer-sampled":"true"}},"session":{"user":{"id":"ecd8844b0d2e"},"xsrf":"JhafL0O2OdUx","isSpoofed":false},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fdeephunt.in\u002Fthe-gan-zoo-79597dc8c347","host":"deephunt.in","hostname":"deephunt.in","referrer":"https:\u002F\u002Fwww.google.com\u002F","susiModal":{"step":null,"operation":"register"},"postRead":false},"client":{"isBot":false,"isCustomDomain":true,"isEu":false,"isNativeMedium":false,"isSafariMobile":false,"inAppBrowserName":"","supportsWebp":true},"multiVote":{"clapsPerPost":{}},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY.variantFlags.0":{"name":"add_friction_to_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.0.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.0.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.1":{"name":"allow_access","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.1.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.1.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.2":{"name":"allow_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.2.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.2.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.3":{"name":"allow_test_auth","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.3.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.3.valueType":{"__typename":"VariantFlagString","value":"disallow"},"ROOT_QUERY.variantFlags.4":{"name":"assign_default_topic_to_posts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.4.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.4.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.5":{"name":"available_annual_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.5.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.5.valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"},"ROOT_QUERY.variantFlags.6":{"name":"available_monthly_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.6.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.6.valueType":{"__typename":"VariantFlagString","value":"60e220181034"},"ROOT_QUERY.variantFlags.7":{"name":"bane_add_user","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.7.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.7.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.8":{"name":"branch_seo_metadata","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.8.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.8.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.9":{"name":"browsable_stream_config_bucket","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.9.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.9.valueType":{"__typename":"VariantFlagString","value":"curated-topics"},"ROOT_QUERY.variantFlags.10":{"name":"coronavirus_topic_recirc","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.10.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.10.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.11":{"name":"covid_19_cdc_banner","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.11.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.11.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.12":{"name":"disable_android_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.12.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.12.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.13":{"name":"disable_gosocial_followers_that_you_follow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.13.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.13.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.14":{"name":"disable_ios_resume_reading_toast","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.14.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.14.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.15":{"name":"disable_ios_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.15.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.15.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.16":{"name":"disable_mobile_featured_chunk","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.16.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.16.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.17":{"name":"disable_post_recommended_from_friends_provider","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.17.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.17.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.18":{"name":"enable_alternate_onboarding_email_subject","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.18.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.18.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.19":{"name":"enable_android_local_currency","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.19.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.19.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.20":{"name":"enable_annual_renewal_reminder_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.20.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.20.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.21":{"name":"enable_app_flirty_thirty","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.21.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.21.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.22":{"name":"enable_apple_sign_in","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.22.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.22.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.23":{"name":"enable_aurora_opt_in_control","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.23.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.23.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.24":{"name":"enable_automated_mission_control_triggers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.24.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.24.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.25":{"name":"enable_braintree_integration","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.25.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.25.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.26":{"name":"enable_braintree_webhook","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.26.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.26.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.27":{"name":"enable_branch_io","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.27.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.27.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.28":{"name":"enable_branding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.28.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.28.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.29":{"name":"enable_branding_fonts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.29.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.29.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.30":{"name":"enable_cc_trial_member_onboarding_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.30.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.30.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.31":{"name":"enable_cleansweep_cachev2_reads","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.31.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.31.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.32":{"name":"enable_cleansweep_double_writes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.32.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.32.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.33":{"name":"enable_confirm_sign_in","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.33.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.33.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.34":{"name":"enable_cta_meter","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.34.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.34.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.35":{"name":"enable_curation_priority_queue_experiment","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.35.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.35.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.36":{"name":"enable_dedicated_series_tab_api_ios","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.36.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.36.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.37":{"name":"enable_different_grid","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.37.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.37.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.38":{"name":"enable_digest_feature_logging","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.38.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.38.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.39":{"name":"enable_digest_tagline","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.39.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.39.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.40":{"name":"enable_disregard_trunc_state_for_footer","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.40.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.40.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.41":{"name":"enable_edit_alt_text","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.41.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.41.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.42":{"name":"enable_email_sign_in_captcha","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.42.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.42.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.43":{"name":"enable_embedding_based_diversification","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.43.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.43.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.44":{"name":"enable_end_of_post_cleanup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.44.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.44.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.45":{"name":"enable_expanded_feature_chunk_pool","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.45.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.45.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.46":{"name":"enable_filter_by_resend_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.46.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.46.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.47":{"name":"enable_filter_expire_processor","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.47.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.47.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.48":{"name":"enable_first_name_on_paywall","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.48.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.48.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.49":{"name":"enable_footer_app_buttons","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.49.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.49.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.50":{"name":"enable_free_corona_topic","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.50.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.50.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.51":{"name":"enable_global_susi_modal","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.51.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.51.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.52":{"name":"enable_google_one_tap","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.52.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.52.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.53":{"name":"enable_highlander_member_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.53.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.53.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.54":{"name":"enable_icelandic_truncated_posts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.54.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.54.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.55":{"name":"enable_ios_post_stats","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.55.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.55.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.56":{"name":"enable_janky_spam_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.56.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.56.valueType":{"__typename":"VariantFlagString","value":"users,posts"},"ROOT_QUERY.variantFlags.57":{"name":"enable_json_logs_trained_ranker","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.57.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.57.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.58":{"name":"enable_kafka_events","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.58.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.58.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.59":{"name":"enable_kbfd_rex","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.59.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.59.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.60":{"name":"enable_kbfd_rex_app_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.60.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.60.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.61":{"name":"enable_kbfd_rex_daily_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.61.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.61.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.62":{"name":"enable_li_open_in_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.62.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.62.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.63":{"name":"enable_lite_about_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.63.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.63.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.64":{"name":"enable_lite_notifications","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.64.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.64.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.65":{"name":"enable_lite_post","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.65.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.65.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.66":{"name":"enable_lite_post_cd","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.66.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.66.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.67":{"name":"enable_lite_post_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.67.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.67.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.68":{"name":"enable_lite_post_highlights_view_only","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.68.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.68.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.69":{"name":"enable_lite_profile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.69.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.69.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.70":{"name":"enable_lite_pub_header_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.70.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.70.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.71":{"name":"enable_lite_pub_homepage_for_selected_domains","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.71.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.71.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.72":{"name":"enable_lite_server_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.72.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.72.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.73":{"name":"enable_lite_stories","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.73.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.73.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.74":{"name":"enable_lite_topics","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.74.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.74.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.75":{"name":"enable_lite_unread_notification_count_mutation","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.75.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.75.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.76":{"name":"enable_lo_open_in_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.76.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.76.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.77":{"name":"enable_login_code_flow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.77.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.77.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.78":{"name":"enable_m2_unviewable_filter","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.78.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.78.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.79":{"name":"enable_marketing_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.79.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.79.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.80":{"name":"enable_media_resource_try_catch","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.80.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.80.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.81":{"name":"enable_membership_remove_section_a","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.81.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.81.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.82":{"name":"enable_miro_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.82.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.82.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.83":{"name":"enable_ml_rank_modules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.83.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.83.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.84":{"name":"enable_ml_rank_rex_anno","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.84.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.84.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.85":{"name":"enable_monthly_member_onboarding_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.85.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.85.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.86":{"name":"enable_more_on_coronavirus","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.86.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.86.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.87":{"name":"enable_mute","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.87.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.87.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.88":{"name":"enable_new_collaborative_filtering_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.88.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.88.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.89":{"name":"enable_new_suspended_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.89.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.89.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.90":{"name":"enable_new_three_dot_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.90.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.90.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.91":{"name":"enable_newsletter_v3","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.91.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.91.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.92":{"name":"enable_olsen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.92.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.92.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.93":{"name":"enable_open_in_app_regwall","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.93.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.93.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.94":{"name":"enable_optimizely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.94.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.94.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.95":{"name":"enable_orion","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.95.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.95.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.96":{"name":"enable_parsely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.96.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.96.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.97":{"name":"enable_patronus_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.97.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.97.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.98":{"name":"enable_popularity_feature","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.98.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.98.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.99":{"name":"enable_post_import","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.99.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.99.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.100":{"name":"enable_post_page_nav_stickiness_removal","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.100.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.100.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.101":{"name":"enable_post_seo_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.101.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.101.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.102":{"name":"enable_post_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.102.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.102.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.103":{"name":"enable_primary_topic_for_mobile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.103.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.103.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.104":{"name":"enable_responses_2","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.104.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.104.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.105":{"name":"enable_rito_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.105.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.105.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.106":{"name":"enable_rtr_channel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.106.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.106.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.107":{"name":"enable_save_to_medium","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.107.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.107.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.108":{"name":"enable_sepia_to_olsen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.108.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.108.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.109":{"name":"enable_sisko","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.109.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.109.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.110":{"name":"enable_starspace","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.110.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.110.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.111":{"name":"enable_starspace_digest_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.111.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.111.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.112":{"name":"enable_starspace_ranker_starspace","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.112.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.112.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.113":{"name":"enable_theme_editor","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.113.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.113.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.114":{"name":"enable_tick_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.114.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.114.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.115":{"name":"enable_tipalti_onboarding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.115.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.115.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.116":{"name":"enable_topic_lifecycle_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.116.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.116.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.117":{"name":"enable_tribute_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.117.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.117.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.118":{"name":"enable_trumpland_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.118.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.118.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.119":{"name":"enable_utc_fix_on_partner_program_dashboard","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.119.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.119.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.120":{"name":"enable_valencia_topics","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.120.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.120.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.121":{"name":"exclude_curated_in_popular_topic","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.121.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.121.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.122":{"name":"featured_fc_and_ydr","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.122.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.122.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.123":{"name":"filter_low_scoring_users","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.123.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.123.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.124":{"name":"glyph_embed_commands","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.124.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.124.valueType":{"__typename":"VariantFlagString","value":"control"},"ROOT_QUERY.variantFlags.125":{"name":"glyph_font_set","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.125.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.125.valueType":{"__typename":"VariantFlagString","value":"m2"},"ROOT_QUERY.variantFlags.126":{"name":"google_sign_in_android","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.126.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.126.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.127":{"name":"ios_pub_follow_email_opt_in","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.127.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.127.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.128":{"name":"is_not_medium_subscriber","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.128.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.128.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.129":{"name":"limit_post_referrers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.129.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.129.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.130":{"name":"make_nav_sticky","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.130.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.130.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.131":{"name":"new_transition_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.131.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.131.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.132":{"name":"pub_sidebar","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.132.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.132.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.133":{"name":"rank_model","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.133.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.133.valueType":{"__typename":"VariantFlagString","value":"default"},"ROOT_QUERY.variantFlags.134":{"name":"remove_email_opt_in_on_pub_follow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.134.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.134.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.135":{"name":"remove_post_post_similarity","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.135.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.135.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.136":{"name":"share_post_linkedin","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.136.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.136.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.137":{"name":"sign_up_with_email_button","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.137.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.137.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.138":{"name":"signin_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.138.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.138.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.139":{"name":"signup_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.139.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.139.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.140":{"name":"skip_sign_in_recaptcha","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.140.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.140.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.141":{"name":"sourcing_refactor_2","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.141.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.141.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.142":{"name":"use_new_admin_topic_backend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.142.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.142.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.143":{"name":"xgboost_auto_suspend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.143.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.143.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY":{"variantFlags":[{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.0","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.1","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.2","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.3","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.4","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.5","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.6","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.7","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.8","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.9","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.10","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.11","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.12","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.13","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.14","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.15","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.16","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.17","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.18","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.19","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.20","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.21","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.22","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.23","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.24","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.25","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.26","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.27","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.28","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.29","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.30","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.31","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.32","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.33","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.34","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.35","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.36","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.37","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.38","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.39","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.40","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.41","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.42","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.43","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.44","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.45","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.46","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.47","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.48","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.49","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.50","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.51","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.52","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.53","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.54","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.55","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.56","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.57","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.58","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.59","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.60","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.61","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.62","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.63","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.64","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.65","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.66","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.67","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.68","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.69","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.70","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.71","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.72","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.73","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.74","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.75","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.76","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.77","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.78","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.79","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.80","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.81","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.82","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.83","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.84","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.85","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.86","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.87","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.88","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.89","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.90","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.91","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.92","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.93","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.94","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.95","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.96","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.97","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.98","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.99","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.100","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.101","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.102","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.103","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.104","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.105","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.106","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.107","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.108","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.109","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.110","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.111","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.112","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.113","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.114","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.115","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.116","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.117","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.118","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.119","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.120","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.121","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.122","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.123","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.124","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.125","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.126","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.127","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.128","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.129","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.130","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.131","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.132","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.133","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.134","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.135","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.136","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.137","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.138","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.139","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.140","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.141","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.142","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.143","typename":"VariantFlag"}],"viewer":{"type":"id","generated":false,"id":"User:ecd8844b0d2e","typename":"User"},"meterPost({\"postId\":\"79597dc8c347\",\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":false,"id":"MeteringInfo:singleton","typename":"MeteringInfo"},"postResult({\"id\":\"79597dc8c347\"})":{"type":"id","generated":false,"id":"Post:79597dc8c347","typename":"Post"}},"User:ecd8844b0d2e":{"id":"ecd8844b0d2e","username":"nath.pritam004","name":"Nath Pritam","imageId":"0*ltmrQGulORdZR-m6","mediumMemberAt":0,"hasPastMemberships":false,"isPartnerProgramEnrolled":false,"email":"nath.pritam004@gmail.com","unverifiedEmail":"","createdAt":1573061234834,"isEligibleToViewNewResponses":false,"isMembershipTrialEligible":true,"isSuspended":false,"__typename":"User"},"MeteringInfo:singleton":{"__typename":"MeteringInfo","postIds":{"type":"json","json":[]},"maxUnlockCount":3,"unlocksRemaining":3},"Post:79597dc8c347":{"__typename":"Post","id":"79597dc8c347","mediumUrl":"https:\u002F\u002Fdeephunt.in\u002Fthe-gan-zoo-79597dc8c347","canonicalUrl":"","collection":{"type":"id","generated":false,"id":"Collection:2aa09a31045c","typename":"Collection"},"content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":true,"id":"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})","typename":"PostContent"},"creator":{"type":"id","generated":false,"id":"User:4bdd665cbeca","typename":"User"},"firstPublishedAt":1492618432100,"isLocked":false,"isPublished":true,"layerCake":0,"primaryTopic":null,"title":"The GAN Zoo","latestPublishedVersion":"5f8adc94679e","visibility":"PUBLIC","isLimitedState":false,"sequence":null,"pendingCollection":null,"shareKey":null,"statusForCollection":"APPROVED","readingTime":21.843710691823897,"readingList":"READING_LIST_NONE","allowResponses":true,"clapCount":1603,"viewerClapCount":null,"voterCount":457,"recommenders":[],"license":"ALL_RIGHTS_RESERVED","tags":[{"type":"id","generated":false,"id":"Tag:machine-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:artificial-intelligence","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:deep-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:technology","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:neural-networks","typename":"Tag"}],"topics":[],"postResponses":{"type":"id","generated":true,"id":"$Post:79597dc8c347.postResponses","typename":"PostResponses"},"responsesCount":11,"collaborators":[],"translationSourcePost":null,"newsletterId":"","inResponseToPostResult":null,"inResponseToMediaResource":null,"lockedSource":"LOCKED_POST_SOURCE_NONE","curationEligibleAt":0,"isDistributionAlertDismissed":false,"audioVersionUrl":"","socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1538338039456,"previewContent":{"type":"id","generated":true,"id":"$Post:79597dc8c347.previewContent","typename":"PreviewContent"},"previewImage":{"type":"id","generated":false,"id":"ImageMetadata:0*ncqqFthh4e9baHxI.jpg","typename":"ImageMetadata"},"isShortform":false,"seoTitle":"","updatedAt":1538338039456,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false},"Collection:2aa09a31045c":{"id":"2aa09a31045c","domain":"deephunt.in","googleAnalyticsId":"UA-97176350-1","slug":"deep-hunt","customStyleSheet":null,"colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","isAuroraPilot":false,"isAuroraVisible":false,"favicon":{"type":"id","generated":false,"id":"ImageMetadata:1*6yx91P_l0phituLnYOK7Jw.png","typename":"ImageMetadata"},"isAuroraEligible":false,"viewerIsEditor":false,"__typename":"Collection","name":"Deep Hunt","logo":{"type":"id","generated":false,"id":"ImageMetadata:","typename":"ImageMetadata"},"avatar":{"type":"id","generated":false,"id":"ImageMetadata:1*6yx91P_l0phituLnYOK7Jw.png","typename":"ImageMetadata"},"isEnrolledInHightower":false,"isNewsletterV3Enabled":true,"newsletterV3":null,"creator":{"type":"id","generated":false,"id":"User:4bdd665cbeca","typename":"User"},"navItems":[{"type":"id","generated":true,"id":"Collection:2aa09a31045c.navItems.0","typename":"NavItem"}],"colorPalette":{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette","typename":"ColorPalette"},"description":"Your weekly newsletter on the hottest things in Artificial Intelligence carefully curated by Avinash Hindupur!","shortDescription":"Your weekly newsletter on the hottest things in Artificial…","viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"canToggleEmail":false,"isUserSubscribedToCollectionEmails":false,"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"viewerIsMuting":false,"ampEnabled":false,"twitterUsername":"deephunt_in","facebookPageId":null,"tagline":"Your weekly newsletter on the hottest things in Artificial…"},"ImageMetadata:1*6yx91P_l0phituLnYOK7Jw.png":{"id":"1*6yx91P_l0phituLnYOK7Jw.png","__typename":"ImageMetadata"},"ImageMetadata:":{"id":"","originalWidth":0,"originalHeight":0,"__typename":"ImageMetadata"},"User:4bdd665cbeca":{"id":"4bdd665cbeca","__typename":"User","isSuspended":false,"allowNotes":true,"name":"Avinash Hindupur","isFollowing":false,"username":"hindupuravinash","bio":"Dreamer, @iitguwahati alum. Creator of @deephunt_in, Organiser @ DeepLearningDelhi | Interested in all things data and machine learning.","imageId":"0*5q7vZAHEK04LVoU4.jpeg","mediumMemberAt":0,"isBlocking":false,"isMuting":false,"isPartnerProgramEnrolled":false,"twitterScreenName":"hindupuravinash"},"Collection:2aa09a31045c.navItems.0":{"title":"Newsletter","url":"https:\u002F\u002Fdeephunt.in\u002Ftagged\u002Fnewsletter","type":"TAG_NAV_ITEM","__typename":"NavItem"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum":{"backgroundColor":"#FFE15718","colorPoints":[{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.0":{"color":"#FFE15718","point":0,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.1":{"color":"#FFED682E","point":0.1,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.2":{"color":"#FFF77842","point":0.2,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.3":{"color":"#FFFF8855","point":0.3,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.4":{"color":"#FFFF9868","point":0.4,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.5":{"color":"#FFFFA77B","point":0.5,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.6":{"color":"#FFFFB78F","point":0.6,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.7":{"color":"#FFFFC6A3","point":0.7,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.8":{"color":"#FFFFD5B6","point":0.8,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.9":{"color":"#FFFFE4CB","point":0.9,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum.colorPoints.10":{"color":"#FFFFF2DF","point":1,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette":{"tintBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.tintBackgroundSpectrum","typename":"ColorSpectrum"},"__typename":"ColorPalette","highlightSpectrum":{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum","typename":"ColorSpectrum"},"defaultBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum","typename":"ColorSpectrum"}},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.0":{"color":"#FFFFE3CC","point":0,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.1":{"color":"#FFFFDFC4","point":0.1,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.2":{"color":"#FFFFDABC","point":0.2,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.3":{"color":"#FFFFD6B3","point":0.3,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.4":{"color":"#FFFFD1AB","point":0.4,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.5":{"color":"#FFFFCCA3","point":0.5,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.6":{"color":"#FFFFC79B","point":0.6,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.7":{"color":"#FFFFC393","point":0.7,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.8":{"color":"#FFFFBE8A","point":0.8,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.9":{"color":"#FFFFB982","point":0.9,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.highlightSpectrum.colorPoints.10":{"color":"#FFFFB47A","point":1,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.0":{"color":"#FFD95112","point":0,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.1":{"color":"#FFC84D15","point":0.1,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.2":{"color":"#FFB84917","point":0.2,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.3":{"color":"#FFA74418","point":0.3,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.4":{"color":"#FF963F19","point":0.4,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.5":{"color":"#FF853918","point":0.5,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.6":{"color":"#FF743317","point":0.6,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.7":{"color":"#FF622C15","point":0.7,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.8":{"color":"#FF502512","point":0.8,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.9":{"color":"#FF3D1C0E","point":0.9,"__typename":"ColorPoint"},"$Collection:2aa09a31045c.colorPalette.defaultBackgroundSpectrum.colorPoints.10":{"color":"#FF2A1208","point":1,"__typename":"ColorPoint"},"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"isLockedPreviewOnly":false,"validatedShareKey":"","__typename":"PostContent","bodyModel":{"type":"id","generated":true,"id":"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel","typename":"RichText"}},"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0":{"name":"184b","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.1":{"name":"f97e","startIndex":6,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.2":{"name":"1d3c","startIndex":508,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel":{"sections":[{"type":"id","generated":true,"id":"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0","typename":"Section"},{"type":"id","generated":true,"id":"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.1","typename":"Section"},{"type":"id","generated":true,"id":"$Post:79597dc8c347.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.2","typename":"Section"}],"paragraphs":[{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_0","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_1","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_2","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_3","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_4","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_5","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_6","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_7","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_8","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_9","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_10","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_11","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_12","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_13","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_14","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_15","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_16","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_17","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_18","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_19","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_20","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_21","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_22","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_23","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_24","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_25","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_26","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_27","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_28","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_29","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_30","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_31","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_32","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_33","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_34","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_35","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_36","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_37","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_38","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_39","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_40","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_41","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_42","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_43","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_44","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_45","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_46","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_47","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_48","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_49","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_50","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_51","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_52","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_53","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_54","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_55","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_56","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_57","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_58","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_59","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_60","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_61","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_62","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_63","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_64","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_65","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_66","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_67","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_68","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_69","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_70","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_71","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_72","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_73","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_74","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_75","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_76","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_77","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_78","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_79","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_80","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_81","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_82","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_83","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_84","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_85","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_86","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_87","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_88","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_89","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_90","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_91","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_92","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_93","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_94","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_95","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_96","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_97","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_98","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_99","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_100","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_101","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_102","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_103","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_104","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_105","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_106","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_107","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_108","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_109","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_110","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_111","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_112","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_113","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_114","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_115","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_116","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_117","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_118","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_119","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_120","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_121","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_122","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_123","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_124","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_125","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_126","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_127","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_128","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_129","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_130","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_131","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_132","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_133","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_134","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_135","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_136","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_137","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_138","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_139","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_140","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_141","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_142","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_143","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_144","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_145","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_146","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_147","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_148","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_149","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_150","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_151","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_152","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_153","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_154","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_155","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_156","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_157","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_158","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_159","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_160","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_161","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_162","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_163","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_164","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_165","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_166","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_167","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_168","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_169","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_170","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_171","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_172","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_173","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_174","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_175","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_176","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_177","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_178","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_179","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_180","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_181","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_182","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_183","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_184","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_185","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_186","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_187","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_188","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_189","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_190","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_191","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_192","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_193","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_194","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_195","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_196","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_197","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_198","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_199","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_200","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_201","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_202","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_203","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_204","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_205","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_206","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_207","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_208","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_209","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_210","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_211","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_212","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_213","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_214","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_215","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_216","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_217","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_218","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_219","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_220","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_221","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_222","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_223","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_224","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_225","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_226","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_227","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_228","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_229","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_230","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_231","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_232","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_233","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_234","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_235","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_236","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_237","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_238","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_239","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_240","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_241","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_242","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_243","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_244","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_245","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_246","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_247","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_248","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_249","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_250","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_251","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_252","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_253","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_254","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_255","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_256","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_257","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_258","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_259","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_260","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_261","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_262","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_263","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_264","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_265","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_266","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_267","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_268","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_269","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_270","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_271","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_272","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_273","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_274","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_275","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_276","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_277","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_278","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_279","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_280","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_281","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_282","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_283","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_284","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_285","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_286","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_287","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_288","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_289","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_290","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_291","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_292","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_293","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_294","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_295","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_296","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_297","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_298","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_299","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_300","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_301","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_302","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_303","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_304","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_305","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_306","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_307","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_308","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_309","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_310","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_311","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_312","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_313","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_314","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_315","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_316","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_317","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_318","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_319","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_320","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_321","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_322","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_323","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_324","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_325","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_326","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_327","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_328","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_329","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_330","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_331","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_332","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_333","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_334","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_335","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_336","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_337","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_338","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_339","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_340","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_341","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_342","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_343","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_344","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_345","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_346","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_347","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_348","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_349","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_350","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_351","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_352","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_353","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_354","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_355","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_356","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_357","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_358","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_359","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_360","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_361","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_362","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_363","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_364","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_365","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_366","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_367","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_368","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_369","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_370","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_371","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_372","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_373","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_374","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_375","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_376","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_377","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_378","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_379","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_380","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_381","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_382","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_383","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_384","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_385","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_386","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_387","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_388","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_389","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_390","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_391","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_392","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_393","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_394","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_395","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_396","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_397","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_398","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_399","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_400","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_401","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_402","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_403","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_404","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_405","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_406","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_407","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_408","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_409","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_410","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_411","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_412","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_413","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_414","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_415","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_416","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_417","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_418","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_419","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_420","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_421","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_422","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_423","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_424","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_425","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_426","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_427","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_428","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_429","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_430","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_431","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_432","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_433","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_434","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_435","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_436","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_437","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_438","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_439","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_440","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_441","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_442","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_443","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_444","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_445","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_446","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_447","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_448","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_449","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_450","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_451","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_452","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_453","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_454","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_455","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_456","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_457","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_458","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_459","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_460","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_461","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_462","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_463","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_464","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_465","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_466","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_467","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_468","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_469","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_470","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_471","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_472","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_473","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_474","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_475","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_476","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_477","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_478","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_479","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_480","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_481","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_482","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_483","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_484","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_485","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_486","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_487","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_488","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_489","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_490","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_491","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_492","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_493","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_494","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_495","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_496","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_497","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_498","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_499","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_500","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_501","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_502","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_503","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_504","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_505","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_506","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_507","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:5f8adc94679e_508","typename":"Paragraph"}],"__typename":"RichText"},"Paragraph:5f8adc94679e_0":{"id":"5f8adc94679e_0","name":"8038","type":"H3","href":null,"layout":null,"metadata":null,"text":"The GAN Zoo","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_1":{"id":"5f8adc94679e_1","name":"9c45","type":"H4","href":null,"layout":null,"metadata":null,"text":"A list of all named GANs!","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_2":{"id":"5f8adc94679e_2","name":"8f51","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:0*ncqqFthh4e9baHxI.jpg","typename":"ImageMetadata"},"text":"Pretty painting is always better than a Terminator","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*ncqqFthh4e9baHxI.jpg":{"id":"0*ncqqFthh4e9baHxI.jpg","originalHeight":968,"originalWidth":1200,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:5f8adc94679e_3":{"id":"5f8adc94679e_3","name":"16a9","type":"P","href":null,"layout":null,"metadata":null,"text":"Every week, new papers on Generative Adversarial Networks (GAN) are coming out and it’s hard to keep track of them all, not to mention the incredibly creative ways in which researchers are naming these GANs! You can read more about GANs in this Generative Models post by OpenAI or this overview tutorial in KDNuggets.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_3.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_3.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_3.markups.0":{"type":"A","start":245,"end":267,"href":"https:\u002F\u002Fblog.openai.com\u002Fgenerative-models\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_3.markups.1":{"type":"A","start":286,"end":303,"href":"http:\u002F\u002Fwww.kdnuggets.com\u002F2017\u002F01\u002Fgenerative-adversarial-networks-hot-topic-machine-learning.html","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_4":{"id":"5f8adc94679e_4","name":"b78b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:0*NI4oWIcZgSKjIE88.jpg","typename":"ImageMetadata"},"text":"Explosive growth — All the named GAN variants cumulatively since 2014. Credit: Bruno Gavranović","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_4.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*NI4oWIcZgSKjIE88.jpg":{"id":"0*NI4oWIcZgSKjIE88.jpg","originalHeight":550,"originalWidth":800,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:5f8adc94679e_4.markups.0":{"type":"A","start":79,"end":95,"href":"https:\u002F\u002Fgithub.com\u002Fbgavran","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_5":{"id":"5f8adc94679e_5","name":"dd00","type":"P","href":null,"layout":null,"metadata":null,"text":"So, here’s the current and frequently updated list, from what started as a fun activity compiling all named GANs in this format: Name and Source Paper linked to Arxiv. Last updated on Feb 23, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_5.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_5.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_5.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_5.markups.0":{"type":"A","start":161,"end":166,"href":"https:\u002F\u002Farxiv.org","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_5.markups.1":{"type":"STRONG","start":129,"end":133,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_5.markups.2":{"type":"STRONG","start":138,"end":150,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_6":{"id":"5f8adc94679e_6","name":"0b56","type":"ULI","href":null,"layout":null,"metadata":null,"text":"3D-ED-GAN — Shape Inpainting using 3D Generative Adversarial Network and Recurrent Convolutional Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_6.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_6.markups.0":{"type":"A","start":12,"end":105,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06375","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_7":{"id":"5f8adc94679e_7","name":"6a92","type":"ULI","href":null,"layout":null,"metadata":null,"text":"3D-GAN — Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_7.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_7.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_7.markups.0":{"type":"A","start":9,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1610.07584","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_7.markups.1":{"type":"A","start":104,"end":110,"href":"https:\u002F\u002Fgithub.com\u002Fzck119\u002F3dgan-release","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_8":{"id":"5f8adc94679e_8","name":"040c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"3D-IWGAN — Improved Adversarial Systems for 3D Object Generation and Reconstruction (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_8.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_8.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_8.markups.0":{"type":"A","start":11,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.09557","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_8.markups.1":{"type":"A","start":85,"end":91,"href":"https:\u002F\u002Fgithub.com\u002FEdwardSmith1884\u002F3D-IWGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_9":{"id":"5f8adc94679e_9","name":"ae16","type":"ULI","href":null,"layout":null,"metadata":null,"text":"3D-PhysNet — 3D-PhysNet: Learning the Intuitive Physics of Non-Rigid Object Deformations","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_9.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_9.markups.0":{"type":"A","start":13,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.00328","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_10":{"id":"5f8adc94679e_10","name":"cd7a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"3D-RecGAN — 3D Object Reconstruction from a Single Depth View with Adversarial Learning (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_10.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_10.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_10.markups.0":{"type":"A","start":12,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.07969","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_10.markups.1":{"type":"A","start":89,"end":95,"href":"https:\u002F\u002Fgithub.com\u002FYang7879\u002F3D-RecGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_11":{"id":"5f8adc94679e_11","name":"78df","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ABC-GAN — ABC-GAN: Adaptive Blur and Control for improved training stability of Generative Adversarial Networks(github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_11.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_11.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_11.markups.0":{"type":"A","start":10,"end":111,"href":"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F0B3wEP_lEl0laVTdGcHE2VnRiMlE\u002Fview","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_11.markups.1":{"type":"A","start":112,"end":118,"href":"https:\u002F\u002Fgithub.com\u002FIgorSusmelj\u002FABC-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_12":{"id":"5f8adc94679e_12","name":"a2c9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ABC-GAN — GANs for LIFE: Generative Adversarial Networks for Likelihood Free Inference","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_12.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_12.markups.0":{"type":"A","start":10,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.11139","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_13":{"id":"5f8adc94679e_13","name":"b72f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AC-GAN — Conditional Image Synthesis With Auxiliary Classifier GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_13.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_13.markups.0":{"type":"A","start":9,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1610.09585","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_14":{"id":"5f8adc94679e_14","name":"b96a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"acGAN — Face Aging With Conditional Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_14.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_14.markups.0":{"type":"A","start":8,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.01983","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_15":{"id":"5f8adc94679e_15","name":"d30a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ACGAN — Coverless Information Hiding Based on Generative adversarial networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_15.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_15.markups.0":{"type":"A","start":8,"end":77,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.06951","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_16":{"id":"5f8adc94679e_16","name":"0d8f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"acGAN — On-line Adaptative Curriculum Learning for GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_16.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_16.markups.0":{"type":"A","start":8,"end":55,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.00020","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_17":{"id":"5f8adc94679e_17","name":"6ffa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ACtuAL — ACtuAL: Actor-Critic Under Adversarial Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_17.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_17.markups.0":{"type":"A","start":9,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.04755","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_18":{"id":"5f8adc94679e_18","name":"c8f5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AdaGAN — AdaGAN: Boosting Generative Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_18.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_18.markups.0":{"type":"A","start":9,"end":43,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.02386v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_19":{"id":"5f8adc94679e_19","name":"a500","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Adaptive GAN — Customizing an Adversarial Example Generator with Class-Conditional GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_19.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_19.markups.0":{"type":"A","start":15,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.10496","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_20":{"id":"5f8adc94679e_20","name":"5e8e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AdvEntuRe — AdvEntuRe: Adversarial Training for Textual Entailment with Knowledge-Guided Examples","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_20.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_20.markups.0":{"type":"A","start":12,"end":97,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.04680","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_21":{"id":"5f8adc94679e_21","name":"90bc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AdvGAN — Generating adversarial examples with adversarial networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_21.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_21.markups.0":{"type":"A","start":9,"end":66,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.02610","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_22":{"id":"5f8adc94679e_22","name":"5893","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AE-GAN — AE-GAN: adversarial eliminating with GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_22.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_22.markups.0":{"type":"A","start":9,"end":49,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.05474","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_23":{"id":"5f8adc94679e_23","name":"c828","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AE-OT — Latent Space Optimal Transport for Generative Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_23.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_23.markups.0":{"type":"A","start":8,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.05964","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_24":{"id":"5f8adc94679e_24","name":"7dc0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AEGAN — Learning Inverse Mapping by Autoencoder based Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_24.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_24.markups.0":{"type":"A","start":8,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.10094","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_25":{"id":"5f8adc94679e_25","name":"9df0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AF-DCGAN — AF-DCGAN: Amplitude Feature Deep Convolutional GAN for Fingerprint Construction in Indoor Localization System","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_25.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_25.markups.0":{"type":"A","start":11,"end":120,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.05347","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_26":{"id":"5f8adc94679e_26","name":"88db","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AffGAN — Amortised MAP Inference for Image Super-resolution","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_26.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_26.markups.0":{"type":"A","start":9,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1610.04490","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_27":{"id":"5f8adc94679e_27","name":"00d2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AIM — Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_27.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_27.markups.0":{"type":"A","start":6,"end":106,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.05972","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_28":{"id":"5f8adc94679e_28","name":"58bc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AL-CGAN — Learning to Generate Images of Outdoor Scenes from Attributes and Semantic Layouts","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_28.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_28.markups.0":{"type":"A","start":10,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.00215","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_29":{"id":"5f8adc94679e_29","name":"3497","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ALI — Adversarially Learned Inference (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_29.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_29.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_29.markups.0":{"type":"A","start":6,"end":37,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1606.00704","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_29.markups.1":{"type":"A","start":39,"end":45,"href":"https:\u002F\u002Fgithub.com\u002FIshmaelBelghazi\u002FALI","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_30":{"id":"5f8adc94679e_30","name":"c472","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AlignGAN — AlignGAN: Learning to Align Cross-Domain Images with Conditional Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_30.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_30.markups.0":{"type":"A","start":11,"end":107,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.01400","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_31":{"id":"5f8adc94679e_31","name":"8de2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AlphaGAN — AlphaGAN: Generative adversarial networks for natural image matting","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_31.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_31.markups.0":{"type":"A","start":11,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.10088","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_32":{"id":"5f8adc94679e_32","name":"b74e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AM-GAN — Activation Maximization Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_32.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_32.markups.0":{"type":"A","start":9,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.02000","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_33":{"id":"5f8adc94679e_33","name":"df03","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AmbientGAN — AmbientGAN: Generative models from lossy measurements (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_33.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_33.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_33.markups.0":{"type":"A","start":13,"end":66,"href":"https:\u002F\u002Fopenreview.net\u002Fforum?id=Hy7fDog0b","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_33.markups.1":{"type":"A","start":68,"end":74,"href":"https:\u002F\u002Fgithub.com\u002FAshishBora\u002Fambient-gan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_34":{"id":"5f8adc94679e_34","name":"fb14","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AMC-GAN — Video Prediction with Appearance and Motion Conditions","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_34.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_34.markups.0":{"type":"A","start":10,"end":64,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.02635","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_35":{"id":"5f8adc94679e_35","name":"3911","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AnoGAN — Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_35.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_35.markups.0":{"type":"A","start":9,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.05921v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_36":{"id":"5f8adc94679e_36","name":"5aba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"APD — Adversarial Distillation of Bayesian Neural Network Posteriors","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_36.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_36.markups.0":{"type":"A","start":6,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.10317","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_37":{"id":"5f8adc94679e_37","name":"af82","type":"ULI","href":null,"layout":null,"metadata":null,"text":"APE-GAN — APE-GAN: Adversarial Perturbation Elimination with GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_37.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_37.markups.0":{"type":"A","start":10,"end":64,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.05474","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_38":{"id":"5f8adc94679e_38","name":"a1d9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ARAE — Adversarially Regularized Autoencoders for Generating Discrete Structures (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_38.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_38.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_38.markups.0":{"type":"A","start":7,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.04223","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_38.markups.1":{"type":"A","start":82,"end":88,"href":"https:\u002F\u002Fgithub.com\u002Fjakezhaojb\u002FARAE","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_39":{"id":"5f8adc94679e_39","name":"d2b6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ARDA — Adversarial Representation Learning for Domain Adaptation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_39.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_39.markups.0":{"type":"A","start":7,"end":64,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.01217","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_40":{"id":"5f8adc94679e_40","name":"c07d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ARIGAN — ARIGAN: Synthetic Arabidopsis Plants using Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_40.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_40.markups.0":{"type":"A","start":9,"end":82,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.00938","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_41":{"id":"5f8adc94679e_41","name":"eb03","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ArtGAN — ArtGAN: Artwork Synthesis with Conditional Categorial GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_41.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_41.markups.0":{"type":"A","start":9,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.03410","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_42":{"id":"5f8adc94679e_42","name":"8e4d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ASDL-GAN — Automatic Steganographic Distortion Learning Using a Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_42.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_42.markups.0":{"type":"A","start":11,"end":94,"href":"https:\u002F\u002Fieeexplore.ieee.org\u002Fdocument\u002F8017430\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_43":{"id":"5f8adc94679e_43","name":"3ca5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ATA-GAN — Attention-Aware Generative Adversarial Networks (ATA-GANs)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_43.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_43.markups.0":{"type":"A","start":10,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.09070","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_44":{"id":"5f8adc94679e_44","name":"248b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Attention-GAN — Attention-GAN for Object Transfiguration in Wild Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_44.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_44.markups.0":{"type":"A","start":16,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.06798","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_45":{"id":"5f8adc94679e_45","name":"bc0a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AttGAN — Arbitrary Facial Attribute Editing: Only Change What You Want (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_45.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_45.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_45.markups.0":{"type":"A","start":9,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.10678","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_45.markups.1":{"type":"A","start":72,"end":78,"href":"https:\u002F\u002Fgithub.com\u002FLynnHo\u002FAttGAN-Tensorflow","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_46":{"id":"5f8adc94679e_46","name":"b04a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AttnGAN — AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_46.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_46.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_46.markups.0":{"type":"A","start":10,"end":105,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.10485","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_46.markups.1":{"type":"A","start":107,"end":113,"href":"https:\u002F\u002Fgithub.com\u002Ftaoxugit\u002FAttnGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_47":{"id":"5f8adc94679e_47","name":"cba6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AVID — AVID: Adversarial Visual Irregularity Detection","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_47.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_47.markups.0":{"type":"A","start":7,"end":54,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.09521","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_48":{"id":"5f8adc94679e_48","name":"c6dd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"B-DCGAN — B-DCGAN:Evaluation of Binarized DCGAN for FPGA","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_48.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_48.markups.0":{"type":"A","start":10,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.10930","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_49":{"id":"5f8adc94679e_49","name":"8b82","type":"ULI","href":null,"layout":null,"metadata":null,"text":"b-GAN — Generative Adversarial Nets from a Density Ratio Estimation Perspective","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_49.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_49.markups.0":{"type":"A","start":8,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1610.02920","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_50":{"id":"5f8adc94679e_50","name":"ea0c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BAGAN — BAGAN: Data Augmentation with Balancing GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_50.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_50.markups.0":{"type":"A","start":8,"end":51,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.09655","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_51":{"id":"5f8adc94679e_51","name":"bbba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Bayesian GAN — Deep and Hierarchical Implicit Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_51.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_51.markups.0":{"type":"A","start":15,"end":52,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.08896","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_52":{"id":"5f8adc94679e_52","name":"b271","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Bayesian GAN — Bayesian GAN (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_52.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_52.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_52.markups.0":{"type":"A","start":15,"end":27,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.09558","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_52.markups.1":{"type":"A","start":29,"end":35,"href":"https:\u002F\u002Fgithub.com\u002Fandrewgordonwilson\u002Fbayesgan\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_53":{"id":"5f8adc94679e_53","name":"316c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BCGAN — Bayesian Conditional Generative Adverserial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_53.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_53.markups.0":{"type":"A","start":8,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.05477","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_54":{"id":"5f8adc94679e_54","name":"82d6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BCGAN — Bidirectional Conditional Generative Adversarial networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_54.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_54.markups.0":{"type":"A","start":8,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.07461","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_55":{"id":"5f8adc94679e_55","name":"f084","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BEAM — Boltzmann Encoded Adversarial Machines","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_55.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_55.markups.0":{"type":"A","start":7,"end":45,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.08682","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_56":{"id":"5f8adc94679e_56","name":"88fa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BEGAN — BEGAN: Boundary Equilibrium Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_56.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_56.markups.0":{"type":"A","start":8,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.10717","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_57":{"id":"5f8adc94679e_57","name":"2663","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BEGAN-CS — Escaping from Collapsing Modes in a Constrained Space","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_57.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_57.markups.0":{"type":"A","start":11,"end":64,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.07258","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_58":{"id":"5f8adc94679e_58","name":"21a6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Bellman GAN — Distributional Multivariate Policy Evaluation and Exploration with the Bellman GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_58.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_58.markups.0":{"type":"A","start":14,"end":96,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.01960","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_59":{"id":"5f8adc94679e_59","name":"490e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BGAN — Binary Generative Adversarial Networks for Image Retrieval (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_59.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_59.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_59.markups.0":{"type":"A","start":7,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.04150","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_59.markups.1":{"type":"A","start":67,"end":73,"href":"https:\u002F\u002Fgithub.com\u002Fhtconquer\u002FBGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_60":{"id":"5f8adc94679e_60","name":"39b1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Bi-GAN — Autonomously and Simultaneously Refining Deep Neural Network Parameters by a Bi-Generative Adversarial Network Aided Genetic Algorithm","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_60.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_60.markups.0":{"type":"A","start":9,"end":143,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.10244","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_61":{"id":"5f8adc94679e_61","name":"ba84","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BicycleGAN — Toward Multimodal Image-to-Image Translation (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_61.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_61.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_61.markups.0":{"type":"A","start":13,"end":57,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.11586","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_61.markups.1":{"type":"A","start":59,"end":65,"href":"https:\u002F\u002Fgithub.com\u002Fjunyanz\u002FBicycleGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_62":{"id":"5f8adc94679e_62","name":"a345","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BiGAN — Adversarial Feature Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_62.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_62.markups.0":{"type":"A","start":8,"end":36,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1605.09782v7","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_63":{"id":"5f8adc94679e_63","name":"ca91","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BinGAN — BinGAN: Learning Compact Binary Descriptors with a Regularized GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_63.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_63.markups.0":{"type":"A","start":9,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.06778","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_64":{"id":"5f8adc94679e_64","name":"a54b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BourGAN — BourGAN: Generative Networks with Metric Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_64.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_64.markups.0":{"type":"A","start":10,"end":61,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.07674","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_65":{"id":"5f8adc94679e_65","name":"d4b2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BranchGAN — Branched Generative Adversarial Networks for Multi-Scale Image Manifold Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_65.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_65.markups.0":{"type":"A","start":12,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.08467","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_66":{"id":"5f8adc94679e_66","name":"37f5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BRE — Improving GAN Training via Binarized Representation Entropy (BRE) Regularization (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_66.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_66.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_66.markups.0":{"type":"A","start":6,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.03644","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_66.markups.1":{"type":"A","start":88,"end":94,"href":"https:\u002F\u002Fgithub.com\u002FBorealisAI\u002Fbre-gan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_67":{"id":"5f8adc94679e_67","name":"1724","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BridgeGAN — Generative Adversarial Frontal View to Bird View Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_67.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_67.markups.0":{"type":"A","start":12,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.00327","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_68":{"id":"5f8adc94679e_68","name":"8cba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BS-GAN — Boundary-Seeking Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_68.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_68.markups.0":{"type":"A","start":9,"end":57,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.08431v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_69":{"id":"5f8adc94679e_69","name":"e91c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BubGAN — BubGAN: Bubble Generative Adversarial Networks for Synthesizing Realistic Bubbly Flow Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_69.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_69.markups.0":{"type":"A","start":9,"end":101,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.02266","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_70":{"id":"5f8adc94679e_70","name":"5485","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BWGAN — Banach Wasserstein GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_70.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_70.markups.0":{"type":"A","start":8,"end":30,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.06621","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_71":{"id":"5f8adc94679e_71","name":"3e87","type":"ULI","href":null,"layout":null,"metadata":null,"text":"C-GAN — Face Aging with Contextual Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_71.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_71.markups.0":{"type":"A","start":8,"end":62,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.00237","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_72":{"id":"5f8adc94679e_72","name":"9b88","type":"ULI","href":null,"layout":null,"metadata":null,"text":"C-RNN-GAN — C-RNN-GAN: Continuous recurrent neural networks with adversarial training (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_72.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_72.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_72.markups.0":{"type":"A","start":12,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.09904","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_72.markups.1":{"type":"A","start":87,"end":93,"href":"https:\u002F\u002Fgithub.com\u002Folofmogren\u002Fc-rnn-gan\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_73":{"id":"5f8adc94679e_73","name":"6d2a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CA-GAN — Composition-aided Sketch-realistic Portrait Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_73.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_73.markups.0":{"type":"A","start":9,"end":63,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00899","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_74":{"id":"5f8adc94679e_74","name":"e790","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CaloGAN — CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_74.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_74.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_74.markups.0":{"type":"A","start":10,"end":142,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.02355","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_74.markups.1":{"type":"A","start":144,"end":150,"href":"https:\u002F\u002Fgithub.com\u002Fhep-lbdl\u002FCaloGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_75":{"id":"5f8adc94679e_75","name":"3c7b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CAN — CAN: Creative Adversarial Networks, Generating Art by Learning About Styles and Deviating from Style Norms","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_75.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_75.markups.0":{"type":"A","start":6,"end":112,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.07068","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_76":{"id":"5f8adc94679e_76","name":"ae7d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CapsGAN — CapsGAN: Using Dynamic Routing for Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_76.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_76.markups.0":{"type":"A","start":10,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.03968","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_77":{"id":"5f8adc94679e_77","name":"c7b3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CapsuleGAN — CapsuleGAN: Generative Adversarial Capsule Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_77.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_77.markups.0":{"type":"A","start":13,"end":63,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1802.06167","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_78":{"id":"5f8adc94679e_78","name":"a57e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CatGAN — Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_78.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_78.markups.0":{"type":"A","start":9,"end":99,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1511.06390v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_79":{"id":"5f8adc94679e_79","name":"5fb5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CatGAN — CatGAN: Coupled Adversarial Transfer for Domain Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_79.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_79.markups.0":{"type":"A","start":9,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.08904","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_80":{"id":"5f8adc94679e_80","name":"96f7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CausalGAN — CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_80.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_80.markups.0":{"type":"A","start":12,"end":91,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.02023","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_81":{"id":"5f8adc94679e_81","name":"1e41","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CC-GAN — Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_81.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_81.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_81.markups.0":{"type":"A","start":9,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.06430","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_81.markups.1":{"type":"A","start":92,"end":98,"href":"https:\u002F\u002Fgithub.com\u002Fedenton\u002Fcc-gan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_82":{"id":"5f8adc94679e_82","name":"4487","type":"ULI","href":null,"layout":null,"metadata":null,"text":"cd-GAN — Conditional Image-to-Image Translation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_82.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_82.markups.0":{"type":"A","start":9,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.00251","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_83":{"id":"5f8adc94679e_83","name":"7ddb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CDcGAN — Simultaneously Color-Depth Super-Resolution with Conditional Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_83.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_83.markups.0":{"type":"A","start":9,"end":100,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.09105","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_84":{"id":"5f8adc94679e_84","name":"3334","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CE-GAN — Deep Learning for Imbalance Data Classification using Class Expert Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_84.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_84.markups.0":{"type":"A","start":9,"end":106,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.04585","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_85":{"id":"5f8adc94679e_85","name":"906f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CFG-GAN — Composite Functional Gradient Learning of Generative Adversarial Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_85.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_85.markups.0":{"type":"A","start":10,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.06309","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_86":{"id":"5f8adc94679e_86","name":"d21c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CGAN — Conditional Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_86.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_86.markups.0":{"type":"A","start":7,"end":46,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1411.1784","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_87":{"id":"5f8adc94679e_87","name":"4086","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CGAN — Controllable Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_87.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_87.markups.0":{"type":"A","start":7,"end":50,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.00598","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_88":{"id":"5f8adc94679e_88","name":"73b4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Chekhov GAN — An Online Learning Approach to Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_88.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_88.markups.0":{"type":"A","start":14,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.03269","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_89":{"id":"5f8adc94679e_89","name":"9268","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ciGAN — Conditional Infilling GANs for Data Augmentation in Mammogram Classification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_89.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_89.markups.0":{"type":"A","start":8,"end":84,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.08093","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_90":{"id":"5f8adc94679e_90","name":"2e77","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CinCGAN — Unsupervised Image Super-Resolution using Cycle-in-Cycle Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_90.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_90.markups.0":{"type":"A","start":10,"end":98,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.00437","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_91":{"id":"5f8adc94679e_91","name":"e3ce","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CipherGAN — Unsupervised Cipher Cracking Using Discrete GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_91.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_91.markups.0":{"type":"A","start":12,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.04883","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_92":{"id":"5f8adc94679e_92","name":"d91e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ClusterGAN — ClusterGAN : Latent Space Clustering in Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_92.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_92.markups.0":{"type":"A","start":13,"end":84,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.03627","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_93":{"id":"5f8adc94679e_93","name":"729c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CM-GAN — CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_93.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_93.markups.0":{"type":"A","start":9,"end":96,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.05106","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_94":{"id":"5f8adc94679e_94","name":"49dc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CoAtt-GAN — Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_94.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_94.markups.0":{"type":"A","start":12,"end":97,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.07613","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_95":{"id":"5f8adc94679e_95","name":"f07d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CoGAN — Coupled Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_95.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_95.markups.0":{"type":"A","start":8,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1606.07536v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_96":{"id":"5f8adc94679e_96","name":"e9d4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ComboGAN — ComboGAN: Unrestrained Scalability for Image Domain Translation (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_96.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_96.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_96.markups.0":{"type":"A","start":11,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.06909","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_96.markups.1":{"type":"A","start":76,"end":82,"href":"https:\u002F\u002Fgithub.com\u002FAAnoosheh\u002FComboGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_97":{"id":"5f8adc94679e_97","name":"b578","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ConceptGAN — Learning Compositional Visual Concepts with Mutual Consistency","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_97.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_97.markups.0":{"type":"A","start":13,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06148","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_98":{"id":"5f8adc94679e_98","name":"9027","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Conditional cycleGAN — Conditional CycleGAN for Attribute Guided Face Image Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_98.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_98.markups.0":{"type":"A","start":23,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.09966","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_99":{"id":"5f8adc94679e_99","name":"0c99","type":"ULI","href":null,"layout":null,"metadata":null,"text":"constrast-GAN — Generative Semantic Manipulation with Contrasting GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_99.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_99.markups.0":{"type":"A","start":16,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.00315","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_100":{"id":"5f8adc94679e_100","name":"1845","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Context-RNN-GAN — Contextual RNN-GANs for Abstract Reasoning Diagram Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_100.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_100.markups.0":{"type":"A","start":18,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1609.09444","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_101":{"id":"5f8adc94679e_101","name":"e51d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CorrGAN — Correlated discrete data generation using adversarial training","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_101.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_101.markups.0":{"type":"A","start":10,"end":72,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.00925","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_102":{"id":"5f8adc94679e_102","name":"aa14","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Coulomb GAN — Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_102.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_102.markups.0":{"type":"A","start":14,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.08819","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_103":{"id":"5f8adc94679e_103","name":"63e9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Cover-GAN — Generative Steganography with Kerckhoffs’ Principle based on Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_103.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_103.markups.0":{"type":"A","start":12,"end":104,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.04916","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_104":{"id":"5f8adc94679e_104","name":"a526","type":"ULI","href":null,"layout":null,"metadata":null,"text":"cowboy — Defending Against Adversarial Attacks by Leveraging an Entire GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_104.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_104.markups.0":{"type":"A","start":9,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.10652","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_105":{"id":"5f8adc94679e_105","name":"eccc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CR-GAN — CR-GAN: Learning Complete Representations for Multi-view Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_105.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_105.markups.0":{"type":"A","start":9,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.11191","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_106":{"id":"5f8adc94679e_106","name":"ffa3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Cramèr GAN — The Cramer Distance as a Solution to Biased Wasserstein Gradients","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_106.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_106.markups.0":{"type":"A","start":13,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.10743","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_107":{"id":"5f8adc94679e_107","name":"69e5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Cross-GAN — Crossing Generative Adversarial Networks for Cross-View Person Re-identification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_107.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_107.markups.0":{"type":"A","start":12,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.01760","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_108":{"id":"5f8adc94679e_108","name":"a967","type":"ULI","href":null,"layout":null,"metadata":null,"text":"crVAE-GAN — Channel-Recurrent Variational Autoencoders","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_108.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_108.markups.0":{"type":"A","start":12,"end":54,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.03729","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_109":{"id":"5f8adc94679e_109","name":"53dc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CS-GAN — Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_109.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_109.markups.0":{"type":"A","start":9,"end":99,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.04887","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_110":{"id":"5f8adc94679e_110","name":"c0d7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CSG — Speech-Driven Expressive Talking Lips with Conditional Sequential Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_110.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_110.markups.0":{"type":"A","start":6,"end":103,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.00154","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_111":{"id":"5f8adc94679e_111","name":"d798","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CT-GAN — CT-GAN: Conditional Transformation Generative Adversarial Network for Image Attribute Modification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_111.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_111.markups.0":{"type":"A","start":9,"end":107,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.04812","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_112":{"id":"5f8adc94679e_112","name":"3852","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CVAE-GAN — CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_112.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_112.markups.0":{"type":"A","start":11,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.10155","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_113":{"id":"5f8adc94679e_113","name":"78e7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CycleGAN — Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_113.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_113.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_113.markups.0":{"type":"A","start":11,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.10593","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_113.markups.1":{"type":"A","start":92,"end":98,"href":"https:\u002F\u002Fgithub.com\u002Fjunyanz\u002FCycleGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_114":{"id":"5f8adc94679e_114","name":"e65b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"D-GAN — Differential Generative Adversarial Networks: Synthesizing Non-linear Facial Variations with Limited Number of Training Data","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_114.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_114.markups.0":{"type":"A","start":8,"end":132,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.10267","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_115":{"id":"5f8adc94679e_115","name":"1d89","type":"ULI","href":null,"layout":null,"metadata":null,"text":"D-WCGAN — I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_115.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_115.markups.0":{"type":"A","start":10,"end":124,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.00290","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_116":{"id":"5f8adc94679e_116","name":"d8ed","type":"ULI","href":null,"layout":null,"metadata":null,"text":"D2GAN — Dual Discriminator Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_116.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_116.markups.0":{"type":"A","start":8,"end":54,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1709.03831","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_117":{"id":"5f8adc94679e_117","name":"fd3d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"D2IA-GAN — Tagging like Humans: Diverse and Distinct Image Annotation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_117.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_117.markups.0":{"type":"A","start":11,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.00113","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_118":{"id":"5f8adc94679e_118","name":"087d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DA-GAN — DA-GAN: Instance-level Image Translation by Deep Attention Generative Adversarial Networks (with Supplementary Materials)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_118.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_118.markups.0":{"type":"A","start":9,"end":130,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1802.06454","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_119":{"id":"5f8adc94679e_119","name":"cfde","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DADA — DADA: Deep Adversarial Data Augmentation for Extremely Low Data Regime Classification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_119.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_119.markups.0":{"type":"A","start":7,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.00981","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_120":{"id":"5f8adc94679e_120","name":"466d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DAGAN — Data Augmentation Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_120.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_120.markups.0":{"type":"A","start":8,"end":57,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.04340","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_121":{"id":"5f8adc94679e_121","name":"02b4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DAN — Distributional Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_121.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_121.markups.0":{"type":"A","start":6,"end":41,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.09549","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_122":{"id":"5f8adc94679e_122","name":"c9d0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DBLRGAN — Adversarial Spatio-Temporal Learning for Video Deblurring","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_122.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_122.markups.0":{"type":"A","start":10,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.00533","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_123":{"id":"5f8adc94679e_123","name":"4139","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DCGAN — Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_123.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_123.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_123.markups.0":{"type":"A","start":8,"end":100,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1511.06434","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_123.markups.1":{"type":"A","start":102,"end":108,"href":"https:\u002F\u002Fgithub.com\u002FNewmu\u002Fdcgan_code","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_124":{"id":"5f8adc94679e_124","name":"9f22","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DE-GAN — Generative Adversarial Networks with Decoder-Encoder Output Noise","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_124.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_124.markups.0":{"type":"A","start":9,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.03923","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_125":{"id":"5f8adc94679e_125","name":"ac6d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DeblurGAN — DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_125.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_125.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_125.markups.0":{"type":"A","start":12,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.07064","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_125.markups.1":{"type":"A","start":87,"end":93,"href":"https:\u002F\u002Fgithub.com\u002FKupynOrest\u002FDeblurGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_126":{"id":"5f8adc94679e_126","name":"ce13","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DeepFD — Learning to Detect Fake Face Images in the Wild","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_126.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_126.markups.0":{"type":"A","start":9,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.08754","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_127":{"id":"5f8adc94679e_127","name":"e1b9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Defense-GAN — Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_127.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_127.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_127.markups.0":{"type":"A","start":14,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.06605","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_127.markups.1":{"type":"A","start":103,"end":109,"href":"https:\u002F\u002Fgithub.com\u002Fkabkabm\u002Fdefensegan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_128":{"id":"5f8adc94679e_128","name":"0021","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Defo-Net — Defo-Net: Learning Body Deformation using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_128.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_128.markups.0":{"type":"A","start":11,"end":84,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.05928","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_129":{"id":"5f8adc94679e_129","name":"ebd0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DeliGAN — DeLiGAN : Generative Adversarial Networks for Diverse and Limited Data (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_129.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_129.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_129.markups.0":{"type":"A","start":10,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.02071","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_129.markups.1":{"type":"A","start":82,"end":88,"href":"https:\u002F\u002Fgithub.com\u002Fval-iisc\u002Fdeligan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_130":{"id":"5f8adc94679e_130","name":"e00f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DF-GAN — Learning Disentangling and Fusing Networks for Face Completion Under Structured Occlusions","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_130.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_130.markups.0":{"type":"A","start":9,"end":99,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.04646","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_131":{"id":"5f8adc94679e_131","name":"22e0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DialogWAE — DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_131.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_131.markups.0":{"type":"A","start":12,"end":95,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.12352","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_132":{"id":"5f8adc94679e_132","name":"d712","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DiscoGAN — Learning to Discover Cross-Domain Relations with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_132.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_132.markups.0":{"type":"A","start":11,"end":91,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.05192v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_133":{"id":"5f8adc94679e_133","name":"764e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DistanceGAN — One-Sided Unsupervised Domain Mapping","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_133.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_133.markups.0":{"type":"A","start":14,"end":51,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.00826","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_134":{"id":"5f8adc94679e_134","name":"3d99","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DM-GAN — Dual Motion GAN for Future-Flow Embedded Video Prediction","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_134.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_134.markups.0":{"type":"A","start":9,"end":66,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.00284","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_135":{"id":"5f8adc94679e_135","name":"e89a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DMGAN — Disconnected Manifold Learning for Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_135.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_135.markups.0":{"type":"A","start":8,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.00880","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_136":{"id":"5f8adc94679e_136","name":"ca57","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DNA-GAN — DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_136.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_136.markups.0":{"type":"A","start":10,"end":84,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.05415","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_137":{"id":"5f8adc94679e_137","name":"e194","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DOPING — DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection with GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_137.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_137.markups.0":{"type":"A","start":9,"end":89,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.07632","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_138":{"id":"5f8adc94679e_138","name":"3fb0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"dp-GAN — Differentially Private Releasing via Deep Generative Model","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_138.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_138.markups.0":{"type":"A","start":9,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.01594","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_139":{"id":"5f8adc94679e_139","name":"6c8f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DP-GAN — DP-GAN: Diversity-Promoting Generative Adversarial Network for Generating Informative and Diversified Text","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_139.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_139.markups.0":{"type":"A","start":9,"end":115,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.01345","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_140":{"id":"5f8adc94679e_140","name":"587a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DPGAN — Differentially Private Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_140.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_140.markups.0":{"type":"A","start":8,"end":61,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1802.06739","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_141":{"id":"5f8adc94679e_141","name":"14c4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DR-GAN — Representation Learning by Rotating Your Faces","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_141.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_141.markups.0":{"type":"A","start":9,"end":55,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.11136","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_142":{"id":"5f8adc94679e_142","name":"56cf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DRAGAN — How to Train Your DRAGAN (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_142.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_142.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_142.markups.0":{"type":"A","start":9,"end":33,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.07215","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_142.markups.1":{"type":"A","start":35,"end":41,"href":"https:\u002F\u002Fgithub.com\u002Fkodalinaveen3\u002FDRAGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_143":{"id":"5f8adc94679e_143","name":"5781","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Dropout-GAN — Dropout-GAN: Learning from a Dynamic Ensemble of Discriminators","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_143.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_143.markups.0":{"type":"A","start":14,"end":77,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.11346","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_144":{"id":"5f8adc94679e_144","name":"10cc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DRPAN — Discriminative Region Proposal Adversarial Networks for High-Quality Image-to-Image Translation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_144.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_144.markups.0":{"type":"A","start":8,"end":103,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.09554","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_145":{"id":"5f8adc94679e_145","name":"cd8d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DSH-GAN — Deep Semantic Hashing with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_145.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_145.markups.0":{"type":"A","start":10,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.08275","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_146":{"id":"5f8adc94679e_146","name":"1c55","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DSP-GAN — Depth Structure Preserving Scene Image Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_146.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_146.markups.0":{"type":"A","start":10,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.00212","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_147":{"id":"5f8adc94679e_147","name":"4784","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DTLC-GAN — Generative Adversarial Image Synthesis with Decision Tree Latent Controller","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_147.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_147.markups.0":{"type":"A","start":11,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.10603","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_148":{"id":"5f8adc94679e_148","name":"dd3f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DTN — Unsupervised Cross-Domain Image Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_148.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_148.markups.0":{"type":"A","start":6,"end":48,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.02200","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_149":{"id":"5f8adc94679e_149","name":"0a01","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DTR-GAN — DTR-GAN: Dilated Temporal Relational Adversarial Network for Video Summarization","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_149.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_149.markups.0":{"type":"A","start":10,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.11228","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_150":{"id":"5f8adc94679e_150","name":"f9f0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DualGAN — DualGAN: Unsupervised Dual Learning for Image-to-Image Translation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_150.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_150.markups.0":{"type":"A","start":10,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.02510v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_151":{"id":"5f8adc94679e_151","name":"4ddc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Dualing GAN — Dualing GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_151.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_151.markups.0":{"type":"A","start":14,"end":26,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.06216","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_152":{"id":"5f8adc94679e_152","name":"88fc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"DVGAN — Human Motion Modeling using DVGANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_152.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_152.markups.0":{"type":"A","start":8,"end":42,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.10652","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_153":{"id":"5f8adc94679e_153","name":"d979","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Dynamics Transfer GAN — Dynamics Transfer GAN: Generating Video by Transferring Arbitrary Temporal Dynamics from a Source Video to a Single Target Image","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_153.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_153.markups.0":{"type":"A","start":24,"end":152,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.03534","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_154":{"id":"5f8adc94679e_154","name":"87e4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"E-GAN — Evolutionary Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_154.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_154.markups.0":{"type":"A","start":8,"end":52,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.00657","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_155":{"id":"5f8adc94679e_155","name":"71ac","type":"ULI","href":null,"layout":null,"metadata":null,"text":"EAR — Generative Model for Heterogeneous Inference","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_155.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_155.markups.0":{"type":"A","start":6,"end":50,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.09858","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_156":{"id":"5f8adc94679e_156","name":"371c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"EBGAN — Energy-based Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_156.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_156.markups.0":{"type":"A","start":8,"end":51,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1609.03126v4","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_157":{"id":"5f8adc94679e_157","name":"f947","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ecGAN — eCommerceGAN : A Generative Adversarial Network for E-commerce","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_157.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_157.markups.0":{"type":"A","start":8,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.03244","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_158":{"id":"5f8adc94679e_158","name":"253b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ED\u002F\u002FGAN — Stabilizing Training of Generative Adversarial Networks through Regularization","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_158.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_158.markups.0":{"type":"A","start":10,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.09367","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_159":{"id":"5f8adc94679e_159","name":"4f8a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Editable GAN — Editable Generative Adversarial Networks: Generating and Editing Faces Simultaneously","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_159.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_159.markups.0":{"type":"A","start":15,"end":100,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.07700","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_160":{"id":"5f8adc94679e_160","name":"8af5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"EGAN — Enhanced Experience Replay Generation for Efficient Reinforcement Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_160.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_160.markups.0":{"type":"A","start":7,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.08245","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_161":{"id":"5f8adc94679e_161","name":"3c14","type":"ULI","href":null,"layout":null,"metadata":null,"text":"EL-GAN — EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_161.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_161.markups.0":{"type":"A","start":9,"end":89,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.05525","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_162":{"id":"5f8adc94679e_162","name":"83af","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ELEGANT — ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_162.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_162.markups.0":{"type":"A","start":10,"end":97,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.10562","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_163":{"id":"5f8adc94679e_163","name":"8bb7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"EnergyWGAN — Energy-relaxed Wassertein GANs (EnergyWGAN): Towards More Stable and High Resolution Image Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_163.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_163.markups.0":{"type":"A","start":13,"end":114,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.01026","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_164":{"id":"5f8adc94679e_164","name":"5232","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ESRGAN — ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_164.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_164.markups.0":{"type":"A","start":9,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.00219","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_165":{"id":"5f8adc94679e_165","name":"7f3d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ExGAN — Eye In-Painting with Exemplar Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_165.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_165.markups.0":{"type":"A","start":8,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.03999","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_166":{"id":"5f8adc94679e_166","name":"b837","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ExposureGAN — Exposure: A White-Box Photo Post-Processing Framework (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_166.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_166.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_166.markups.0":{"type":"A","start":14,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.09602","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_166.markups.1":{"type":"A","start":69,"end":75,"href":"https:\u002F\u002Fgithub.com\u002Fyuanming-hu\u002Fexposure","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_167":{"id":"5f8adc94679e_167","name":"5716","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ExprGAN — ExprGAN: Facial Expression Editing with Controllable Expression Intensity","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_167.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_167.markups.0":{"type":"A","start":10,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.03842","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_168":{"id":"5f8adc94679e_168","name":"484c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"f-CLSWGAN — Feature Generating Networks for Zero-Shot Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_168.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_168.markups.0":{"type":"A","start":12,"end":62,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00981","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_169":{"id":"5f8adc94679e_169","name":"bcbc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"f-GAN — f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_169.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_169.markups.0":{"type":"A","start":8,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1606.00709","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_170":{"id":"5f8adc94679e_170","name":"d8af","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FairGAN — FairGAN: Fairness-aware Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_170.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_170.markups.0":{"type":"A","start":10,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.11202","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_171":{"id":"5f8adc94679e_171","name":"d471","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Fairness GAN — Fairness GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_171.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_171.markups.0":{"type":"A","start":15,"end":27,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.09910","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_172":{"id":"5f8adc94679e_172","name":"6c6b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FakeGAN — Detecting Deceptive Reviews using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_172.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_172.markups.0":{"type":"A","start":10,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.10364","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_173":{"id":"5f8adc94679e_173","name":"93ff","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FBGAN — Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_173.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_173.markups.0":{"type":"A","start":8,"end":105,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.01694","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_174":{"id":"5f8adc94679e_174","name":"9e7e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FBGAN — Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_174.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_174.markups.0":{"type":"A","start":8,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.07862","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_175":{"id":"5f8adc94679e_175","name":"3212","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FC-GAN — Fast-converging Conditional Generative Adversarial Networks for Image Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_175.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_175.markups.0":{"type":"A","start":9,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.01972","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_176":{"id":"5f8adc94679e_176","name":"499f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FF-GAN — Towards Large-Pose Face Frontalization in the Wild","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_176.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_176.markups.0":{"type":"A","start":9,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.06244","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_177":{"id":"5f8adc94679e_177","name":"26ff","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FGGAN — Adversarial Learning for Fine-grained Image Search","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_177.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_177.markups.0":{"type":"A","start":8,"end":58,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.02247","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_178":{"id":"5f8adc94679e_178","name":"8c98","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Fictitious GAN — Fictitious GAN: Training GANs with Historical Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_178.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_178.markups.0":{"type":"A","start":17,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.08647","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_179":{"id":"5f8adc94679e_179","name":"674c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FIGAN — Frame Interpolation with Multi-Scale Deep Loss Functions and Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_179.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_179.markups.0":{"type":"A","start":8,"end":100,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06045","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_180":{"id":"5f8adc94679e_180","name":"d3f4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Fila-GAN — Synthesizing Filamentary Structured Images with GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_180.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_180.markups.0":{"type":"A","start":11,"end":63,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.02185","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_181":{"id":"5f8adc94679e_181","name":"8802","type":"ULI","href":null,"layout":null,"metadata":null,"text":"First Order GAN — First Order Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_181.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_181.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_181.markups.0":{"type":"A","start":18,"end":62,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.04591","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_181.markups.1":{"type":"A","start":63,"end":69,"href":"https:\u002F\u002Fgithub.com\u002Fzalandoresearch\u002Ffirst_order_gan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_182":{"id":"5f8adc94679e_182","name":"3ae7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Fisher GAN — Fisher GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_182.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_182.markups.0":{"type":"A","start":13,"end":23,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.09675","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_183":{"id":"5f8adc94679e_183","name":"aee8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Flow-GAN — Flow-GAN: Bridging implicit and prescribed learning in generative models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_183.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_183.markups.0":{"type":"A","start":11,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.08868","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_184":{"id":"5f8adc94679e_184","name":"6fff","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FrankenGAN — rankenGAN: Guided Detail Synthesis for Building Mass-Models Using Style-Synchonized GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_184.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_184.markups.0":{"type":"A","start":13,"end":101,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.07179","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_185":{"id":"5f8adc94679e_185","name":"1318","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FSEGAN — Exploring Speech Enhancement with Generative Adversarial Networks for Robust Speech Recognition","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_185.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_185.markups.0":{"type":"A","start":9,"end":104,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.05747","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_186":{"id":"5f8adc94679e_186","name":"cd6f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FTGAN — Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_186.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_186.markups.0":{"type":"A","start":8,"end":91,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.09618","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_187":{"id":"5f8adc94679e_187","name":"f658","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FusedGAN — Semi-supervised FusedGAN for Conditional Image Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_187.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_187.markups.0":{"type":"A","start":11,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.05551","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_188":{"id":"5f8adc94679e_188","name":"0626","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FusionGAN — Learning to Fuse Music Genres with Generative Adversarial Dual Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_188.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_188.markups.0":{"type":"A","start":12,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.01456","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_189":{"id":"5f8adc94679e_189","name":"ad65","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FusionGAN — Generating a Fusion Image: One’s Identity and Another’s Shape","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_189.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_189.markups.0":{"type":"A","start":12,"end":73,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.07455","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_190":{"id":"5f8adc94679e_190","name":"151b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"G2-GAN — Geometry Guided Adversarial Facial Expression Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_190.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_190.markups.0":{"type":"A","start":9,"end":64,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.03474","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_191":{"id":"5f8adc94679e_191","name":"e3b9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAAN — Generative Adversarial Autoencoder Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_191.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_191.markups.0":{"type":"A","start":7,"end":50,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.08887","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_192":{"id":"5f8adc94679e_192","name":"02b9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAF — Generative Adversarial Forests for Better Conditioned Adversarial Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_192.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_192.markups.0":{"type":"A","start":6,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.05185","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_193":{"id":"5f8adc94679e_193","name":"71f7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAGAN — GAGAN: Geometry-Aware Generative Adverserial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_193.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_193.markups.0":{"type":"A","start":8,"end":61,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00684","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_194":{"id":"5f8adc94679e_194","name":"4aca","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAIA — Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_194.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_194.markups.0":{"type":"A","start":7,"end":147,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.06650","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_195":{"id":"5f8adc94679e_195","name":"dd2c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAIN — GAIN: Missing Data Imputation using Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_195.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_195.markups.0":{"type":"A","start":7,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.02920","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_196":{"id":"5f8adc94679e_196","name":"2971","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAMN — Generative Adversarial Mapping Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_196.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_196.markups.0":{"type":"A","start":7,"end":46,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.09820","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_197":{"id":"5f8adc94679e_197","name":"5424","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN — Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_197.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_197.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_197.markups.0":{"type":"A","start":6,"end":37,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1406.2661","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_197.markups.1":{"type":"A","start":39,"end":45,"href":"https:\u002F\u002Fgithub.com\u002Fgoodfeli\u002Fadversarial","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_198":{"id":"5f8adc94679e_198","name":"d3c3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN Lab — GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_198.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_198.markups.0":{"type":"A","start":10,"end":104,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.01587","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_199":{"id":"5f8adc94679e_199","name":"13e1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN Q-learning — GAN Q-learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_199.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_199.markups.0":{"type":"A","start":17,"end":31,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.04874","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_200":{"id":"5f8adc94679e_200","name":"3eaf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-AD — Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_200.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_200.markups.0":{"type":"A","start":9,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.04758","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_201":{"id":"5f8adc94679e_201","name":"a303","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-ATV — A Novel Approach to Artistic Textual Visualization via GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_201.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_201.markups.0":{"type":"A","start":10,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.10553","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_202":{"id":"5f8adc94679e_202","name":"b93f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-CLS — Generative Adversarial Text to Image Synthesis (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_202.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_202.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_202.markups.0":{"type":"A","start":10,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1605.05396","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_202.markups.1":{"type":"A","start":58,"end":64,"href":"https:\u002F\u002Fgithub.com\u002Freedscot\u002Ficml2016","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_203":{"id":"5f8adc94679e_203","name":"3542","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-RS — Towards Qualitative Advancement of Underwater Machine Vision with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_203.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_203.markups.0":{"type":"A","start":9,"end":106,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00736","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_204":{"id":"5f8adc94679e_204","name":"39b2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-SD — Virtual-Taobao: Virtualizing Real-world Online Retail Environment for Reinforcement Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_204.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_204.markups.0":{"type":"A","start":9,"end":101,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.10000","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_205":{"id":"5f8adc94679e_205","name":"bad0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-sep — GANs for Biological Image Synthesis (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_205.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_205.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_205.markups.0":{"type":"A","start":10,"end":45,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.04692","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_205.markups.1":{"type":"A","start":47,"end":53,"href":"https:\u002F\u002Fgithub.com\u002Faosokin\u002Fbiogans","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_206":{"id":"5f8adc94679e_206","name":"7de5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-VFS — Generative Adversarial Network-based Synthesis of Visible Faces from Polarimetric Thermal Faces","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_206.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_206.markups.0":{"type":"A","start":10,"end":105,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.02681","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_207":{"id":"5f8adc94679e_207","name":"3abb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAN-Word2Vec — Adversarial Training of Word2Vec for Basket Completion","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_207.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_207.markups.0":{"type":"A","start":15,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.08720","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_208":{"id":"5f8adc94679e_208","name":"2dfb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GANAX — GANAX: A Unified MIMD-SIMD Acceleration for Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_208.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_208.markups.0":{"type":"A","start":8,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.01107","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_209":{"id":"5f8adc94679e_209","name":"0bd7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GANCS — Deep Generative Adversarial Networks for Compressed Sensing Automates MRI","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_209.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_209.markups.0":{"type":"A","start":8,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.00051","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_210":{"id":"5f8adc94679e_210","name":"d8bc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GANDI — Guiding the search in continuous state-action spaces by learning an action sampling distribution from off-target samples","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_210.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_210.markups.0":{"type":"A","start":8,"end":128,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.01391","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_211":{"id":"5f8adc94679e_211","name":"1fbf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GANG — GANGs: Generative Adversarial Network Games","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_211.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_211.markups.0":{"type":"A","start":7,"end":50,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00679","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_212":{"id":"5f8adc94679e_212","name":"bc74","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GANG — Beyond Local Nash Equilibria for Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_212.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_212.markups.0":{"type":"A","start":7,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.07268","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_213":{"id":"5f8adc94679e_213","name":"6a03","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GANosaic — GANosaic: Mosaic Creation with Generative Texture Manifolds","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_213.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_213.markups.0":{"type":"A","start":11,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00269","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_214":{"id":"5f8adc94679e_214","name":"51ba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GANVO — GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_214.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_214.markups.0":{"type":"A","start":8,"end":116,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.05786","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_215":{"id":"5f8adc94679e_215","name":"8e9a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAP — Context-Aware Generative Adversarial Privacy","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_215.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_215.markups.0":{"type":"A","start":6,"end":50,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.09549","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_216":{"id":"5f8adc94679e_216","name":"d8b1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAP — Generative Adversarial Privacy","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_216.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_216.markups.0":{"type":"A","start":6,"end":36,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.05306","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_217":{"id":"5f8adc94679e_217","name":"fedc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GATS — Sample-Efficient Deep RL with Generative Adversarial Tree Search","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_217.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_217.markups.0":{"type":"A","start":7,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.05780","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_218":{"id":"5f8adc94679e_218","name":"ed9a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GAWWN — Learning What and Where to Draw (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_218.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_218.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_218.markups.0":{"type":"A","start":8,"end":39,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1610.02454","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_218.markups.1":{"type":"A","start":41,"end":47,"href":"https:\u002F\u002Fgithub.com\u002Freedscot\u002Fnips2016","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_219":{"id":"5f8adc94679e_219","name":"2830","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GC-GAN — Geometry-Contrastive Generative Adversarial Network for Facial Expression Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_219.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_219.markups.0":{"type":"A","start":9,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.01822","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_220":{"id":"5f8adc94679e_220","name":"15f1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GcGAN — Geometry-Consistent Adversarial Networks for One-Sided Unsupervised Domain Mapping","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_220.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_220.markups.0":{"type":"A","start":8,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.05852","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_221":{"id":"5f8adc94679e_221","name":"2a37","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GeneGAN — GeneGAN: Learning Object Transfiguration and Attribute Subspace from Unpaired Data (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_221.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_221.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_221.markups.0":{"type":"A","start":10,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.04932","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_221.markups.1":{"type":"A","start":94,"end":100,"href":"https:\u002F\u002Fgithub.com\u002FPrinsphield\u002FGeneGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_222":{"id":"5f8adc94679e_222","name":"e4fd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GeoGAN — Generating Instance Segmentation Annotation by Geometry-guided GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_222.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_222.markups.0":{"type":"A","start":9,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.08839","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_223":{"id":"5f8adc94679e_223","name":"6893","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Geometric GAN — Geometric GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_223.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_223.markups.0":{"type":"A","start":16,"end":29,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.02894","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_224":{"id":"5f8adc94679e_224","name":"1acb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GIN — Generative Invertible Networks (GIN): Pathophysiology-Interpretable Feature Mapping and Virtual Patient Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_224.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_224.markups.0":{"type":"A","start":6,"end":120,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.04495","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_225":{"id":"5f8adc94679e_225","name":"d1c0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GLCA-GAN — Global and Local Consistent Age Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_225.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_225.markups.0":{"type":"A","start":11,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.08390","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_226":{"id":"5f8adc94679e_226","name":"7957","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GM-GAN — Gaussian Mixture Generative Adversarial Networks for Diverse Datasets, and the Unsupervised Clustering of Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_226.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_226.markups.0":{"type":"A","start":9,"end":121,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.10356","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_227":{"id":"5f8adc94679e_227","name":"1130","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GMAN — Generative Multi-Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_227.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_227.markups.0":{"type":"A","start":7,"end":44,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1611.01673","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_228":{"id":"5f8adc94679e_228","name":"6ccf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GMM-GAN — Towards Understanding the Dynamics of Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_228.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_228.markups.0":{"type":"A","start":10,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.09884","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_229":{"id":"5f8adc94679e_229","name":"c4fc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GoGAN — Gang of GANs: Generative Adversarial Networks with Maximum Margin Ranking","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_229.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_229.markups.0":{"type":"A","start":8,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.04865","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_230":{"id":"5f8adc94679e_230","name":"7652","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GONet — GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_230.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_230.markups.0":{"type":"A","start":8,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.03254","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_231":{"id":"5f8adc94679e_231","name":"a710","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GP-GAN — GP-GAN: Towards Realistic High-Resolution Image Blending (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_231.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_231.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_231.markups.0":{"type":"A","start":9,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.07195","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_231.markups.1":{"type":"A","start":67,"end":73,"href":"https:\u002F\u002Fgithub.com\u002Fwuhuikai\u002FGP-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_232":{"id":"5f8adc94679e_232","name":"9c48","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GP-GAN — GP-GAN: Gender Preserving GAN for Synthesizing Faces from Landmarks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_232.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_232.markups.0":{"type":"A","start":9,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.00962","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_233":{"id":"5f8adc94679e_233","name":"3ca9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GPU — A generative adversarial framework for positive-unlabeled classification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_233.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_233.markups.0":{"type":"A","start":6,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.08054","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_234":{"id":"5f8adc94679e_234","name":"5ba3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GRAN — Generating images with recurrent adversarial networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_234.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_234.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_234.markups.0":{"type":"A","start":7,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1602.05110","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_234.markups.1":{"type":"A","start":62,"end":68,"href":"https:\u002F\u002Fgithub.com\u002Fjiwoongim\u002FGRAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_235":{"id":"5f8adc94679e_235","name":"ded6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Graphical-GAN — Graphical Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_235.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_235.markups.0":{"type":"A","start":16,"end":57,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.03429","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_236":{"id":"5f8adc94679e_236","name":"9349","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GraphSGAN — Semi-supervised Learning on Graphs with Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_236.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_236.markups.0":{"type":"A","start":12,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.00130","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_237":{"id":"5f8adc94679e_237","name":"c3e8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GraspGAN — Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_237.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_237.markups.0":{"type":"A","start":11,"end":96,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.07857","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_238":{"id":"5f8adc94679e_238","name":"8a74","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GT-GAN — Deep Graph Translation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_238.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_238.markups.0":{"type":"A","start":9,"end":31,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.09980","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_239":{"id":"5f8adc94679e_239","name":"1dfa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"HAN — Chinese Typeface Transformation with Hierarchical Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_239.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_239.markups.0":{"type":"A","start":6,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06448","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_240":{"id":"5f8adc94679e_240","name":"f8b4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"HAN — Bidirectional Learning for Robust Neural Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_240.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_240.markups.0":{"type":"A","start":6,"end":55,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.08006","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_241":{"id":"5f8adc94679e_241","name":"1591","type":"ULI","href":null,"layout":null,"metadata":null,"text":"HiGAN — Exploiting Images for Video Recognition with Hierarchical Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_241.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_241.markups.0":{"type":"A","start":8,"end":97,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.04384","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_242":{"id":"5f8adc94679e_242","name":"b42b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"HP-GAN — HP-GAN: Probabilistic 3D human motion prediction via GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_242.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_242.markups.0":{"type":"A","start":9,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.09561","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_243":{"id":"5f8adc94679e_243","name":"4a04","type":"ULI","href":null,"layout":null,"metadata":null,"text":"HR-DCGAN — High-Resolution Deep Convolutional Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_243.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_243.markups.0":{"type":"A","start":11,"end":77,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06491","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_244":{"id":"5f8adc94679e_244","name":"265b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"hredGAN — Multi-turn Dialogue Response Generation in an Adversarial Learning framework","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_244.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_244.markups.0":{"type":"A","start":10,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.11752","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_245":{"id":"5f8adc94679e_245","name":"5415","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IAN — Neural Photo Editing with Introspective Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_245.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_245.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_245.markups.0":{"type":"A","start":6,"end":66,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1609.07093","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_245.markups.1":{"type":"A","start":68,"end":74,"href":"https:\u002F\u002Fgithub.com\u002Fajbrock\u002FNeural-Photo-Editor","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_246":{"id":"5f8adc94679e_246","name":"3493","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IcGAN — Invertible Conditional GANs for image editing (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_246.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_246.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_246.markups.0":{"type":"A","start":8,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.06355","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_246.markups.1":{"type":"A","start":55,"end":61,"href":"https:\u002F\u002Fgithub.com\u002FGuim3\u002FIcGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_247":{"id":"5f8adc94679e_247","name":"f379","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ID-CGAN — Image De-raining Using a Conditional Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_247.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_247.markups.0":{"type":"A","start":10,"end":77,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.05957v3","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_248":{"id":"5f8adc94679e_248","name":"dea8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IdCycleGAN — Face Translation between Images and Videos using Identity-aware CycleGAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_248.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_248.markups.0":{"type":"A","start":13,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00971","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_249":{"id":"5f8adc94679e_249","name":"d6b1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IFcVAEGAN — Conditional Autoencoders with Adversarial Information Factorization","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_249.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_249.markups.0":{"type":"A","start":12,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.05175","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_250":{"id":"5f8adc94679e_250","name":"9165","type":"ULI","href":null,"layout":null,"metadata":null,"text":"iGAN — Generative Visual Manipulation on the Natural Image Manifold (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_250.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_250.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_250.markups.0":{"type":"A","start":7,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1609.03552v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_250.markups.1":{"type":"A","start":69,"end":75,"href":"https:\u002F\u002Fgithub.com\u002Fjunyanz\u002FiGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_251":{"id":"5f8adc94679e_251","name":"1fc9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IGMM-GAN — Coupled IGMM-GANs for deep multimodal anomaly detection in human mobility data","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_251.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_251.markups.0":{"type":"A","start":11,"end":89,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.02728","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_252":{"id":"5f8adc94679e_252","name":"f924","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Improved GAN — Improved Techniques for Training GANs (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_252.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_252.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_252.markups.0":{"type":"A","start":15,"end":52,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1606.03498","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_252.markups.1":{"type":"A","start":54,"end":60,"href":"https:\u002F\u002Fgithub.com\u002Fopenai\u002Fimproved-gan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_253":{"id":"5f8adc94679e_253","name":"9140","type":"ULI","href":null,"layout":null,"metadata":null,"text":"In2I — In2I : Unsupervised Multi-Image-to-Image Translation Using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_253.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_253.markups.0":{"type":"A","start":7,"end":97,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.09334","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_254":{"id":"5f8adc94679e_254","name":"2b5f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"InfoGAN — InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets(github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_254.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_254.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_254.markups.0":{"type":"A","start":10,"end":110,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1606.03657v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_254.markups.1":{"type":"A","start":111,"end":117,"href":"https:\u002F\u002Fgithub.com\u002Fopenai\u002FInfoGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_255":{"id":"5f8adc94679e_255","name":"c1b7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IntroVAE — IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_255.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_255.markups.0":{"type":"A","start":11,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.06358","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_256":{"id":"5f8adc94679e_256","name":"421d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IR2VI — IR2VI: Enhanced Night Environmental Perception by Unsupervised Thermal Image Translation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_256.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_256.markups.0":{"type":"A","start":8,"end":96,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.09565","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_257":{"id":"5f8adc94679e_257","name":"ec4a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IRGAN — IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_257.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_257.markups.0":{"type":"A","start":8,"end":101,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.10513v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_258":{"id":"5f8adc94679e_258","name":"0603","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IRGAN — Generative Adversarial Nets for Information Retrieval: Fundamentals and Advances","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_258.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_258.markups.0":{"type":"A","start":8,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.03577","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_259":{"id":"5f8adc94679e_259","name":"cb91","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ISGAN — Invisible Steganography via Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_259.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_259.markups.0":{"type":"A","start":8,"end":66,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.08571","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_260":{"id":"5f8adc94679e_260","name":"1e81","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ISP-GPM — Inner Space Preserving Generative Pose Machine","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_260.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_260.markups.0":{"type":"A","start":10,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.02104","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_261":{"id":"5f8adc94679e_261","name":"fc7c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Iterative-GAN — Two Birds with One Stone: Iteratively Learn Facial Attributes with GANs (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_261.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_261.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_261.markups.0":{"type":"A","start":16,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06078","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_261.markups.1":{"type":"A","start":89,"end":95,"href":"https:\u002F\u002Fgithub.com\u002Fpunkcure\u002FIterative-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_262":{"id":"5f8adc94679e_262","name":"6fb1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IterGAN — IterGANs: Iterative GANs to Learn and Control 3D Object Transformation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_262.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_262.markups.0":{"type":"A","start":10,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.05651","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_263":{"id":"5f8adc94679e_263","name":"71f6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IVE-GAN — IVE-GAN: Invariant Encoding Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_263.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_263.markups.0":{"type":"A","start":10,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.08646","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_264":{"id":"5f8adc94679e_264","name":"5162","type":"ULI","href":null,"layout":null,"metadata":null,"text":"iVGAN — Towards an Understanding of Our World by GANing Videos in the Wild (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_264.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_264.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_264.markups.0":{"type":"A","start":8,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.11453","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_264.markups.1":{"type":"A","start":76,"end":82,"href":"https:\u002F\u002Fgithub.com\u002Fbernhard2202\u002Fimproved-video-gan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_265":{"id":"5f8adc94679e_265","name":"952e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"IWGAN — On Unifying Deep Generative Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_265.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_265.markups.0":{"type":"A","start":8,"end":42,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.00550","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_266":{"id":"5f8adc94679e_266","name":"1def","type":"ULI","href":null,"layout":null,"metadata":null,"text":"JointGAN — JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_266.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_266.markups.0":{"type":"A","start":11,"end":94,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.02978","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_267":{"id":"5f8adc94679e_267","name":"2af8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"JR-GAN — JR-GAN: Jacobian Regularization for Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_267.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_267.markups.0":{"type":"A","start":9,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.09235","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_268":{"id":"5f8adc94679e_268","name":"e25f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"KBGAN — KBGAN: Adversarial Learning for Knowledge Graph Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_268.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_268.markups.0":{"type":"A","start":8,"end":66,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.04071","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_269":{"id":"5f8adc94679e_269","name":"7222","type":"ULI","href":null,"layout":null,"metadata":null,"text":"KGAN — KGAN: How to Break The Minimax Game in GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_269.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_269.markups.0":{"type":"A","start":7,"end":49,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.01744","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_270":{"id":"5f8adc94679e_270","name":"b5eb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"l-GAN — Representation Learning and Adversarial Generation of 3D Point Clouds","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_270.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_270.markups.0":{"type":"A","start":8,"end":77,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.02392","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_271":{"id":"5f8adc94679e_271","name":"0d45","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LAC-GAN — Grounded Language Understanding for Manipulation Instructions Using GAN-Based Classification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_271.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_271.markups.0":{"type":"A","start":10,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.05096","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_272":{"id":"5f8adc94679e_272","name":"a17c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LAGAN — Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_272.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_272.markups.0":{"type":"A","start":8,"end":114,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.05927","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_273":{"id":"5f8adc94679e_273","name":"f8b7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LAPGAN — Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_273.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_273.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_273.markups.0":{"type":"A","start":9,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1506.05751","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_273.markups.1":{"type":"A","start":89,"end":95,"href":"https:\u002F\u002Fgithub.com\u002Ffacebook\u002Feyescream","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_274":{"id":"5f8adc94679e_274","name":"df5a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LB-GAN — Load Balanced GANs for Multi-view Face Image Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_274.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_274.markups.0":{"type":"A","start":9,"end":63,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1802.07447","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_275":{"id":"5f8adc94679e_275","name":"34f8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LBT — Learning Implicit Generative Models by Teaching Explicit Ones","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_275.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_275.markups.0":{"type":"A","start":6,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.03870","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_276":{"id":"5f8adc94679e_276","name":"383f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LCC-GAN — Adversarial Learning with Local Coordinate Coding","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_276.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_276.markups.0":{"type":"A","start":10,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.04895","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_277":{"id":"5f8adc94679e_277","name":"e40a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LD-GAN — Linear Discriminant Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_277.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_277.markups.0":{"type":"A","start":9,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.07831","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_278":{"id":"5f8adc94679e_278","name":"4e60","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LDAN — Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Face Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_278.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_278.markups.0":{"type":"A","start":7,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.01993","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_279":{"id":"5f8adc94679e_279","name":"78c7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LeakGAN — Long Text Generation via Adversarial Training with Leaked Information","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_279.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_279.markups.0":{"type":"A","start":10,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.08624","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_280":{"id":"5f8adc94679e_280","name":"1168","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LeGAN — Likelihood Estimation for Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_280.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_280.markups.0":{"type":"A","start":8,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.07530","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_281":{"id":"5f8adc94679e_281","name":"102d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LGAN — Global versus Localized Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_281.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_281.markups.0":{"type":"A","start":7,"end":58,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06020","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_282":{"id":"5f8adc94679e_282","name":"8ac9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Lipizzaner — Towards Distributed Coevolutionary GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_282.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_282.markups.0":{"type":"A","start":13,"end":52,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.08194","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_283":{"id":"5f8adc94679e_283","name":"1ce1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LR-GAN — LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_283.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_283.markups.0":{"type":"A","start":9,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.01560v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_284":{"id":"5f8adc94679e_284","name":"4847","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LS-GAN — Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_284.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_284.markups.0":{"type":"A","start":9,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.06264","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_285":{"id":"5f8adc94679e_285","name":"458e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LSGAN — Least Squares Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_285.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_285.markups.0":{"type":"A","start":8,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.04076v3","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_286":{"id":"5f8adc94679e_286","name":"16d3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"M-AAE — Mask-aware Photorealistic Face Attribute Manipulation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_286.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_286.markups.0":{"type":"A","start":8,"end":61,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.08882","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_287":{"id":"5f8adc94679e_287","name":"a131","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MAD-GAN — Multi-Agent Diverse Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_287.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_287.markups.0":{"type":"A","start":10,"end":61,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.02906","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_288":{"id":"5f8adc94679e_288","name":"b234","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MAGAN — MAGAN: Margin Adaptation for Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_288.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_288.markups.0":{"type":"A","start":8,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.03817v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_289":{"id":"5f8adc94679e_289","name":"083c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MAGAN — MAGAN: Aligning Biological Manifolds","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_289.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_289.markups.0":{"type":"A","start":8,"end":44,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.00385","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_290":{"id":"5f8adc94679e_290","name":"eed1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MalGAN — Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_290.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_290.markups.0":{"type":"A","start":9,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.05983v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_291":{"id":"5f8adc94679e_291","name":"d6e8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MaliGAN — Maximum-Likelihood Augmented Discrete Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_291.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_291.markups.0":{"type":"A","start":10,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.07983","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_292":{"id":"5f8adc94679e_292","name":"87d5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"manifold-WGAN — Manifold-valued Image Generation with Wasserstein Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_292.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_292.markups.0":{"type":"A","start":16,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.01551","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_293":{"id":"5f8adc94679e_293","name":"333e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MARTA-GAN — Deep Unsupervised Representation Learning for Remote Sensing Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_293.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_293.markups.0":{"type":"A","start":12,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.08879","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_294":{"id":"5f8adc94679e_294","name":"a13e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MaskGAN — MaskGAN: Better Text Generation via Filling in the ______","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_294.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_294.markups.0":{"type":"A","start":10,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.07736","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_295":{"id":"5f8adc94679e_295","name":"9061","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MC-GAN — Multi-Content GAN for Few-Shot Font Style Transfer (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_295.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_295.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_295.markups.0":{"type":"A","start":9,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00516","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_295.markups.1":{"type":"A","start":61,"end":67,"href":"https:\u002F\u002Fgithub.com\u002Fazadis\u002FMC-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_296":{"id":"5f8adc94679e_296","name":"aee9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MC-GAN — MC-GAN: Multi-conditional Generative Adversarial Network for Image Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_296.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_296.markups.0":{"type":"A","start":9,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.01123","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_297":{"id":"5f8adc94679e_297","name":"82fc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"McGAN — McGan: Mean and Covariance Feature Matching GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_297.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_297.markups.0":{"type":"A","start":8,"end":55,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.08398v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_298":{"id":"5f8adc94679e_298","name":"a686","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MD-GAN — Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_298.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_298.markups.0":{"type":"A","start":9,"end":105,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.07592","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_299":{"id":"5f8adc94679e_299","name":"b746","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MDGAN — Mode Regularized Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_299.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_299.markups.0":{"type":"A","start":8,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.02136","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_300":{"id":"5f8adc94679e_300","name":"720c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MedGAN — Generating Multi-label Discrete Electronic Health Records using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_300.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_300.markups.0":{"type":"A","start":9,"end":104,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.06490v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_301":{"id":"5f8adc94679e_301","name":"908b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MedGAN — MedGAN: Medical Image Translation using GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_301.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_301.markups.0":{"type":"A","start":9,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.06397","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_302":{"id":"5f8adc94679e_302","name":"e1f4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MEGAN — MEGAN: Mixture of Experts of Generative Adversarial Networks for Multimodal Image Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_302.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_302.markups.0":{"type":"A","start":8,"end":100,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.02481","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_303":{"id":"5f8adc94679e_303","name":"af3e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MelanoGAN — MelanoGANs: High Resolution Skin Lesion Synthesis with GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_303.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_303.markups.0":{"type":"A","start":12,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.04338","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_304":{"id":"5f8adc94679e_304","name":"ea75","type":"ULI","href":null,"layout":null,"metadata":null,"text":"memoryGAN — Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_304.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_304.markups.0":{"type":"A","start":12,"end":93,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.01500","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_305":{"id":"5f8adc94679e_305","name":"7d90","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MeRGAN — Memory Replay GANs: learning to generate images from new categories without forgetting","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_305.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_305.markups.0":{"type":"A","start":9,"end":95,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.02058","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_306":{"id":"5f8adc94679e_306","name":"8509","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MGAN — Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_306.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_306.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_306.markups.0":{"type":"A","start":7,"end":93,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1604.04382","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_306.markups.1":{"type":"A","start":95,"end":101,"href":"https:\u002F\u002Fgithub.com\u002Fchuanli11\u002FMGANs","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_307":{"id":"5f8adc94679e_307","name":"092d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MGGAN — Multi-Generator Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_307.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_307.markups.0":{"type":"A","start":8,"end":51,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.02556","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_308":{"id":"5f8adc94679e_308","name":"76b3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MGGAN — MGGAN: Solving Mode Collapse using Manifold Guided Training","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_308.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_308.markups.0":{"type":"A","start":8,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.04391","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_309":{"id":"5f8adc94679e_309","name":"5d83","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MIL-GAN — Multimodal Storytelling via Generative Adversarial Imitation Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_309.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_309.markups.0":{"type":"A","start":10,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.01455","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_310":{"id":"5f8adc94679e_310","name":"0ca7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MinLGAN — Anomaly Detection via Minimum Likelihood Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_310.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_310.markups.0":{"type":"A","start":10,"end":82,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.00200","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_311":{"id":"5f8adc94679e_311","name":"4561","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MIX+GAN — Generalization and Equilibrium in Generative Adversarial Nets (GANs)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_311.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_311.markups.0":{"type":"A","start":10,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.00573v3","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_312":{"id":"5f8adc94679e_312","name":"e488","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MIXGAN — MIXGAN: Learning Concepts from Different Domains for Mixture Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_312.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_312.markups.0":{"type":"A","start":9,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.01659","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_313":{"id":"5f8adc94679e_313","name":"0cba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MLGAN — Metric Learning-based Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_313.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_313.markups.0":{"type":"A","start":8,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.02792","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_314":{"id":"5f8adc94679e_314","name":"40f0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MMC-GAN — A Multimodal Classifier Generative Adversarial Network for Carry and Place Tasks from Ambiguous Language Instructions","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_314.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_314.markups.0":{"type":"A","start":10,"end":127,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.03847","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_315":{"id":"5f8adc94679e_315","name":"2c8c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MMD-GAN — MMD GAN: Towards Deeper Understanding of Moment Matching Network (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_315.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_315.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_315.markups.0":{"type":"A","start":10,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.08584","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_315.markups.1":{"type":"A","start":76,"end":82,"href":"https:\u002F\u002Fgithub.com\u002Fdougalsutherland\u002Fopt-mmd","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_316":{"id":"5f8adc94679e_316","name":"ec47","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MMGAN — MMGAN: Manifold Matching Generative Adversarial Network for Generating Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_316.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_316.markups.0":{"type":"A","start":8,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.08273","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_317":{"id":"5f8adc94679e_317","name":"ebe0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MoCoGAN — MoCoGAN: Decomposing Motion and Content for Video Generation (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_317.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_317.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_317.markups.0":{"type":"A","start":10,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.04993","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_317.markups.1":{"type":"A","start":72,"end":78,"href":"https:\u002F\u002Fgithub.com\u002Fsergeytulyakov\u002Fmocogan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_318":{"id":"5f8adc94679e_318","name":"0b95","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Modified GAN-CLS — Generate the corresponding Image from Text Description using Modified GAN-CLS Algorithm","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_318.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_318.markups.0":{"type":"A","start":19,"end":106,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.11302","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_319":{"id":"5f8adc94679e_319","name":"5742","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ModularGAN — Modular Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_319.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_319.markups.0":{"type":"A","start":13,"end":52,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.03343","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_320":{"id":"5f8adc94679e_320","name":"5b4a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MolGAN — MolGAN: An implicit generative model for small molecular graphs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_320.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_320.markups.0":{"type":"A","start":9,"end":72,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.11973","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_321":{"id":"5f8adc94679e_321","name":"5331","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MPM-GAN — Message Passing Multi-Agent GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_321.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_321.markups.0":{"type":"A","start":10,"end":42,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.01294","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_322":{"id":"5f8adc94679e_322","name":"3e57","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MS-GAN — Temporal Coherency based Criteria for Predicting Video Frames using Deep Multi-stage Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_322.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_322.markups.0":{"type":"A","start":9,"end":125,"href":"http:\u002F\u002Fpapers.nips.cc\u002Fpaper\u002F7014-temporal-coherency-based-criteria-for-predicting-video-frames-using-deep-multi-stage-generative-adversarial-networks","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_323":{"id":"5f8adc94679e_323","name":"9e06","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MTGAN — MTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_323.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_323.markups.0":{"type":"A","start":8,"end":96,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.09059","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_324":{"id":"5f8adc94679e_324","name":"4aa2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MuseGAN — MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_324.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_324.markups.0":{"type":"A","start":10,"end":129,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.06298","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_325":{"id":"5f8adc94679e_325","name":"0bfb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MV-BiGAN — Multi-view Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_325.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_325.markups.0":{"type":"A","start":11,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.02019v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_326":{"id":"5f8adc94679e_326","name":"d74a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"N2RPP — N2RPP: An Adversarial Network to Rebuild Plantar Pressure for ACLD Patients","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_326.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_326.markups.0":{"type":"A","start":8,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.02825","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_327":{"id":"5f8adc94679e_327","name":"8973","type":"ULI","href":null,"layout":null,"metadata":null,"text":"NAN — Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_327.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_327.markups.0":{"type":"A","start":6,"end":122,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.03287","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_328":{"id":"5f8adc94679e_328","name":"5ddb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"NCE-GAN — Dihedral angle prediction using generative adversarial networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_328.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_328.markups.0":{"type":"A","start":10,"end":73,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.10996","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_329":{"id":"5f8adc94679e_329","name":"e3c8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ND-GAN — Novelty Detection with GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_329.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_329.markups.0":{"type":"A","start":9,"end":35,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.10560","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_330":{"id":"5f8adc94679e_330","name":"ac1c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"NetGAN — NetGAN: Generating Graphs via Random Walks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_330.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_330.markups.0":{"type":"A","start":9,"end":51,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.00816","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_331":{"id":"5f8adc94679e_331","name":"20b3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"OCAN — One-Class Adversarial Nets for Fraud Detection","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_331.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_331.markups.0":{"type":"A","start":7,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.01798","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_332":{"id":"5f8adc94679e_332","name":"25c0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"OptionGAN — OptionGAN: Learning Joint Reward-Policy Options using Generative Adversarial Inverse Reinforcement Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_332.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_332.markups.0":{"type":"A","start":12,"end":119,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.06683","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_333":{"id":"5f8adc94679e_333","name":"e4a4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ORGAN — Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_333.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_333.markups.0":{"type":"A","start":8,"end":99,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.10843","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_334":{"id":"5f8adc94679e_334","name":"e48a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ORGAN — 3D Reconstruction of Incomplete Archaeological Objects Using a Generative Adversary Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_334.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_334.markups.0":{"type":"A","start":8,"end":99,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.06363","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_335":{"id":"5f8adc94679e_335","name":"cd1d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"OT-GAN — Improving GANs Using Optimal Transport","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_335.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_335.markups.0":{"type":"A","start":9,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.05573","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_336":{"id":"5f8adc94679e_336","name":"5ca1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PacGAN — PacGAN: The power of two samples in generative adversarial networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_336.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_336.markups.0":{"type":"A","start":9,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.04086","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_337":{"id":"5f8adc94679e_337","name":"a204","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PAN — Perceptual Adversarial Networks for Image-to-Image Transformation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_337.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_337.markups.0":{"type":"A","start":6,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.09138","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_338":{"id":"5f8adc94679e_338","name":"af86","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PassGAN — PassGAN: A Deep Learning Approach for Password Guessing","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_338.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_338.markups.0":{"type":"A","start":10,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.00440","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_339":{"id":"5f8adc94679e_339","name":"8226","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PD-WGAN — Primal-Dual Wasserstein GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_339.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_339.markups.0":{"type":"A","start":10,"end":37,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.09575","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_340":{"id":"5f8adc94679e_340","name":"1f94","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Perceptual GAN — Perceptual Generative Adversarial Networks for Small Object Detection","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_340.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_340.markups.0":{"type":"A","start":17,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.05274","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_341":{"id":"5f8adc94679e_341","name":"15ee","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PGAN — Probabilistic Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_341.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_341.markups.0":{"type":"A","start":7,"end":52,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.01886","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_342":{"id":"5f8adc94679e_342","name":"df67","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PGD-GAN — Solving Linear Inverse Problems Using GAN Priors: An Algorithm with Provable Guarantees","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_342.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_342.markups.0":{"type":"A","start":10,"end":97,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.08406","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_343":{"id":"5f8adc94679e_343","name":"9305","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PGGAN — Patch-Based Image Inpainting with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_343.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_343.markups.0":{"type":"A","start":8,"end":73,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.07422","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_344":{"id":"5f8adc94679e_344","name":"a827","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PIONEER — Pioneer Networks: Progressively Growing Generative Autoencoder","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_344.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_344.markups.0":{"type":"A","start":10,"end":72,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.03026","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_345":{"id":"5f8adc94679e_345","name":"085a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Pip-GAN — Pipeline Generative Adversarial Networks for Facial Images Generation with Multiple Attributes","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_345.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_345.markups.0":{"type":"A","start":10,"end":104,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.10742","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_346":{"id":"5f8adc94679e_346","name":"211d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"pix2pix — Image-to-Image Translation with Conditional Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_346.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_346.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_346.markups.0":{"type":"A","start":10,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.07004","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_346.markups.1":{"type":"A","start":76,"end":82,"href":"https:\u002F\u002Fgithub.com\u002Fphillipi\u002Fpix2pix","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_347":{"id":"5f8adc94679e_347","name":"771e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"pix2pixHD — High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_347.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_347.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_347.markups.0":{"type":"A","start":12,"end":91,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.11585","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_347.markups.1":{"type":"A","start":93,"end":99,"href":"https:\u002F\u002Fgithub.com\u002FNVIDIA\u002Fpix2pixHD","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_348":{"id":"5f8adc94679e_348","name":"2ddd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PixelGAN — PixelGAN Autoencoders","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_348.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_348.markups.0":{"type":"A","start":11,"end":32,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.00531","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_349":{"id":"5f8adc94679e_349","name":"b767","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PM-GAN — PM-GANs: Discriminative Representation Learning for Action Recognition Using Partial-modalities","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_349.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_349.markups.0":{"type":"A","start":9,"end":104,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.06248","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_350":{"id":"5f8adc94679e_350","name":"8a02","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PN-GAN — Pose-Normalized Image Generation for Person Re-identification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_350.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_350.markups.0":{"type":"A","start":9,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.02225","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_351":{"id":"5f8adc94679e_351","name":"500d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"POGAN — Perceptually Optimized Generative Adversarial Network for Single Image Dehazing","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_351.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_351.markups.0":{"type":"A","start":8,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.01084","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_352":{"id":"5f8adc94679e_352","name":"1f47","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Pose-GAN — The Pose Knows: Video Forecasting by Generating Pose Futures","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_352.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_352.markups.0":{"type":"A","start":11,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.00053","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_353":{"id":"5f8adc94679e_353","name":"18a0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PP-GAN — Privacy-Protective-GAN for Face De-identification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_353.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_353.markups.0":{"type":"A","start":9,"end":58,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.08906","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_354":{"id":"5f8adc94679e_354","name":"8502","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PPAN — Privacy-Preserving Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_354.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_354.markups.0":{"type":"A","start":7,"end":46,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.07008","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_355":{"id":"5f8adc94679e_355","name":"6c60","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PPGN — Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_355.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_355.markups.0":{"type":"A","start":7,"end":98,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.00005","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_356":{"id":"5f8adc94679e_356","name":"d758","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PrGAN — 3D Shape Induction from 2D Views of Multiple Objects","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_356.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_356.markups.0":{"type":"A","start":8,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.05872","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_357":{"id":"5f8adc94679e_357","name":"254c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ProGanSR — A Fully Progressive Approach to Single-Image Super-Resolution","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_357.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_357.markups.0":{"type":"A","start":11,"end":72,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.02900","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_358":{"id":"5f8adc94679e_358","name":"abf5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Progressive GAN — Progressive Growing of GANs for Improved Quality, Stability, and Variation (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_358.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_358.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_358.markups.0":{"type":"A","start":18,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.10196","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_358.markups.1":{"type":"A","start":94,"end":100,"href":"https:\u002F\u002Fgithub.com\u002Ftkarras\u002Fprogressive_growing_of_gans","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_359":{"id":"5f8adc94679e_359","name":"9def","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PS-GAN — Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_359.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_359.markups.0":{"type":"A","start":9,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.02047","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_360":{"id":"5f8adc94679e_360","name":"d177","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PSGAN — Learning Texture Manifolds with the Periodic Spatial GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_360.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_360.markups.0":{"type":"A","start":8,"end":64,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1705.06566","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_361":{"id":"5f8adc94679e_361","name":"25ad","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PSGAN — PSGAN: A Generative Adversarial Network for Remote Sensing Image Pan-Sharpening","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_361.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_361.markups.0":{"type":"A","start":8,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.03371","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_362":{"id":"5f8adc94679e_362","name":"8ce8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"PS²-GAN — High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_362.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_362.markups.0":{"type":"A","start":10,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.10182","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_363":{"id":"5f8adc94679e_363","name":"e127","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RadialGAN — RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_363.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_363.markups.0":{"type":"A","start":12,"end":134,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1802.06403","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_364":{"id":"5f8adc94679e_364","name":"26de","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RaGAN — The relativistic discriminator: a key element missing from standard GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_364.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_364.markups.0":{"type":"A","start":8,"end":79,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.00734","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_365":{"id":"5f8adc94679e_365","name":"1540","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RAN — RAN4IQA: Restorative Adversarial Nets for No-Reference Image Quality Assessment (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_365.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_365.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_365.markups.0":{"type":"A","start":6,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.05444","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_365.markups.1":{"type":"A","start":87,"end":93,"href":"https:\u002F\u002Fgithub.com\u002Fhindupuravinash\u002Fthe-gan-zoo\u002Fblob\u002Fmaster","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_366":{"id":"5f8adc94679e_366","name":"ca2b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RankGAN — Adversarial Ranking for Language Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_366.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_366.markups.0":{"type":"A","start":10,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.11001","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_367":{"id":"5f8adc94679e_367","name":"57ca","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RCGAN — Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_367.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_367.markups.0":{"type":"A","start":8,"end":84,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.02633","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_368":{"id":"5f8adc94679e_368","name":"016b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ReConNN — Reconstruction of Simulation-Based Physical Field with Limited Samples by Reconstruction Neural Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_368.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_368.markups.0":{"type":"A","start":10,"end":113,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.00528","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_369":{"id":"5f8adc94679e_369","name":"8dd9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Recycle-GAN — Recycle-GAN: Unsupervised Video Retargeting","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_369.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_369.markups.0":{"type":"A","start":14,"end":57,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.05174","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_370":{"id":"5f8adc94679e_370","name":"3c25","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RefineGAN — Compressed Sensing MRI Reconstruction with Cyclic Loss in Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_370.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_370.markups.0":{"type":"A","start":12,"end":101,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.00753","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_371":{"id":"5f8adc94679e_371","name":"799e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ReGAN — ReGAN: RE[LAX|BAR|INFORCE] based Sequence Generation using GANs (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_371.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_371.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_371.markups.0":{"type":"A","start":8,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.02788","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_371.markups.1":{"type":"A","start":73,"end":79,"href":"https:\u002F\u002Fgithub.com\u002FTalkToTheGAN\u002FREGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_372":{"id":"5f8adc94679e_372","name":"ff15","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RegCGAN — Unpaired Multi-Domain Image Generation via Regularized Conditional GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_372.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_372.markups.0":{"type":"A","start":10,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.02456","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_373":{"id":"5f8adc94679e_373","name":"12b8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RenderGAN — RenderGAN: Generating Realistic Labeled Data","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_373.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_373.markups.0":{"type":"A","start":12,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.01331","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_374":{"id":"5f8adc94679e_374","name":"5ff1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Resembled GAN — Resembled Generative Adversarial Networks: Two Domains with Similar Attributes","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_374.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_374.markups.0":{"type":"A","start":16,"end":94,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.00947","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_375":{"id":"5f8adc94679e_375","name":"ec72","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ResGAN — Generative Adversarial Network based on Resnet for Conditional Image Restoration","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_375.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_375.markups.0":{"type":"A","start":9,"end":89,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.04881","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_376":{"id":"5f8adc94679e_376","name":"dcdf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RNN-WGAN — Language Generation with Recurrent Generative Adversarial Networks without Pre-training (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_376.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_376.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_376.markups.0":{"type":"A","start":11,"end":98,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.01399","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_376.markups.1":{"type":"A","start":100,"end":106,"href":"https:\u002F\u002Fgithub.com\u002Famirbar\u002Frnn.wgan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_377":{"id":"5f8adc94679e_377","name":"1626","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RoCGAN — Robust Conditional Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_377.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_377.markups.0":{"type":"A","start":9,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.08657","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_378":{"id":"5f8adc94679e_378","name":"8a3c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RPGAN — Stabilizing GAN Training with Multiple Random Projections (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_378.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_378.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_378.markups.0":{"type":"A","start":8,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.07831","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_378.markups.1":{"type":"A","start":67,"end":73,"href":"https:\u002F\u002Fgithub.com\u002Fayanc\u002Frpgan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_379":{"id":"5f8adc94679e_379","name":"e3ac","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RTT-GAN — Recurrent Topic-Transition GAN for Visual Paragraph Generation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_379.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_379.markups.0":{"type":"A","start":10,"end":72,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.07022v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_380":{"id":"5f8adc94679e_380","name":"8b73","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RWGAN — Relaxed Wasserstein with Applications to GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_380.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_380.markups.0":{"type":"A","start":8,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.07164","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_381":{"id":"5f8adc94679e_381","name":"bb8e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SAD-GAN — SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_381.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_381.markups.0":{"type":"A","start":10,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.08788v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_382":{"id":"5f8adc94679e_382","name":"811f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SAGA — Generative Adversarial Learning for Spectrum Sensing","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_382.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_382.markups.0":{"type":"A","start":7,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.00709","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_383":{"id":"5f8adc94679e_383","name":"ae38","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SAGAN — Self-Attention Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_383.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_383.markups.0":{"type":"A","start":8,"end":54,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.08318","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_384":{"id":"5f8adc94679e_384","name":"3e51","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SalGAN — SalGAN: Visual Saliency Prediction with Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_384.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_384.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_384.markups.0":{"type":"A","start":9,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.01081","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_384.markups.1":{"type":"A","start":82,"end":88,"href":"https:\u002F\u002Fgithub.com\u002Fimatge-upc\u002Fsaliency-salgan-2017","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_385":{"id":"5f8adc94679e_385","name":"6089","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SAM — Sample-Efficient Imitation Learning via Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_385.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_385.markups.0":{"type":"A","start":6,"end":73,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.02064","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_386":{"id":"5f8adc94679e_386","name":"a1fa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"sAOG — Deep Structured Generative Models","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_386.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_386.markups.0":{"type":"A","start":7,"end":40,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.03877","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_387":{"id":"5f8adc94679e_387","name":"3510","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SAR-GAN — Generating High Quality Visible Images from SAR Images Using CNNs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_387.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_387.markups.0":{"type":"A","start":10,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.10036","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_388":{"id":"5f8adc94679e_388","name":"23f4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SBADA-GAN — From source to target and back: symmetric bi-directional adaptive GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_388.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_388.markups.0":{"type":"A","start":12,"end":81,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.08824","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_389":{"id":"5f8adc94679e_389","name":"8a17","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ScarGAN — ScarGAN: Chained Generative Adversarial Networks to Simulate Pathological Tissue on Cardiovascular MR Scans","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_389.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_389.markups.0":{"type":"A","start":10,"end":117,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.04500","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_390":{"id":"5f8adc94679e_390","name":"d343","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SCH-GAN — SCH-GAN: Semi-supervised Cross-modal Hashing by Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_390.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_390.markups.0":{"type":"A","start":10,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.02488","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_391":{"id":"5f8adc94679e_391","name":"ab9d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SD-GAN — Semantically Decomposing the Latent Spaces of Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_391.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_391.markups.0":{"type":"A","start":9,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.07904","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_392":{"id":"5f8adc94679e_392","name":"5cc8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sdf-GAN — Sdf-GAN: Semi-supervised Depth Fusion with Multi-scale Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_392.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_392.markups.0":{"type":"A","start":10,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.06657","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_393":{"id":"5f8adc94679e_393","name":"c85a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SEGAN — SEGAN: Speech Enhancement Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_393.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_393.markups.0":{"type":"A","start":8,"end":64,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.09452v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_394":{"id":"5f8adc94679e_394","name":"4cf7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SeGAN — SeGAN: Segmenting and Generating the Invisible","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_394.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_394.markups.0":{"type":"A","start":8,"end":54,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.10239","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_395":{"id":"5f8adc94679e_395","name":"af55","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SegAN — SegAN: Adversarial Network with Multi-scale L1 Loss for Medical Image Segmentation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_395.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_395.markups.0":{"type":"A","start":8,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.01805","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_396":{"id":"5f8adc94679e_396","name":"b383","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sem-GAN — Sem-GAN: Semantically-Consistent Image-to-Image Translation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_396.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_396.markups.0":{"type":"A","start":10,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.04409","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_397":{"id":"5f8adc94679e_397","name":"ebdb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SeqGAN — SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_397.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_397.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_397.markups.0":{"type":"A","start":9,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1609.05473v5","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_397.markups.1":{"type":"A","start":76,"end":82,"href":"https:\u002F\u002Fgithub.com\u002FLantaoYu\u002FSeqGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_398":{"id":"5f8adc94679e_398","name":"7bad","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SeUDA — Semantic-Aware Generative Adversarial Nets for Unsupervised Domain Adaptation in Chest X-ray Segmentation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_398.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_398.markups.0":{"type":"A","start":8,"end":113,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.00600","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_399":{"id":"5f8adc94679e_399","name":"d8aa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SG-GAN — Semantic-aware Grad-GAN for Virtual-to-Real Urban Scene Adaption (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_399.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_399.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_399.markups.0":{"type":"A","start":9,"end":73,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.01726","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_399.markups.1":{"type":"A","start":75,"end":81,"href":"https:\u002F\u002Fgithub.com\u002FPeilun-Li\u002FSG-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_400":{"id":"5f8adc94679e_400","name":"7927","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SG-GAN — Sparsely Grouped Multi-task Generative Adversarial Networks for Facial Attribute Manipulation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_400.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_400.markups.0":{"type":"A","start":9,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.07509","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_401":{"id":"5f8adc94679e_401","name":"0ecb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SGAN — Texture Synthesis with Spatial Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_401.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_401.markups.0":{"type":"A","start":7,"end":69,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.08207","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_402":{"id":"5f8adc94679e_402","name":"55bb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SGAN — Stacked Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_402.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_402.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_402.markups.0":{"type":"A","start":7,"end":46,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.04357v4","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_402.markups.1":{"type":"A","start":48,"end":54,"href":"https:\u002F\u002Fgithub.com\u002Fxunhuang1995\u002FSGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_403":{"id":"5f8adc94679e_403","name":"9228","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SGAN — Steganographic Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_403.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_403.markups.0":{"type":"A","start":7,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.05502","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_404":{"id":"5f8adc94679e_404","name":"53c0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SGAN — SGAN: An Alternative Training of Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_404.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_404.markups.0":{"type":"A","start":7,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.02330","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_405":{"id":"5f8adc94679e_405","name":"223c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SGAN — CT Image Enhancement Using Stacked Generative Adversarial Networks and Transfer Learning for Lesion Segmentation Improvement","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_405.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_405.markups.0":{"type":"A","start":7,"end":131,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.07144","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_406":{"id":"5f8adc94679e_406","name":"b075","type":"ULI","href":null,"layout":null,"metadata":null,"text":"sGAN — Generative Adversarial Training for MRA Image Synthesis Using Multi-Contrast MRI","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_406.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_406.markups.0":{"type":"A","start":7,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.04366","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_407":{"id":"5f8adc94679e_407","name":"adc5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SiftingGAN — SiftingGAN: Generating and Sifting Labeled Samples to Improve the Remote Sensing Image Scene Classification Baseline in vitro","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_407.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_407.markups.0":{"type":"A","start":13,"end":138,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.04985","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_408":{"id":"5f8adc94679e_408","name":"87d6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SiGAN — SiGAN: Siamese Generative Adversarial Network for Identity-Preserving Face Hallucination","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_408.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_408.markups.0":{"type":"A","start":8,"end":96,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.08370","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_409":{"id":"5f8adc94679e_409","name":"1945","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SimGAN — Learning from Simulated and Unsupervised Images through Adversarial Training","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_409.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_409.markups.0":{"type":"A","start":9,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.07828","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_410":{"id":"5f8adc94679e_410","name":"0406","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SisGAN — Semantic Image Synthesis via Adversarial Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_410.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_410.markups.0":{"type":"A","start":9,"end":58,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.06873","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_411":{"id":"5f8adc94679e_411","name":"2094","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sketcher-Refiner GAN — Learning Myelin Content in Multiple Sclerosis from Multimodal MRI through Adversarial Training","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_411.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_411.markups.0":{"type":"A","start":23,"end":117,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.08039","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_412":{"id":"5f8adc94679e_412","name":"75eb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SketchGAN — Adversarial Training For Sketch Retrieval","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_412.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_412.markups.0":{"type":"A","start":12,"end":53,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1607.02748","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_413":{"id":"5f8adc94679e_413","name":"bb1e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SketchyGAN — SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_413.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_413.markups.0":{"type":"A","start":13,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.02753","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_414":{"id":"5f8adc94679e_414","name":"322f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Skip-Thought GAN — Generating Text through Adversarial Training using Skip-Thought Vectors","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_414.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_414.markups.0":{"type":"A","start":19,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.08703","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_415":{"id":"5f8adc94679e_415","name":"faa3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SL-GAN — Semi-Latent GAN: Learning to generate and modify facial images from attributes","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_415.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_415.markups.0":{"type":"A","start":9,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.02166","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_416":{"id":"5f8adc94679e_416","name":"8bff","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SLSR — Sparse Label Smoothing for Semi-supervised Person Re-Identification","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_416.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_416.markups.0":{"type":"A","start":7,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.04976","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_417":{"id":"5f8adc94679e_417","name":"8436","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SN-DCGAN — Generative Adversarial Networks for Unsupervised Object Co-localization","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_417.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_417.markups.0":{"type":"A","start":11,"end":82,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.00236","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_418":{"id":"5f8adc94679e_418","name":"ce3e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SN-GAN — Spectral Normalization for Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_418.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_418.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_418.markups.0":{"type":"A","start":9,"end":67,"href":"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F0B8HZ50DPgR3eSVV6YlF3XzQxSjQ\u002Fview","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_418.markups.1":{"type":"A","start":69,"end":75,"href":"https:\u002F\u002Fgithub.com\u002Fpfnet-research\u002Fchainer-gan-lib","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_419":{"id":"5f8adc94679e_419","name":"7083","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SN-PatchGAN — Free-Form Image Inpainting with Gated Convolution","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_419.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_419.markups.0":{"type":"A","start":14,"end":63,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.03589","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_420":{"id":"5f8adc94679e_420","name":"0e1e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sobolev GAN — Sobolev GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_420.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_420.markups.0":{"type":"A","start":14,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.04894","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_421":{"id":"5f8adc94679e_421","name":"5df5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Social GAN — Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_421.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_421.markups.0":{"type":"A","start":13,"end":94,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.10892","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_422":{"id":"5f8adc94679e_422","name":"3e2a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Softmax GAN — Softmax GAN","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_422.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_422.markups.0":{"type":"A","start":14,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.06191","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_423":{"id":"5f8adc94679e_423","name":"3018","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SoPhie — SoPhie: An Attentive GAN for Predicting Paths Compliant to Social and Physical Constraints","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_423.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_423.markups.0":{"type":"A","start":9,"end":99,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.01482","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_424":{"id":"5f8adc94679e_424","name":"b321","type":"ULI","href":null,"layout":null,"metadata":null,"text":"speech-driven animation GAN — End-to-End Speech-Driven Facial Animation with Temporal GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_424.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_424.markups.0":{"type":"A","start":30,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.09313","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_425":{"id":"5f8adc94679e_425","name":"d366","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Spike-GAN — Synthesizing realistic neural population activity patterns using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_425.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_425.markups.0":{"type":"A","start":12,"end":108,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.00338","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_426":{"id":"5f8adc94679e_426","name":"863d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Splitting GAN — Class-Splitting Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_426.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_426.markups.0":{"type":"A","start":16,"end":63,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.07359","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_427":{"id":"5f8adc94679e_427","name":"e412","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SR-CNN-VAE-GAN — Semi-Recurrent CNN-based VAE-GAN for Sequential Data Generation (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_427.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_427.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_427.markups.0":{"type":"A","start":17,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.00509","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_427.markups.1":{"type":"A","start":82,"end":88,"href":"https:\u002F\u002Fgithub.com\u002Fmakbari7\u002FSR-CNN-VAE-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_428":{"id":"5f8adc94679e_428","name":"b013","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SRGAN — Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_428.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_428.markups.0":{"type":"A","start":8,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1609.04802","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_429":{"id":"5f8adc94679e_429","name":"616a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SRPGAN — SRPGAN: Perceptual Generative Adversarial Network for Single Image Super Resolution","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_429.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_429.markups.0":{"type":"A","start":9,"end":92,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.05927","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_430":{"id":"5f8adc94679e_430","name":"b6d2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SS-GAN — Semi-supervised Conditional GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_430.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_430.markups.0":{"type":"A","start":9,"end":41,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.05789","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_431":{"id":"5f8adc94679e_431","name":"ee90","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ss-InfoGAN — Guiding InfoGAN with Semi-Supervision","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_431.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_431.markups.0":{"type":"A","start":13,"end":50,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.04487","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_432":{"id":"5f8adc94679e_432","name":"3336","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SSGAN — SSGAN: Secure Steganography Based on Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_432.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_432.markups.0":{"type":"A","start":8,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.01613","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_433":{"id":"5f8adc94679e_433","name":"9531","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SSL-GAN — Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_433.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_433.markups.0":{"type":"A","start":10,"end":91,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.06430v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_434":{"id":"5f8adc94679e_434","name":"1d4b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ST-CGAN — Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_434.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_434.markups.0":{"type":"A","start":10,"end":118,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.02478","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_435":{"id":"5f8adc94679e_435","name":"9edd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ST-GAN — Style Transfer Generative Adversarial Networks: Learning to Play Chess Differently","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_435.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_435.markups.0":{"type":"A","start":9,"end":91,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.06762","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_436":{"id":"5f8adc94679e_436","name":"d06b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ST-GAN — ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_436.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_436.markups.0":{"type":"A","start":9,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.01837","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_437":{"id":"5f8adc94679e_437","name":"bdde","type":"ULI","href":null,"layout":null,"metadata":null,"text":"StackGAN — StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_437.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_437.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_437.markups.0":{"type":"A","start":11,"end":105,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1612.03242v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_437.markups.1":{"type":"A","start":107,"end":113,"href":"https:\u002F\u002Fgithub.com\u002Fhanzhanggit\u002FStackGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_438":{"id":"5f8adc94679e_438","name":"d9bc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"StainGAN — StainGAN: Stain Style Transfer for Digital Histological Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_438.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_438.markups.0":{"type":"A","start":11,"end":73,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.01601","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_439":{"id":"5f8adc94679e_439","name":"30ad","type":"ULI","href":null,"layout":null,"metadata":null,"text":"StarGAN — StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_439.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_439.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_439.markups.0":{"type":"A","start":10,"end":102,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.09020","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_439.markups.1":{"type":"A","start":104,"end":110,"href":"https:\u002F\u002Fgithub.com\u002Fyunjey\u002FStarGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_440":{"id":"5f8adc94679e_440","name":"589c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"StarGAN-VC — StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_440.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_440.markups.0":{"type":"A","start":13,"end":109,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.02169","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_441":{"id":"5f8adc94679e_441","name":"cdb7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SteinGAN — Learning Deep Energy Models: Contrastive Divergence vs. Amortized MLE","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_441.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_441.markups.0":{"type":"A","start":11,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.00797","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_442":{"id":"5f8adc94679e_442","name":"564d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"StepGAN — Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_442.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_442.markups.0":{"type":"A","start":10,"end":95,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.05599","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_443":{"id":"5f8adc94679e_443","name":"8dba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Super-FAN — Super-FAN: Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_443.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_443.markups.0":{"type":"A","start":12,"end":147,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.02765","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_444":{"id":"5f8adc94679e_444","name":"b66e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SVSGAN — SVSGAN: Singing Voice Separation via Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_444.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_444.markups.0":{"type":"A","start":9,"end":76,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.11428","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_445":{"id":"5f8adc94679e_445","name":"4c60","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SWGAN — Solving Approximate Wasserstein GANs to Stationarity","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_445.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_445.markups.0":{"type":"A","start":8,"end":60,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.08249","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_446":{"id":"5f8adc94679e_446","name":"a35b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SyncGAN — SyncGAN: Synchronize the Latent Space of Cross-modal Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_446.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_446.markups.0":{"type":"A","start":10,"end":94,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.00410","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_447":{"id":"5f8adc94679e_447","name":"9072","type":"ULI","href":null,"layout":null,"metadata":null,"text":"S²GAN — Generative Image Modeling using Style and Structure Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_447.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_447.markups.0":{"type":"A","start":8,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1603.05631v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_448":{"id":"5f8adc94679e_448","name":"86a8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"T2Net — T2Net: Synthetic-to-Realistic Translation for Solving Single-Image Depth Estimation Tasks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_448.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_448.markups.0":{"type":"A","start":8,"end":97,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.01454","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_449":{"id":"5f8adc94679e_449","name":"2c5a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"table-GAN — Data Synthesis based on Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_449.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_449.markups.0":{"type":"A","start":12,"end":67,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.03384","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_450":{"id":"5f8adc94679e_450","name":"6b8e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TAC-GAN — TAC-GAN — Text Conditioned Auxiliary Classifier Generative Adversarial Network (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_450.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_450.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_450.markups.0":{"type":"A","start":10,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.06412v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_450.markups.1":{"type":"A","start":90,"end":96,"href":"https:\u002F\u002Fgithub.com\u002Fdashayushman\u002FTAC-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_451":{"id":"5f8adc94679e_451","name":"bdc2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TAN — Outline Colorization through Tandem Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_451.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_451.markups.0":{"type":"A","start":6,"end":62,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.08834","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_452":{"id":"5f8adc94679e_452","name":"d3d2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"tcGAN — Cross-modal Hallucination for Few-shot Fine-grained Recognition","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_452.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_452.markups.0":{"type":"A","start":8,"end":71,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.05147","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_453":{"id":"5f8adc94679e_453","name":"b49a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TD-GAN — Task Driven Generative Modeling for Unsupervised Domain Adaptation: Application to X-ray Image Segmentation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_453.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_453.markups.0":{"type":"A","start":9,"end":116,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.07201","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_454":{"id":"5f8adc94679e_454","name":"d6be","type":"ULI","href":null,"layout":null,"metadata":null,"text":"tempCycleGAN — Improving Surgical Training Phantoms by Hyperrealism: Deep Unpaired Image-to-Image Translation from Real Surgeries","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_454.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_454.markups.0":{"type":"A","start":15,"end":129,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.03627","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_455":{"id":"5f8adc94679e_455","name":"b230","type":"ULI","href":null,"layout":null,"metadata":null,"text":"tempoGAN — tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_455.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_455.markups.0":{"type":"A","start":11,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.09710","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_456":{"id":"5f8adc94679e_456","name":"0679","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TequilaGAN — TequilaGAN: How to easily identify GAN samples","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_456.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_456.markups.0":{"type":"A","start":13,"end":59,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.04919","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_457":{"id":"5f8adc94679e_457","name":"2c58","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Text2Shape — Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_457.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_457.markups.0":{"type":"A","start":13,"end":93,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.08495","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_458":{"id":"5f8adc94679e_458","name":"d65e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"textGAN — Generating Text via Adversarial Training","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_458.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_458.markups.0":{"type":"A","start":10,"end":50,"href":"https:\u002F\u002Fzhegan27.github.io\u002FPapers\u002FtextGAN_nips2016_workshop.pdf","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_459":{"id":"5f8adc94679e_459","name":"76cf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TextureGAN — TextureGAN: Controlling Deep Image Synthesis with Texture Patches","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_459.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_459.markups.0":{"type":"A","start":13,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.02823","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_460":{"id":"5f8adc94679e_460","name":"ec1f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TGAN — Temporal Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_460.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_460.markups.0":{"type":"A","start":7,"end":43,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.06624v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_461":{"id":"5f8adc94679e_461","name":"c716","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TGAN — Tensorizing Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_461.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_461.markups.0":{"type":"A","start":7,"end":46,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1710.10772","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_462":{"id":"5f8adc94679e_462","name":"3cda","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TGAN — Tensor-Generative Adversarial Network with Two-dimensional Sparse Coding: Application to Real-time Indoor Localization","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_462.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_462.markups.0":{"type":"A","start":7,"end":125,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.02666","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_463":{"id":"5f8adc94679e_463","name":"d074","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TGANs-C — To Create What You Tell: Generating Videos from Captions","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_463.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_463.markups.0":{"type":"A","start":10,"end":66,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.08264","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_464":{"id":"5f8adc94679e_464","name":"795c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"tiny-GAN — Analysis of Nonautonomous Adversarial Systems","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_464.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_464.markups.0":{"type":"A","start":11,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.05045","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_465":{"id":"5f8adc94679e_465","name":"d908","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TP-GAN — Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_465.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_465.markups.0":{"type":"A","start":9,"end":128,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.04086","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_466":{"id":"5f8adc94679e_466","name":"8fee","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TreeGAN — TreeGAN: Syntax-Aware Sequence Generation with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_466.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_466.markups.0":{"type":"A","start":10,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.07582","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_467":{"id":"5f8adc94679e_467","name":"3199","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Triple-GAN — Triple Generative Adversarial Nets","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_467.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_467.markups.0":{"type":"A","start":13,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.02291v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_468":{"id":"5f8adc94679e_468","name":"7d50","type":"ULI","href":null,"layout":null,"metadata":null,"text":"tripletGAN — TripletGAN: Training Generative Model with Triplet Loss","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_468.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_468.markups.0":{"type":"A","start":13,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.05084","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_469":{"id":"5f8adc94679e_469","name":"56de","type":"ULI","href":null,"layout":null,"metadata":null,"text":"TV-GAN — TV-GAN: Generative Adversarial Network Based Thermal to Visible Face Recognition","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_469.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_469.markups.0":{"type":"A","start":9,"end":89,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.02514","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_470":{"id":"5f8adc94679e_470","name":"ac6e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Twin-GAN — Twin-GAN — Unpaired Cross-Domain Image Translation with Weight-Sharing GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_470.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_470.markups.0":{"type":"A","start":11,"end":86,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.00946","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_471":{"id":"5f8adc94679e_471","name":"30b7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"UGACH — Unsupervised Generative Adversarial Cross-modal Hashing","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_471.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_471.markups.0":{"type":"A","start":8,"end":63,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00358","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_472":{"id":"5f8adc94679e_472","name":"ec50","type":"ULI","href":null,"layout":null,"metadata":null,"text":"UGAN — Enhancing Underwater Imagery using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_472.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_472.markups.0":{"type":"A","start":7,"end":73,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1801.04011","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_473":{"id":"5f8adc94679e_473","name":"af56","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Unim2im — Unsupervised Image-to-Image Translation with Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_473.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_473.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_473.markups.0":{"type":"A","start":10,"end":87,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.02676","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_473.markups.1":{"type":"A","start":88,"end":94,"href":"http:\u002F\u002Fgithub.com\u002Fzsdonghao\u002FUnsup-Im2Im","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_474":{"id":"5f8adc94679e_474","name":"dde0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"UNIT — Unsupervised Image-to-image Translation Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_474.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_474.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_474.markups.0":{"type":"A","start":7,"end":55,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1703.00848","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_474.markups.1":{"type":"A","start":57,"end":63,"href":"https:\u002F\u002Fgithub.com\u002Fmingyuliutw\u002FUNIT","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_475":{"id":"5f8adc94679e_475","name":"2c88","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Unrolled GAN — Unrolled Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_475.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_475.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_475.markups.0":{"type":"A","start":15,"end":55,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.02163","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_475.markups.1":{"type":"A","start":57,"end":63,"href":"https:\u002F\u002Fgithub.com\u002Fpoolio\u002Funrolled_gan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_476":{"id":"5f8adc94679e_476","name":"be6b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"UT-SCA-GAN — Spatial Image Steganography Based on Generative Adversarial Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_476.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_476.markups.0":{"type":"A","start":13,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1804.07939","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_477":{"id":"5f8adc94679e_477","name":"4935","type":"ULI","href":null,"layout":null,"metadata":null,"text":"UV-GAN — UV-GAN: Adversarial Facial UV Map Completion for Pose-invariant Face Recognition","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_477.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_477.markups.0":{"type":"A","start":9,"end":89,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.04695","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_478":{"id":"5f8adc94679e_478","name":"e803","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VA-GAN — Visual Feature Attribution using Wasserstein GANs","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_478.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_478.markups.0":{"type":"A","start":9,"end":58,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.08998","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_479":{"id":"5f8adc94679e_479","name":"823e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VAC+GAN — Versatile Auxiliary Classifier with Generative Adversarial Network (VAC+GAN), Multi Class Scenarios","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_479.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_479.markups.0":{"type":"A","start":10,"end":109,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.07751","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_480":{"id":"5f8adc94679e_480","name":"aa48","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VAE-GAN — Autoencoding beyond pixels using a learned similarity metric","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_480.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_480.markups.0":{"type":"A","start":10,"end":70,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1512.09300","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_481":{"id":"5f8adc94679e_481","name":"c5ca","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VariGAN — Multi-View Image Generation from a Single-View","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_481.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_481.markups.0":{"type":"A","start":10,"end":56,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.04886","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_482":{"id":"5f8adc94679e_482","name":"a4f0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VAW-GAN — Voice Conversion from Unaligned Corpora using Variational Autoencoding Wasserstein Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_482.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_482.markups.0":{"type":"A","start":10,"end":124,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.00849","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_483":{"id":"5f8adc94679e_483","name":"9b35","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VEEGAN — VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_483.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_483.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_483.markups.0":{"type":"A","start":9,"end":83,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.07761","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_483.markups.1":{"type":"A","start":85,"end":91,"href":"https:\u002F\u002Fgithub.com\u002Fakashgit\u002FVEEGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_484":{"id":"5f8adc94679e_484","name":"7ab4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VGAN — Generating Videos with Scene Dynamics (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_484.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_484.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_484.markups.0":{"type":"A","start":7,"end":44,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1609.02612","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_484.markups.1":{"type":"A","start":46,"end":52,"href":"https:\u002F\u002Fgithub.com\u002Fcvondrick\u002Fvideogan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_485":{"id":"5f8adc94679e_485","name":"d626","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VGAN — Generative Adversarial Networks as Variational Training of Energy Based Models (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_485.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_485.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_485.markups.0":{"type":"A","start":7,"end":85,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1611.01799","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_485.markups.1":{"type":"A","start":87,"end":93,"href":"https:\u002F\u002Fgithub.com\u002FShuangfei\u002Fvgan","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_486":{"id":"5f8adc94679e_486","name":"812a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VGAN — Text Generation Based on Generative Adversarial Nets with Latent Variable","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_486.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_486.markups.0":{"type":"A","start":7,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.00170","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_487":{"id":"5f8adc94679e_487","name":"9f4d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ViGAN — Image Generation and Editing with Variational Info Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_487.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_487.markups.0":{"type":"A","start":8,"end":90,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.04568v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_488":{"id":"5f8adc94679e_488","name":"367f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VIGAN — VIGAN: Missing View Imputation with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_488.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_488.markups.0":{"type":"A","start":8,"end":75,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1708.06724","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_489":{"id":"5f8adc94679e_489","name":"8243","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VoiceGAN — Voice Impersonation using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_489.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_489.markups.0":{"type":"A","start":11,"end":68,"href":"http:\u002F\u002Farxiv.org\u002Fabs\u002F1802.06840","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_490":{"id":"5f8adc94679e_490","name":"c874","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VOS-GAN — VOS-GAN: Adversarial Learning of Visual-Temporal Dynamics for Unsupervised Dense Prediction in Videos","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_490.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_490.markups.0":{"type":"A","start":10,"end":111,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.09092","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_491":{"id":"5f8adc94679e_491","name":"607f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"VRAL — Variance Regularizing Adversarial Learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_491.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_491.markups.0":{"type":"A","start":7,"end":49,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1707.00309","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_492":{"id":"5f8adc94679e_492","name":"d9ad","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WaterGAN — WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_492.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_492.markups.0":{"type":"A","start":11,"end":120,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1702.07392v1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_493":{"id":"5f8adc94679e_493","name":"ffff","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WaveGAN — Synthesizing Audio with Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_493.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_493.markups.0":{"type":"A","start":10,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1802.04208","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_494":{"id":"5f8adc94679e_494","name":"7914","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WaveletGLCA-GAN — Global and Local Consistent Wavelet-domain Age Synthesis","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_494.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_494.markups.0":{"type":"A","start":18,"end":74,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1809.07764","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_495":{"id":"5f8adc94679e_495","name":"e4a6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"weGAN — Generative Adversarial Nets for Multiple Text Corpora","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_495.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_495.markups.0":{"type":"A","start":8,"end":61,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1712.09127","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_496":{"id":"5f8adc94679e_496","name":"24bd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WGAN — Wasserstein GAN (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_496.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_496.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_496.markups.0":{"type":"A","start":7,"end":22,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1701.07875v2","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_496.markups.1":{"type":"A","start":24,"end":30,"href":"https:\u002F\u002Fgithub.com\u002Fmartinarjovsky\u002FWassersteinGAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_497":{"id":"5f8adc94679e_497","name":"1789","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WGAN-CLS — Text to Image Synthesis Using Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_497.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_497.markups.0":{"type":"A","start":11,"end":72,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1805.00676","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_498":{"id":"5f8adc94679e_498","name":"306c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WGAN-GP — Improved Training of Wasserstein GANs (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_498.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_498.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_498.markups.0":{"type":"A","start":10,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1704.00028","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_498.markups.1":{"type":"A","start":49,"end":55,"href":"https:\u002F\u002Fgithub.com\u002Figul222\u002Fimproved_wgan_training","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_499":{"id":"5f8adc94679e_499","name":"82cf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WGAN-L1 — Subsampled Turbulence Removal Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_499.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_499.markups.0":{"type":"A","start":10,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.04418","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_500":{"id":"5f8adc94679e_500","name":"064f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"WS-GAN — Weakly Supervised Generative Adversarial Networks for 3D Reconstruction","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_500.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_500.markups.0":{"type":"A","start":9,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.10904","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_501":{"id":"5f8adc94679e_501","name":"c249","type":"ULI","href":null,"layout":null,"metadata":null,"text":"X-GANs — X-GANs: Image Reconstruction Made Easy for Extreme Cases","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_501.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_501.markups.0":{"type":"A","start":9,"end":65,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.04432","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_502":{"id":"5f8adc94679e_502","name":"3083","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGAN — XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_502.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_502.markups.0":{"type":"A","start":7,"end":78,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.05139","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_503":{"id":"5f8adc94679e_503","name":"324e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ZipNet-GAN — ZipNet-GAN: Inferring Fine-grained Mobile Traffic Patterns via a Generative Adversarial Neural Network","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_503.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_503.markups.0":{"type":"A","start":13,"end":115,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1711.02413","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_504":{"id":"5f8adc94679e_504","name":"1619","type":"ULI","href":null,"layout":null,"metadata":null,"text":"α-GAN — Variational Approaches for Auto-Encoding Generative Adversarial Networks (github)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_504.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_504.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_504.markups.0":{"type":"A","start":8,"end":80,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.04987","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_504.markups.1":{"type":"A","start":82,"end":88,"href":"https:\u002F\u002Fgithub.com\u002Fvictor-shepardson\u002Falpha-GAN","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_505":{"id":"5f8adc94679e_505","name":"08db","type":"ULI","href":null,"layout":null,"metadata":null,"text":"β-GAN — Annealed Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_505.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_505.markups.0":{"type":"A","start":8,"end":48,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1705.07505","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_506":{"id":"5f8adc94679e_506","name":"8aae","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Δ-GAN — Triangle Generative Adversarial Networks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_506.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_506.markups.0":{"type":"A","start":8,"end":48,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.06548","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_507":{"id":"5f8adc94679e_507","name":"17ee","type":"P","href":null,"layout":null,"metadata":null,"text":"Visit the Github repository to add more links via pull requests or create an issue to lemme know something I missed or to start a discussion. Thanks to all the contributors, especially Emanuele Plebani, Lukas Galke, Peter Waller and Bruno Gavranović.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_507.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_507.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_507.markups.2","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_507.markups.3","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_507.markups.4","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_507.markups.0":{"type":"A","start":10,"end":27,"href":"https:\u002F\u002Fgithub.com\u002Fhindupuravinash\u002Fthe-gan-zoo","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_507.markups.1":{"type":"A","start":185,"end":201,"href":"https:\u002F\u002Fgithub.com\u002FBanus","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_507.markups.2":{"type":"A","start":203,"end":214,"href":"https:\u002F\u002Fgithub.com\u002Flgalke","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_507.markups.3":{"type":"A","start":216,"end":228,"href":"https:\u002F\u002Fgithub.com\u002Fpwaller","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_507.markups.4":{"type":"A","start":233,"end":249,"href":"https:\u002F\u002Fgithub.com\u002Fbgavran","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:5f8adc94679e_508":{"id":"5f8adc94679e_508","name":"35d5","type":"P","href":null,"layout":null,"metadata":null,"text":"If you like what you are reading, follow Deep Hunt — a weekly AI newsletter with special focus on Machine Learning to stay updated in this fast moving field.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:5f8adc94679e_508.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:5f8adc94679e_508.markups.0":{"type":"A","start":41,"end":50,"href":"https:\u002F\u002Fdeephunt.in\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Tag:machine-learning":{"id":"machine-learning","displayTitle":"Machine Learning","__typename":"Tag"},"Tag:artificial-intelligence":{"id":"artificial-intelligence","displayTitle":"Artificial Intelligence","__typename":"Tag"},"Tag:deep-learning":{"id":"deep-learning","displayTitle":"Deep Learning","__typename":"Tag"},"Tag:technology":{"id":"technology","displayTitle":"Technology","__typename":"Tag"},"Tag:neural-networks":{"id":"neural-networks","displayTitle":"Neural Networks","__typename":"Tag"},"$Post:79597dc8c347.postResponses":{"count":8,"__typename":"PostResponses"},"$Post:79597dc8c347.previewContent":{"subtitle":"A list of all named GANs!","__typename":"PreviewContent"}}</script><script src="./The GAN Zoo - Deep Hunt_files/manifest.7d2785d8.js"></script><script src="./The GAN Zoo - Deep Hunt_files/vendors_main.314590f6.chunk.js"></script><script src="./The GAN Zoo - Deep Hunt_files/main.c8f95410.chunk.js"></script><script src="./The GAN Zoo - Deep Hunt_files/vendors_instrumentation.b4ca681f.chunk.js"></script>
<script src="./The GAN Zoo - Deep Hunt_files/instrumentation.e5b0d1a6.chunk.js"></script>
<script src="./The GAN Zoo - Deep Hunt_files/reporting.83f8bbe2.chunk.js"></script>
<script src="./The GAN Zoo - Deep Hunt_files/vendors_AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformEditor_Collection_37c9fa1e.77e6fe9c.chunk.js"></script>
<script src="./The GAN Zoo - Deep Hunt_files/vendors_AMPPost_DebugCachedPost_Post_SequencePost_Series.0bf77567.chunk.js"></script>
<script src="./The GAN Zoo - Deep Hunt_files/AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformEditor_CollectionPostShor_3fa3f642.15e3ccc0.chunk.js"></script>
<script src="./The GAN Zoo - Deep Hunt_files/AMPPost_CollectionHomepage_CollectionHomepagePreview_DebugCachedPost_PackageBuilder_Post_SequenceLib_32b7ff81.4df3a8c2.chunk.js"></script>
<script src="./The GAN Zoo - Deep Hunt_files/Post.579e0610.chunk.js"></script><script>window.main();</script><script src="./The GAN Zoo - Deep Hunt_files/p.js" async="" id="parsely-cf"></script><iframe src="./The GAN Zoo - Deep Hunt_files/a16180790160.html" hidden="" tabindex="-1" title="Optimizely Internal Frame" height="0" width="0" style="display: none;"></iframe><iframe frameborder="0" scrolling="no" style="background-color: transparent; border: 0px; display: none;" src="./The GAN Zoo - Deep Hunt_files/saved_resource.html"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:true,&quot;ss&quot;:true}" style="display: none;"></div></body></html>